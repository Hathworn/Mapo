{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11b8a95-5d5e-4bd6-946a-09196306b71b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mm2_kernel1(int, int, int, int, float, float, float*, float*, float*)': {'demangledName': 'mm2_kernel1(int, int, int, int, float, float, float*, float*, float*)',\n",
       "  'actualName': 'mm2_kernel1',\n",
       "  'vector': [-4.376014108657989,\n",
       "   -0.8832646128949169,\n",
       "   -13.14113780736776,\n",
       "   -5.632629050813722,\n",
       "   4.133851467273263,\n",
       "   12.36032405351951,\n",
       "   4.081151569938985,\n",
       "   -11.539710300388139,\n",
       "   -12.335082979147103,\n",
       "   3.272177472125346,\n",
       "   11.348284178114042,\n",
       "   -15.739424615820274,\n",
       "   -3.4178150890754364,\n",
       "   14.24129976500746,\n",
       "   -9.62373974639389,\n",
       "   8.339995335514699,\n",
       "   13.175991092112461,\n",
       "   4.540791896866637,\n",
       "   -14.793326454769634,\n",
       "   3.3267827333452016,\n",
       "   13.07318535179251,\n",
       "   11.038970126211954,\n",
       "   18.57576752544045,\n",
       "   12.234786726247664,\n",
       "   -12.019073281849478,\n",
       "   1.4890672948148624,\n",
       "   -4.339262908078936,\n",
       "   -3.799208032023643,\n",
       "   1.2422534256476427,\n",
       "   0.06964621193988835,\n",
       "   2.005428543347515,\n",
       "   -0.8226425750378644,\n",
       "   11.171583648315544,\n",
       "   -10.80669578167841,\n",
       "   -5.504876329914569,\n",
       "   -3.5623908388970733,\n",
       "   -0.21220433415562712,\n",
       "   2.5642888110420046,\n",
       "   12.263379814772453,\n",
       "   -13.170105501762805,\n",
       "   3.633244689417534,\n",
       "   6.605674854248898,\n",
       "   5.712931995748878,\n",
       "   -3.996590079776551,\n",
       "   -4.716503000529056,\n",
       "   -0.8229695093980122,\n",
       "   7.122447896888371,\n",
       "   11.039450865420164,\n",
       "   8.137891844209665,\n",
       "   -2.8306908595180453,\n",
       "   6.2580903297200665,\n",
       "   4.622797920649256,\n",
       "   5.635045978793693,\n",
       "   2.3269324967627614,\n",
       "   5.25870925460632,\n",
       "   -2.7672753729843578,\n",
       "   5.4973855004980035,\n",
       "   -0.018477229454785582,\n",
       "   -2.418234549860418,\n",
       "   -12.997322149768523,\n",
       "   -1.5255895291648338,\n",
       "   6.446073341513017,\n",
       "   -2.111146843503973,\n",
       "   14.453068902710367,\n",
       "   13.79656904031019,\n",
       "   5.738259625197161,\n",
       "   -2.9780391384256624,\n",
       "   6.676970157486786,\n",
       "   3.626607419783034,\n",
       "   2.133973497867001,\n",
       "   4.960147570479986,\n",
       "   1.2341333335177145,\n",
       "   -5.827607385791416,\n",
       "   8.250567361168008,\n",
       "   -3.5352617632518895,\n",
       "   -1.477315547482415,\n",
       "   0.9872578681525324,\n",
       "   -1.9805199532723117,\n",
       "   -2.743272621013814,\n",
       "   -6.057698055552732,\n",
       "   -3.178913292891278,\n",
       "   4.353305575986276,\n",
       "   6.651152233755338,\n",
       "   2.434480826486781,\n",
       "   6.733436270525149,\n",
       "   0.24003568893636162,\n",
       "   12.194151577420481,\n",
       "   3.401784776132755,\n",
       "   -5.449245306416333,\n",
       "   15.145105602472395,\n",
       "   18.873169826519756,\n",
       "   -9.17188737928218,\n",
       "   -5.702874239573074,\n",
       "   0.3432106155883953,\n",
       "   -5.814370966681219,\n",
       "   4.837892766740872,\n",
       "   -4.211224428240223,\n",
       "   10.157273191799447,\n",
       "   3.678279464580798,\n",
       "   3.1817229395612476,\n",
       "   -11.592561086350479,\n",
       "   -6.478526103431839,\n",
       "   -9.868119035263028,\n",
       "   5.090280541695851,\n",
       "   -4.344792628101076,\n",
       "   1.6247886947987569,\n",
       "   4.95327606636827,\n",
       "   5.449040171621409,\n",
       "   -6.62121387028023,\n",
       "   -0.4516798093023018,\n",
       "   9.51847446624695,\n",
       "   9.319635587281976,\n",
       "   -1.214725350613574,\n",
       "   -23.110394432978165,\n",
       "   -13.650009233458526,\n",
       "   -6.390376210961946,\n",
       "   -2.699517071555066,\n",
       "   -0.10526387461857503,\n",
       "   -6.8868633345203145,\n",
       "   -11.465665067323034,\n",
       "   0.40453723976494405,\n",
       "   4.928875650942461,\n",
       "   -2.3749973119188708,\n",
       "   -2.0464365323758713,\n",
       "   2.4225072078179095,\n",
       "   -1.6881983944611543,\n",
       "   1.2822048403400659,\n",
       "   10.101737531788158,\n",
       "   -2.6140241193258924,\n",
       "   -0.8137464614472394,\n",
       "   7.2719952550633415,\n",
       "   17.785551047184395,\n",
       "   -9.314560892631178,\n",
       "   -9.740474432809501,\n",
       "   5.910232033462554,\n",
       "   -8.663883724661911,\n",
       "   3.445318066789307,\n",
       "   11.861503960509731,\n",
       "   -2.587944497142326,\n",
       "   -6.134184991023087,\n",
       "   -1.1776938601292213,\n",
       "   -8.229285544894601,\n",
       "   10.70593562545077,\n",
       "   8.111925652426546,\n",
       "   -5.5450667506892914,\n",
       "   -7.0051582320717305,\n",
       "   -1.667190266007666,\n",
       "   5.5934136779878365,\n",
       "   -2.653030858382039,\n",
       "   24.48124421280345,\n",
       "   0.977273409971581,\n",
       "   18.22454442016371,\n",
       "   12.403157653644953,\n",
       "   -12.383296294235564,\n",
       "   -6.222564782505004,\n",
       "   -7.15023521886184,\n",
       "   -2.555764059799938,\n",
       "   0.5064637680354489,\n",
       "   1.0366711993673863,\n",
       "   -1.0279759733405511,\n",
       "   -3.6537807065052728,\n",
       "   -15.11821067651227,\n",
       "   9.11053560629,\n",
       "   15.829948732252754,\n",
       "   8.431122221795006,\n",
       "   -9.492701240293378,\n",
       "   14.93979166791366,\n",
       "   3.4746935361362916,\n",
       "   -4.224992384204251,\n",
       "   -5.820940256748429,\n",
       "   3.3059830816665436,\n",
       "   0.8103456241765106,\n",
       "   3.4388056213459306,\n",
       "   -10.294284872490163,\n",
       "   -3.6232604622407005,\n",
       "   15.4868351472906,\n",
       "   19.485084609061374,\n",
       "   -5.920950527542864,\n",
       "   -1.1026914650938697,\n",
       "   4.2758010145119405,\n",
       "   3.6777915286603693,\n",
       "   3.5090645981761672,\n",
       "   -0.8083062868919302,\n",
       "   -5.684456649337734,\n",
       "   -6.682194096329762,\n",
       "   4.957680644492397,\n",
       "   7.9295720012295625,\n",
       "   4.305157379024584,\n",
       "   6.804568565987112,\n",
       "   11.49063284192678,\n",
       "   -3.0645823425844863,\n",
       "   13.386167113962621,\n",
       "   0.6095946013355903,\n",
       "   -0.8641192023370361,\n",
       "   9.515079976898383,\n",
       "   3.120250154498892,\n",
       "   -13.640241116366141,\n",
       "   5.6965780659434735,\n",
       "   -3.561915177061273,\n",
       "   6.449180327713824,\n",
       "   5.654473112339552,\n",
       "   -7.976340569601864,\n",
       "   -9.346294662988832,\n",
       "   6.77977267716483,\n",
       "   -11.213675794329458,\n",
       "   -2.107629351272527,\n",
       "   4.799709630039857,\n",
       "   -5.045663024441946,\n",
       "   0.6554369043483621,\n",
       "   5.922423736768964,\n",
       "   3.398769556937607,\n",
       "   -1.5260623702456302,\n",
       "   -8.597123462809824,\n",
       "   6.906982922672409,\n",
       "   2.734820498270163,\n",
       "   -0.5271604178806348,\n",
       "   -2.3880241014835946,\n",
       "   15.254628218351144,\n",
       "   1.3853895839032793,\n",
       "   -5.514845031652452,\n",
       "   12.695160872404742,\n",
       "   2.4793015651351076,\n",
       "   -4.60120282574761,\n",
       "   -8.025810189673399,\n",
       "   -6.05432679820046,\n",
       "   1.8618789389185233,\n",
       "   -9.699416917398397,\n",
       "   -12.609179470023527,\n",
       "   8.29277068343307,\n",
       "   -3.512115448206608,\n",
       "   -0.7451327212721984,\n",
       "   -1.5118600103732422,\n",
       "   1.2099364945415743,\n",
       "   8.891365576294291,\n",
       "   9.472485954284963,\n",
       "   12.540632538071767,\n",
       "   -10.454518290492304,\n",
       "   4.722248299462005,\n",
       "   10.437901492498526,\n",
       "   -3.892772858644476,\n",
       "   7.7317360972876985,\n",
       "   5.340121223826833,\n",
       "   1.541446540161418,\n",
       "   -1.3522643568981823,\n",
       "   -3.508547282946483,\n",
       "   -1.2253033799069661,\n",
       "   -7.896765514937524,\n",
       "   -4.142721745760715,\n",
       "   0.47614013396655963,\n",
       "   4.836494787906072,\n",
       "   -15.102259775952652,\n",
       "   3.6972262713429913,\n",
       "   -3.7499582013734365,\n",
       "   12.760397699732415,\n",
       "   1.9120964035048897,\n",
       "   0.6292326356452271,\n",
       "   -17.374265657162447,\n",
       "   -0.9897216787540353,\n",
       "   11.294317869240587,\n",
       "   2.1561719302234286,\n",
       "   -0.1165346202101186,\n",
       "   1.4056674025760287,\n",
       "   1.1032779596986098,\n",
       "   -12.018996626488413,\n",
       "   -2.651671350652726,\n",
       "   8.877985455426213,\n",
       "   -6.1948287077884245,\n",
       "   4.055819032685353,\n",
       "   -7.982398065756453,\n",
       "   -1.4924084084118894,\n",
       "   -12.543685906583516,\n",
       "   -9.613549910740288,\n",
       "   10.343105618619465,\n",
       "   5.443413423112666,\n",
       "   9.874629374113407,\n",
       "   -2.5798161255848395,\n",
       "   0.8679837991819144,\n",
       "   2.7822508992191524,\n",
       "   6.111927543066954,\n",
       "   4.612838557389833,\n",
       "   4.7154364920867335,\n",
       "   10.864854416601894,\n",
       "   6.3759996581127405,\n",
       "   -5.740978238113937,\n",
       "   1.5284613094010628,\n",
       "   -1.5580532993294112,\n",
       "   -12.129052956553867,\n",
       "   9.941456839378292,\n",
       "   -11.019424758493559,\n",
       "   -12.828225840469301,\n",
       "   10.691783754645245,\n",
       "   -3.916856788991585,\n",
       "   -8.158599016365747,\n",
       "   2.5721235466326138,\n",
       "   -2.176345225236163,\n",
       "   14.701838354547194,\n",
       "   4.570290733623768,\n",
       "   -5.811766451137017,\n",
       "   -3.6831234923856004,\n",
       "   9.460789321157918]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ir2vec\n",
    "import numpy as np\n",
    "\n",
    "# IR2Vec Python APIs can be used in two ways. As shown below.\n",
    "initObj = ir2vec.initEmbedding(\"/home/pm/performance_modeling/per_model/IR/2mm/kernel1.ll\", \"fa\", \"p\")\n",
    "ir2vec.getFunctionVectors(initObj)\n",
    "\n",
    "\n",
    "# instructionVectorsList1 = ir2vec.getInstructionVectors(initObj)\n",
    "# progVector1\n",
    "# #Approach 2\n",
    "# progVector2 = initObj.getProgramVector()\n",
    "# functionVectorMap2 = initObj.getFunctionVectors()\n",
    "# instructionVectorsList2 = initObj.getInstructionVectors()\n",
    "\n",
    "# # Both the approaches would result in same outcomes\n",
    "# assert(np.allclose(progVector1,progVector2))\n",
    "\n",
    "# for fun, funcObj in functionVectorMap1.items():\n",
    "#     assert fun == funcObj[\"demangledName\"]\n",
    "#     functionOutput1 = ir2vec.getFunctionVectors(\n",
    "#         initObj,\n",
    "#         funcObj[\"actualName\"],\n",
    "#     )\n",
    "#     functionOutput2 = initObj.getFunctionVectors(\n",
    "#         funcObj[\"actualName\"]\n",
    "#     )\n",
    "#     assert(np.allclose(functionOutput1[fun][\"vector\"],functionOutput2[fun][\"vector\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eede9a89-bf16-432f-b686-822d7765ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final embedding json saved to: /home/pm/performance_modeling/per_model/IR/kernel_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ir2vec\n",
    "\n",
    "# 提取函数级嵌入中的 actualName 和 vector\n",
    "def convert_ll_to_kernel_embeddings(ll_file_path):\n",
    "    try:\n",
    "        initObj = ir2vec.initEmbedding(ll_file_path, \"fa\", \"p\")\n",
    "        function_vectors = ir2vec.getFunctionVectors(initObj)\n",
    "        \n",
    "        return function_vectors\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ll_file_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# 遍历文件夹收集所有 .ll 文件\n",
    "def collect_ll_files(root_dir):\n",
    "    ll_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".ll\"):\n",
    "                ll_files.append(os.path.join(dirpath, filename))\n",
    "    return ll_files\n",
    "\n",
    "# 保存为合并的 JSON 文件\n",
    "def save_embeddings_to_json(embedding_dict, output_json):\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(embedding_dict, f, indent=4)\n",
    "\n",
    "# 主程序\n",
    "def main(root_dir, output_json):\n",
    "    ll_files = collect_ll_files(root_dir)\n",
    "    ll_files\n",
    "    \n",
    "    merged_embeddings = {}\n",
    "\n",
    "    for ll_file in ll_files:\n",
    "        per_file_embedding = convert_ll_to_kernel_embeddings(ll_file)\n",
    "        merged_embeddings.update(per_file_embedding)\n",
    "\n",
    "    save_embeddings_to_json(merged_embeddings, output_json)\n",
    "    print(f\"Final embedding json saved to: {output_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = \"/home/pm/performance_modeling/per_model/IR\"\n",
    "    output_json = \"/home/pm/performance_modeling/per_model/IR/kernel_embeddings.json\"\n",
    "\n",
    "    main(root_dir, output_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cf7129f-a9bb-4dea-952f-30914b09be0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demangledName</th>\n",
       "      <th>actualName</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bicg_kernel1(int, int, float*, float*, float*)</th>\n",
       "      <td>bicg_kernel1(int, int, float*, float*, float*)</td>\n",
       "      <td>bicg_kernel1</td>\n",
       "      <td>[-3.3166319404484, -0.3058479281741822, -7.827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicg_kernel2(int, int, float*, float*, float*)</th>\n",
       "      <td>bicg_kernel2(int, int, float*, float*, float*)</td>\n",
       "      <td>bicg_kernel2</td>\n",
       "      <td>[-3.138313042353145, 0.17380281751279836, -5.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gramschmidt_kernel1(int, int, float*, float*, float*, int)</th>\n",
       "      <td>gramschmidt_kernel1(int, int, float*, float*, ...</td>\n",
       "      <td>gramschmidt_kernel1</td>\n",
       "      <td>[-3.2697097359338914, 0.30288596196578776, -7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gramschmidt_kernel2(int, int, float*, float*, float*, int)</th>\n",
       "      <td>gramschmidt_kernel2(int, int, float*, float*, ...</td>\n",
       "      <td>gramschmidt_kernel2</td>\n",
       "      <td>[-0.761856533029846, -0.48947391161610154, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gramschmidt_kernel3(int, int, float*, float*, float*, int)</th>\n",
       "      <td>gramschmidt_kernel3(int, int, float*, float*, ...</td>\n",
       "      <td>gramschmidt_kernel3</td>\n",
       "      <td>[-6.836813389998824, -1.778564275897646, -19.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atax_kernel1(int, int, float*, float*, float*)</th>\n",
       "      <td>atax_kernel1(int, int, float*, float*, float*)</td>\n",
       "      <td>atax_kernel1</td>\n",
       "      <td>[-3.138313042353145, 0.17380281751279836, -5.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atax_kernel2(int, int, float*, float*, float*)</th>\n",
       "      <td>atax_kernel2(int, int, float*, float*, float*)</td>\n",
       "      <td>atax_kernel2</td>\n",
       "      <td>[-3.3166319404484, -0.3058479281741822, -7.827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_kernel(int, int, float*, float*)</th>\n",
       "      <td>mean_kernel(int, int, float*, float*)</td>\n",
       "      <td>mean_kernel</td>\n",
       "      <td>[-2.3955802492185034, -1.7837196941175386, -7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covar_kernel(int, int, float*, float*)</th>\n",
       "      <td>covar_kernel(int, int, float*, float*)</td>\n",
       "      <td>covar_kernel</td>\n",
       "      <td>[-3.9002971837609803, -1.2205186085794038, -12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduce_kernel(int, int, float*, float*)</th>\n",
       "      <td>reduce_kernel(int, int, float*, float*)</td>\n",
       "      <td>reduce_kernel</td>\n",
       "      <td>[-1.1174373881408213, -0.9397099413303276, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_kernel(int, int, float*, float*)</th>\n",
       "      <td>corr_kernel(int, int, float*, float*)</td>\n",
       "      <td>corr_kernel</td>\n",
       "      <td>[-4.13777870987449, -1.6844962458317654, -13.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduce_kernel(int, int, float*, float*, float*)</th>\n",
       "      <td>reduce_kernel(int, int, float*, float*, float*)</td>\n",
       "      <td>reduce_kernel</td>\n",
       "      <td>[-1.035140804761741, -0.5501905484393979, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_kernel(int, int, float*, float*, float*)</th>\n",
       "      <td>std_kernel(int, int, float*, float*, float*)</td>\n",
       "      <td>std_kernel</td>\n",
       "      <td>[-2.2506097400748795, 2.4411576349029622, -6.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm2_kernel1(int, int, int, int, float, float, float*, float*, float*)</th>\n",
       "      <td>mm2_kernel1(int, int, int, int, float, float, ...</td>\n",
       "      <td>mm2_kernel1</td>\n",
       "      <td>[-4.376014108657989, -0.8832646128949169, -13....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm2_kernel2(int, int, int, int, float, float, float*, float*, float*)</th>\n",
       "      <td>mm2_kernel2(int, int, int, int, float, float, ...</td>\n",
       "      <td>mm2_kernel2</td>\n",
       "      <td>[-4.305735040097641, -1.518388815707739, -12.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesummv_kernel(int, float, float, float*, float*, float*, float*, float*)</th>\n",
       "      <td>gesummv_kernel(int, float, float, float*, floa...</td>\n",
       "      <td>gesummv_kernel</td>\n",
       "      <td>[-2.9024692502294784, 1.708198176513093, -3.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        demangledName  \\\n",
       "bicg_kernel1(int, int, float*, float*, float*)         bicg_kernel1(int, int, float*, float*, float*)   \n",
       "bicg_kernel2(int, int, float*, float*, float*)         bicg_kernel2(int, int, float*, float*, float*)   \n",
       "gramschmidt_kernel1(int, int, float*, float*, f...  gramschmidt_kernel1(int, int, float*, float*, ...   \n",
       "gramschmidt_kernel2(int, int, float*, float*, f...  gramschmidt_kernel2(int, int, float*, float*, ...   \n",
       "gramschmidt_kernel3(int, int, float*, float*, f...  gramschmidt_kernel3(int, int, float*, float*, ...   \n",
       "atax_kernel1(int, int, float*, float*, float*)         atax_kernel1(int, int, float*, float*, float*)   \n",
       "atax_kernel2(int, int, float*, float*, float*)         atax_kernel2(int, int, float*, float*, float*)   \n",
       "mean_kernel(int, int, float*, float*)                           mean_kernel(int, int, float*, float*)   \n",
       "covar_kernel(int, int, float*, float*)                         covar_kernel(int, int, float*, float*)   \n",
       "reduce_kernel(int, int, float*, float*)                       reduce_kernel(int, int, float*, float*)   \n",
       "corr_kernel(int, int, float*, float*)                           corr_kernel(int, int, float*, float*)   \n",
       "reduce_kernel(int, int, float*, float*, float*)       reduce_kernel(int, int, float*, float*, float*)   \n",
       "std_kernel(int, int, float*, float*, float*)             std_kernel(int, int, float*, float*, float*)   \n",
       "mm2_kernel1(int, int, int, int, float, float, f...  mm2_kernel1(int, int, int, int, float, float, ...   \n",
       "mm2_kernel2(int, int, int, int, float, float, f...  mm2_kernel2(int, int, int, int, float, float, ...   \n",
       "gesummv_kernel(int, float, float, float*, float...  gesummv_kernel(int, float, float, float*, floa...   \n",
       "\n",
       "                                                             actualName  \\\n",
       "bicg_kernel1(int, int, float*, float*, float*)             bicg_kernel1   \n",
       "bicg_kernel2(int, int, float*, float*, float*)             bicg_kernel2   \n",
       "gramschmidt_kernel1(int, int, float*, float*, f...  gramschmidt_kernel1   \n",
       "gramschmidt_kernel2(int, int, float*, float*, f...  gramschmidt_kernel2   \n",
       "gramschmidt_kernel3(int, int, float*, float*, f...  gramschmidt_kernel3   \n",
       "atax_kernel1(int, int, float*, float*, float*)             atax_kernel1   \n",
       "atax_kernel2(int, int, float*, float*, float*)             atax_kernel2   \n",
       "mean_kernel(int, int, float*, float*)                       mean_kernel   \n",
       "covar_kernel(int, int, float*, float*)                     covar_kernel   \n",
       "reduce_kernel(int, int, float*, float*)                   reduce_kernel   \n",
       "corr_kernel(int, int, float*, float*)                       corr_kernel   \n",
       "reduce_kernel(int, int, float*, float*, float*)           reduce_kernel   \n",
       "std_kernel(int, int, float*, float*, float*)                 std_kernel   \n",
       "mm2_kernel1(int, int, int, int, float, float, f...          mm2_kernel1   \n",
       "mm2_kernel2(int, int, int, int, float, float, f...          mm2_kernel2   \n",
       "gesummv_kernel(int, float, float, float*, float...       gesummv_kernel   \n",
       "\n",
       "                                                                                               vector  \n",
       "bicg_kernel1(int, int, float*, float*, float*)      [-3.3166319404484, -0.3058479281741822, -7.827...  \n",
       "bicg_kernel2(int, int, float*, float*, float*)      [-3.138313042353145, 0.17380281751279836, -5.3...  \n",
       "gramschmidt_kernel1(int, int, float*, float*, f...  [-3.2697097359338914, 0.30288596196578776, -7....  \n",
       "gramschmidt_kernel2(int, int, float*, float*, f...  [-0.761856533029846, -0.48947391161610154, -0....  \n",
       "gramschmidt_kernel3(int, int, float*, float*, f...  [-6.836813389998824, -1.778564275897646, -19.9...  \n",
       "atax_kernel1(int, int, float*, float*, float*)      [-3.138313042353145, 0.17380281751279836, -5.3...  \n",
       "atax_kernel2(int, int, float*, float*, float*)      [-3.3166319404484, -0.3058479281741822, -7.827...  \n",
       "mean_kernel(int, int, float*, float*)               [-2.3955802492185034, -1.7837196941175386, -7....  \n",
       "covar_kernel(int, int, float*, float*)              [-3.9002971837609803, -1.2205186085794038, -12...  \n",
       "reduce_kernel(int, int, float*, float*)             [-1.1174373881408213, -0.9397099413303276, -0....  \n",
       "corr_kernel(int, int, float*, float*)               [-4.13777870987449, -1.6844962458317654, -13.6...  \n",
       "reduce_kernel(int, int, float*, float*, float*)     [-1.035140804761741, -0.5501905484393979, -0.9...  \n",
       "std_kernel(int, int, float*, float*, float*)        [-2.2506097400748795, 2.4411576349029622, -6.0...  \n",
       "mm2_kernel1(int, int, int, int, float, float, f...  [-4.376014108657989, -0.8832646128949169, -13....  \n",
       "mm2_kernel2(int, int, int, int, float, float, f...  [-4.305735040097641, -1.518388815707739, -12.7...  \n",
       "gesummv_kernel(int, float, float, float*, float...  [-2.9024692502294784, 1.708198176513093, -3.36...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 JSON 文件\n",
    "json_file = \"/home/pm/performance_modeling/per_model/IR/kernel_embeddings.json\"  # 修改为你生成的 JSON 文件路径\n",
    "with open(json_file, 'r') as f:\n",
    "    embedding_dict = json.load(f)\n",
    "\n",
    "# 将嵌入数据加载到 pandas DataFrame 中并展示\n",
    "embedding_df = pd.DataFrame.from_dict(embedding_dict, orient='index')\n",
    "embedding_df  # 查看前几行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade9c905-4d39-47ae-867c-57880b39f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换成功，已保存至：/home/pm/performance_modeling/per_model/IR/kernel_embeddings_list.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 输入输出路径\n",
    "input_json_path = \"/home/pm/performance_modeling/per_model/IR/kernel_embeddings.json\"\n",
    "output_json_path = \"/home/pm/performance_modeling/per_model/IR/kernel_embeddings_list.json\"\n",
    "\n",
    "# 读取原始 JSON\n",
    "with open(input_json_path, 'r') as f:\n",
    "    embedding_dict = json.load(f)\n",
    "\n",
    "# 转换为列表形式\n",
    "embedding_list = [\n",
    "    {\"kernel_name\": name, \"embedding\": vector}\n",
    "    for name, vector in embedding_dict.items()\n",
    "]\n",
    "\n",
    "# 保存为新的 JSON 文件\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(embedding_list, f, indent=4)\n",
    "\n",
    "print(f\"转换成功，已保存至：{output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4818195-92f2-4dcf-ba44-d6c9804432d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_265225/901578559.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0membedding_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 将嵌入数据加载到 pandas DataFrame 中并展示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0membedding_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0membedding_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 查看前几行数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LS/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1896\u001b[0m         \u001b[0morient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m                 \u001b[0;31m# TODO speed up Series case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_from_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 JSON 文件\n",
    "json_file = \"/home/pm/performance_modeling/per_model/IR/kernel_embeddings_list.json\"  # 修改为你生成的 JSON 文件路径\n",
    "with open(json_file, 'r') as f:\n",
    "    embedding_dict = json.load(f)\n",
    "\n",
    "# 将嵌入数据加载到 pandas DataFrame 中并展示\n",
    "embedding_df = pd.DataFrame.from_dict(embedding_dict, orient='index')\n",
    "embedding_df.head()  # 查看前几行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1944e088-302a-4d18-96fd-ff07439e2526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换成功，已保存至：kernel_embeddings_list1.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 输入文件路径和输出文件路径\n",
    "input_json_path = \"kernel_embeddings_list.json\"  # 请修改为实际路径\n",
    "output_json_path = \"kernel_embeddings_list1.json\"  # 请修改为保存路径\n",
    "\n",
    "# 读取原始 JSON 文件\n",
    "with open(input_json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 转换 embedding 为横向存储的格式\n",
    "for item in data:\n",
    "    item['embedding'] = item['embedding']  # 确保嵌入是横向存储\n",
    "\n",
    "# 保存转换后的 JSON 文件\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"转换成功，已保存至：{output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d69d17fa-8752-4757-beb6-ff4ef2a173ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取成功，新文件保存到：kernel_embeddings_list2.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 输入输出路径\n",
    "input_json = \"kernel_embeddings_list.json\"     # 修改为你的输入文件路径\n",
    "output_json = \"kernel_embeddings_list2.json\"   # 修改为你想保存的新文件路径\n",
    "\n",
    "# 加载原始 JSON 数据\n",
    "with open(input_json, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 提取 actualName 和 vector，构造新结构\n",
    "new_data = []\n",
    "for item in data:\n",
    "    embedding_info = item.get(\"embedding\", {})\n",
    "    kernel_name = embedding_info.get(\"actualName\")\n",
    "    vector = embedding_info.get(\"vector\")\n",
    "    \n",
    "    if kernel_name and vector:\n",
    "        new_data.append({\n",
    "            \"kernel_name\": kernel_name,\n",
    "            \"embedding\": vector\n",
    "        })\n",
    "\n",
    "# 保存新的 JSON 文件\n",
    "with open(output_json, 'w') as f:\n",
    "    json.dump(new_data, f, indent=4)\n",
    "\n",
    "print(f\"提取成功，新文件保存到：{output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "081e0137-e5e1-4ba3-9d54-6f0ad82a5453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to /home/pm/performance_modeling/per_model/IR/all.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ir2vec\n",
    "\n",
    "# 定义一个函数将.ll文件转为嵌入表示\n",
    "def convert_ll_to_embedding(ll_file_path):\n",
    "    try:\n",
    "        # 调用 IR2Vec 转换命令（p模式）\n",
    "        initObj = ir2vec.initEmbedding(ll_file_path, \"fa\", \"p\")\n",
    "        function_vectors = ir2vec.getFunctionVectors(initObj)  # 获取函数级别的嵌入\n",
    "        return function_vectors\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ll_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 遍历文件夹收集所有 .ll 文件\n",
    "def collect_ll_files(root_dir):\n",
    "    ll_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".ll\"):\n",
    "                ll_files.append(os.path.join(dirpath, filename))\n",
    "    return ll_files\n",
    "\n",
    "# 保存结果到 JSON 文件\n",
    "def save_embeddings_to_json(embedding_dict, output_json):\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(embedding_dict, f, indent=4)\n",
    "\n",
    "# 主程序\n",
    "def main(root_dir, output_json):\n",
    "    ll_files = collect_ll_files(root_dir)  # 收集所有.ll文件\n",
    "    embedding_dict = {}\n",
    "\n",
    "    for ll_file in ll_files:\n",
    "        # 提取当前.ll文件的函数级嵌入\n",
    "        function_vectors = convert_ll_to_embedding(ll_file)\n",
    "        if function_vectors:\n",
    "            # 使用文件名（不包括路径）作为 key\n",
    "            file_name = os.path.basename(ll_file)\n",
    "            embedding_dict[file_name] = function_vectors  # 保存嵌入\n",
    "\n",
    "    # 保存结果到 JSON 文件\n",
    "    save_embeddings_to_json(embedding_dict, output_json)\n",
    "    print(f\"Embeddings saved to {output_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 指定根目录（包含.ll文件的根目录）和输出 JSON 文件路径\n",
    "    root_dir = \"/home/pm/performance_modeling/per_model/IR\"  # 请修改为实际路径\n",
    "    output_json = \"/home/pm/performance_modeling/per_model/IR/all.json\"  # 请修改为你想保存的文件路径\n",
    "\n",
    "    main(root_dir, output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d37a11e3-c6a1-479f-8581-3963ebd6b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs saved successfully to cfg.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pydot\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "def parse_dot_file_to_graph(file_path):\n",
    "    \"\"\"\n",
    "    解析 .dot 文件，将其转换为节点、边和 kernel_name 的形式。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        graphs = pydot.graph_from_dot_file(file_path)\n",
    "        if not graphs:\n",
    "            print(f\"No graphs found in file: {file_path}\")\n",
    "            return None, None, None\n",
    "\n",
    "        graph = graphs[0]\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        kernel_name = None\n",
    "\n",
    "        # 提取 label 信息作为 kernel-name\n",
    "        if \"label\" in graph.obj_dict[\"attributes\"]:\n",
    "            label = graph.obj_dict[\"attributes\"][\"label\"]\n",
    "            match = re.search(r\"CFG for '([^']+)' function\", label)\n",
    "            if match:\n",
    "                kernel_name = match.group(1)\n",
    "\n",
    "        # 提取节点\n",
    "        for node in graph.get_nodes():\n",
    "            node_name = node.get_name()\n",
    "            if node_name not in ('node', 'graph'):\n",
    "                # 清洗节点名称（移除冒号及后面的内容）\n",
    "                cleaned_name = node_name.split(\":\")[0].strip('\"')\n",
    "                nodes.append(cleaned_name)\n",
    "\n",
    "        # 提取边\n",
    "        for edge in graph.get_edges():\n",
    "            source = edge.get_source().split(\":\")[0].strip('\"')  # 清洗源节点名称\n",
    "            destination = edge.get_destination().split(\":\")[0].strip('\"')  # 清洗目标节点名称\n",
    "            edges.append((source, destination))\n",
    "\n",
    "        return nodes, edges, kernel_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing .dot file: {file_path}, Error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def process_all_dot_files_in_folder(root_folder):\n",
    "    \"\"\"\n",
    "    遍历文件夹及其子文件夹，提取所有 .dot 文件的节点、边和 kernel-name。\n",
    "    \"\"\"\n",
    "    all_graphs = []\n",
    "\n",
    "    # 遍历文件夹及子文件夹\n",
    "    for root, _, files in os.walk(root_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.dot'):  # 筛选 .dot 文件\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                nodes, edges, kernel_name = parse_dot_file_to_graph(file_path)\n",
    "                if nodes is not None and edges is not None:\n",
    "                    all_graphs.append({\n",
    "                        \"kernel_name\": kernel_name,\n",
    "                        \"nodes\": nodes,\n",
    "                        \"edges\": edges\n",
    "                    })\n",
    "\n",
    "    return all_graphs\n",
    "\n",
    "def save_graphs_to_json(all_graphs, output_path):\n",
    "    \"\"\"\n",
    "    将提取的图数据保存为 JSON 文件。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 保存为 JSON 文件\n",
    "        with open(output_path, \"w\") as f:\n",
    "            for graph in all_graphs:\n",
    "                f.write(json.dumps(graph) + \"\\n\")\n",
    "        print(f\"Graphs saved successfully to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving graphs to JSON: {e}\")\n",
    "\n",
    "# 示例调用\n",
    "root_folder = \"/home/pm/performance_modeling/per_model/cfg\"  # 替换为你的根文件夹路径\n",
    "all_graphs = process_all_dot_files_in_folder(root_folder)\n",
    "output_path = \"cfg.json\"  # 保存的文件名\n",
    "# 将图数据保存为 JSON 文件\n",
    "save_graphs_to_json(all_graphs, output_path)\n",
    "\n",
    "all_graphs = pd.DataFrame(all_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0109220-1c59-40d9-95a2-81e5de43c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 4.144740104675293\n",
      "Epoch 21/50, Loss: 0.7865074872970581\n",
      "Epoch 41/50, Loss: 0.81842041015625\n",
      "Epoch 1/50, Loss: 1.0303688049316406\n",
      "Epoch 21/50, Loss: 0.6393777132034302\n",
      "Epoch 41/50, Loss: 0.8087062239646912\n",
      "Epoch 1/50, Loss: 1.1760227680206299\n",
      "Epoch 21/50, Loss: 0.8304158449172974\n",
      "Epoch 41/50, Loss: 0.6255468130111694\n",
      "Epoch 1/50, Loss: 0.9994017481803894\n",
      "Epoch 21/50, Loss: 0.6517046093940735\n",
      "Epoch 41/50, Loss: 0.8478209972381592\n",
      "Epoch 1/50, Loss: 0.7974346876144409\n",
      "Epoch 21/50, Loss: 0.9830612540245056\n",
      "Epoch 41/50, Loss: 0.7455861568450928\n",
      "Epoch 1/50, Loss: 0.6854866743087769\n",
      "Epoch 21/50, Loss: 0.7194951176643372\n",
      "Epoch 41/50, Loss: 0.7070575952529907\n",
      "Epoch 1/50, Loss: 0.7315657734870911\n",
      "Epoch 21/50, Loss: 0.7328222393989563\n",
      "Epoch 41/50, Loss: 0.6581647396087646\n",
      "Epoch 1/50, Loss: 0.7818625569343567\n",
      "Epoch 21/50, Loss: 0.6703646183013916\n",
      "Epoch 41/50, Loss: 0.5965538620948792\n",
      "Epoch 1/50, Loss: 0.7874701619148254\n",
      "Epoch 21/50, Loss: 0.6530857682228088\n",
      "Epoch 41/50, Loss: 0.7225390672683716\n",
      "Epoch 1/50, Loss: 0.8403791189193726\n",
      "Epoch 21/50, Loss: 0.9575437903404236\n",
      "Epoch 41/50, Loss: 0.6338639259338379\n",
      "Epoch 1/50, Loss: 0.7257643342018127\n",
      "Epoch 21/50, Loss: 0.7092517614364624\n",
      "Epoch 41/50, Loss: 0.7673152089118958\n",
      "Epoch 1/50, Loss: 0.6376845240592957\n",
      "Epoch 21/50, Loss: 0.6601791977882385\n",
      "Epoch 41/50, Loss: 0.6854968667030334\n",
      "Epoch 1/50, Loss: 0.6542006731033325\n",
      "Epoch 21/50, Loss: 0.6340026259422302\n",
      "Epoch 41/50, Loss: 0.8227847814559937\n",
      "Epoch 1/50, Loss: 0.8250725865364075\n",
      "Epoch 21/50, Loss: 1.0036100149154663\n",
      "Epoch 41/50, Loss: 0.6240447163581848\n",
      "Vectorized graphs with embeddings saved successfully to cfg_GAT_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "import pydot\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "# 加载图数据的函数\n",
    "def load_graph_data(json_file):\n",
    "    \"\"\"\n",
    "    加载包含节点、边和程序名的 JSON 文件。\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]  # 读取每行JSON数据\n",
    "    return data\n",
    "\n",
    "# 解析 .dot 文件并提取节点、边和 kernel_name\n",
    "def parse_dot_file_to_graph(file_path):\n",
    "    \"\"\"\n",
    "    解析 .dot 文件，将其转换为节点、边和 kernel_name 的形式。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        graphs = pydot.graph_from_dot_file(file_path)\n",
    "        if not graphs:\n",
    "            print(f\"No graphs found in file: {file_path}\")\n",
    "            return None, None, None\n",
    "\n",
    "        graph = graphs[0]\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        kernel_name = None\n",
    "\n",
    "        # 提取 label 信息作为 kernel_name\n",
    "        if \"label\" in graph.obj_dict[\"attributes\"]:\n",
    "            label = graph.obj_dict[\"attributes\"][\"label\"]\n",
    "            match = re.search(r\"CFG for '([^']+)' function\", label)\n",
    "            if match:\n",
    "                kernel_name = match.group(1)\n",
    "\n",
    "        # 提取节点\n",
    "        for node in graph.get_nodes():\n",
    "            node_name = node.get_name()\n",
    "            if node_name not in ('node', 'graph'):\n",
    "                # 清洗节点名称（移除冒号及后面的内容）\n",
    "                cleaned_name = node_name.split(\":\")[0].strip('\"')\n",
    "                nodes.append(cleaned_name)\n",
    "\n",
    "        # 提取边\n",
    "        for edge in graph.get_edges():\n",
    "            source = edge.get_source().split(\":\")[0].strip('\"')  # 清洗源节点名称\n",
    "            destination = edge.get_destination().split(\":\")[0].strip('\"')  # 清洗目标节点名称\n",
    "            edges.append((source, destination))\n",
    "\n",
    "        return nodes, edges, kernel_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing .dot file: {file_path}, Error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "# 构建GAT模型\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_heads=4):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, out_channels, heads=num_heads)\n",
    "        self.gat2 = GATConv(out_channels * num_heads, out_channels, heads=num_heads)\n",
    "        self.linear = torch.nn.Linear(out_channels * num_heads, 1)  # 用于节点分类\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        return x  # 返回节点嵌入\n",
    "\n",
    "\n",
    "# 转换JSON数据为PyTorch Geometric格式\n",
    "def convert_to_pyg_data(graph):\n",
    "    nodes = graph['nodes']\n",
    "    edges = graph['edges']\n",
    "\n",
    "    # 为节点创建一些自定义特征，例如使用节点的度数或其他信息\n",
    "    node_features = torch.randn(len(nodes), 32)  # 假设每个节点有32维特征\n",
    "    \n",
    "    # 可以考虑使用度数信息作为节点的额外特征\n",
    "    node_degrees = torch.tensor([len([e for e in edges if node in e]) for node in nodes], dtype=torch.float).view(-1, 1)\n",
    "    node_features = torch.cat([node_features, node_degrees], dim=1)  # 合并随机初始化特征和度数特征\n",
    "\n",
    "    # 创建边索引\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "    edge_index = torch.tensor([[node_index[src], node_index[dst]] for src, dst in edges], dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # 返回PyTorch Geometric格式的数据\n",
    "    data = Data(x=node_features, edge_index=edge_index)\n",
    "    return data, node_index, nodes\n",
    "\n",
    "\n",
    "# 提取嵌入\n",
    "def extract_embeddings(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_embeddings = model(data)\n",
    "    return node_embeddings\n",
    "\n",
    "\n",
    "# 将生成的嵌入添加到图数据中\n",
    "def add_embeddings_to_graph(graph, node_embeddings, edge_embeddings=None):\n",
    "    # 将节点嵌入和边嵌入添加到图数据中\n",
    "    graph[\"node_embeddings\"] = node_embeddings.tolist()\n",
    "    if edge_embeddings is not None:\n",
    "        graph[\"edge_embeddings\"] = edge_embeddings.tolist()\n",
    "    return graph\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train_gat_model(model, data, epochs=200):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # 假设节点分类任务\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "\n",
    "        # 假设目标是每个节点的分类标签，这里模拟一个目标\n",
    "        target = torch.randint(0, 2, (out.size(0),))  # 例如二分类任务\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "# 主程序\n",
    "json_file = 'cfg.json'  # 替换为实际路径\n",
    "output_path = 'cfg_GAT_embeddings.json'  # 保存嵌入结果的路径\n",
    "\n",
    "# 加载 CFG 图数据\n",
    "graph_data = load_graph_data(json_file)\n",
    "\n",
    "# 构建GAT模型\n",
    "model = GAT(in_channels=33, out_channels=16)  # 假设每个节点有33维输入特征，16维输出特征\n",
    "\n",
    "vectorized_graphs = []\n",
    "for graph in graph_data:\n",
    "    # 转换为PyTorch Geometric格式\n",
    "    data, node_index, nodes = convert_to_pyg_data(graph)\n",
    "\n",
    "    # 训练模型并获取节点嵌入\n",
    "    train_gat_model(model, data, epochs=50)  # 可以适当减少epoch次数以加速训练\n",
    "    node_embeddings = extract_embeddings(model, data)\n",
    "\n",
    "    # 将嵌入添加回图数据\n",
    "    updated_graph = add_embeddings_to_graph(graph, node_embeddings)\n",
    "\n",
    "    # 将处理后的图数据添加到列表中\n",
    "    vectorized_graphs.append(updated_graph)\n",
    "\n",
    "# 将向量化后的图数据保存为 JSON 文件\n",
    "with open(output_path, \"w\") as f:\n",
    "    for graph in vectorized_graphs:\n",
    "        f.write(json.dumps(graph) + \"\\n\")\n",
    "\n",
    "print(f\"Vectorized graphs with embeddings saved successfully to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "470a2d8c-2da0-4c41-ac7f-a817a1afa7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 CFG graphs from cfg.json\n",
      "Vectorized graphs saved successfully to cfg_embedding.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def load_cfg_json(file_path):\n",
    "    \"\"\"\n",
    "    加载 CFG 图数据 JSON 文件。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            cfg_data = [json.loads(line) for line in f]\n",
    "        print(f\"Loaded {len(cfg_data)} CFG graphs from {file_path}\")\n",
    "        return cfg_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def encode_nodes(nodes, method=\"word2vec\"):\n",
    "    \"\"\"\n",
    "    对节点进行编码，可以选择 Word2Vec。\n",
    "    \"\"\"\n",
    "    if method == \"word2vec\":\n",
    "        # 使用 Word2Vec 对节点文本进行嵌入\n",
    "        model = Word2Vec(sentences=[[n] for n in nodes], vector_size=32, window=5, min_count=1, workers=4)\n",
    "        node_embeddings = np.array([model.wv[node] for node in nodes])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported encoding method: {method}\")\n",
    "\n",
    "    return node_embeddings\n",
    "\n",
    "\n",
    "def encode_edges(edges, nodes):\n",
    "    \"\"\"\n",
    "    对边进行编码，生成边索引。\n",
    "    \"\"\"\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "    edge_index = []\n",
    "    for edge in edges:\n",
    "        source, destination = edge\n",
    "        if source in node_index and destination in node_index:\n",
    "            edge_index.append([node_index[source], node_index[destination]])\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t()  # 转置为 PyTorch 的 [2, num_edges] 格式\n",
    "\n",
    "\n",
    "def vectorize_cfg_graphs(cfg_data):\n",
    "    \"\"\"\n",
    "    对 CFG 图数据进行向量化，并返回更新后的图数据列表。\n",
    "    \"\"\"\n",
    "    vectorized_graphs = []\n",
    "\n",
    "    for graph in cfg_data:\n",
    "        nodes = graph[\"nodes\"]\n",
    "        edges = graph[\"edges\"]\n",
    "\n",
    "        # 对节点进行向量化\n",
    "        node_embeddings = encode_nodes(nodes, method=\"word2vec\")\n",
    "\n",
    "        # 对边进行向量化，生成边索引\n",
    "        edge_index = encode_edges(edges, nodes)\n",
    "\n",
    "        # 将结果保存为向量化的图\n",
    "        vectorized_graphs.append({\n",
    "            \"kernel_name\": graph[\"kernel_name\"],\n",
    "            \"nodes\": graph[\"nodes\"],\n",
    "            \"edges\": graph[\"edges\"],\n",
    "            \"node_embeddings\": node_embeddings.tolist(),  # 保存更新后的节点嵌入\n",
    "            \"edge_index\": edge_index.tolist()  # 保存边索引\n",
    "        })\n",
    "\n",
    "    return vectorized_graphs\n",
    "\n",
    "\n",
    "def save_vectorized_graphs(vectorized_graphs, output_path):\n",
    "    \"\"\"\n",
    "    将向量化的 CFG 图数据保存为 JSON 文件。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            for graph in vectorized_graphs:\n",
    "                f.write(json.dumps(graph) + \"\\n\")\n",
    "        print(f\"Vectorized graphs saved successfully to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving vectorized graphs: {e}\")\n",
    "\n",
    "\n",
    "# 主程序\n",
    "cfg_file_path = \"cfg.json\"  # 替换为你的文件路径\n",
    "output_path = \"cfg_embedding.json\"  # 保存向量化结果的路径\n",
    "\n",
    "# 加载 CFG 图数据\n",
    "cfg_data = load_cfg_json(cfg_file_path)\n",
    "\n",
    "# 对 CFG 图数据进行向量化\n",
    "vectorized_graphs = vectorize_cfg_graphs(cfg_data)\n",
    "\n",
    "# 保存向量化后的 CFG 图数据\n",
    "save_vectorized_graphs(vectorized_graphs, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "093dda1c-4410-4cda-b2c3-67ec12f8841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/pm/codebert-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading code data...\n",
      "Loading embedding model: /home/pm/codebert-base...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492136af5dc746088882075098b4c97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c0f57b81c04aa797d5ea0fb551bbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bef22479a9440ab63183eac14f81c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badfb11be9cb4fc59f11e6b34e60bba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d61d9e06dbf44b0a68fb6c9952650ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a761cc13abbb4387b3a34130829ce914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533f9256edb04a1f95da0564cea3781d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca3871197be45dea4733e6c2741d919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e5c1ce0d814624be5d332ed3ed9b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888e234caeae46dbad0de67378469de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e63952b54a4e2e8003f49967169d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deabc387655144278799188f42a97bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78344b1a9384cb6a47ee7d951ef3c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19893b9f27714a0d9009acfa2377f095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743236affeef4e13a65c1fe166c63937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ced48d7aff1429789eae9c0b602b327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3802c78b693d4c6b83945305fd693e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to code_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def generate_embeddings(data, model_name=\"/home/pm/codebert-base\"):\n",
    "    \"\"\"\n",
    "    为每个代码生成嵌入。\n",
    "    :param data: 包含 source_code 的 DataFrame\n",
    "    :param model_name: 预训练模型的名称\n",
    "    :return: 带有嵌入的 DataFrame\n",
    "    \"\"\"\n",
    "    # 加载预训练模型\n",
    "    print(f\"Loading embedding model: {model_name}...\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # 生成嵌入\n",
    "    print(\"Generating embeddings...\")\n",
    "    data[\"embedding\"] = data[\"source_code\"].apply(lambda code: model.encode(code, show_progress_bar=True).tolist())\n",
    "\n",
    "    return data\n",
    "\n",
    "def prepare_code_embeddings(input_file, output_file=\"code_embeddings.json\"):\n",
    "    \"\"\"\n",
    "    加载代码，生成嵌入，并将结果保存为 JSON 文件。\n",
    "    :param input_file: 输入的 JSON 文件路径\n",
    "    :param output_file: 输出的 JSON 文件路径\n",
    "    \"\"\"\n",
    "    # 加载代码数据\n",
    "    print(\"Loading code data...\")\n",
    "    \n",
    "    # 使用读取器手动逐行加载JSON\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f if line.strip()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 将数据转换为 DataFrame\n",
    "    code_data_df = pd.DataFrame(data)\n",
    "    \n",
    "    # 如果没有数据，提示并退出\n",
    "    if code_data_df.empty:\n",
    "        print(\"No code data found in the file. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # 生成代码嵌入\n",
    "    embedded_data = generate_embeddings(code_data_df)\n",
    "\n",
    "    # 保存为 JSON 文件\n",
    "    embedded_data.to_json(output_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "    print(f\"Embeddings saved to {output_file}\")\n",
    "\n",
    "# 输入输出文件路径\n",
    "input_file = \"/home/pm/performance_modeling/per_model/new_process/code.json\"  # 替换为你的代码文件路径\n",
    "output_file = \"code_embeddings.json\"  # 输出文件路径\n",
    "\n",
    "prepare_code_embeddings(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e3c2686-a536-4d28-a04b-071dbc109b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"kernel_name\": \"mm2_kernel1\",\"source_code\": \"__global__ void mm2_kernel1(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *A, DATA_TYPE *B)\\\\n{\\\\n\\\\tint j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\tint i = blockIdx.y * blockDim.y + threadIdx.y;\\\\n\\\\n\\\\tif ((i < _PB_NI) && (j < _PB_NJ))\\\\n\\\\t{ \\\\n\\\\t\\\\ttmp[i * NJ + j] = 0;\\\\n\\\\t\\\\tint k;\\\\n\\\\t\\\\tfor (k = 0; k < _PB_NK; k++)\\\\n\\\\t\\\\t{\\\\n\\\\t\\\\t\\\\ttmp[i * NJ + j] += alpha * A[i * NK + k] * B[k * NJ + j];\\\\n\\\\t\\\\t}\\\\n\\\\t}\\\\n}\"},\\n', '{\"kernel_name\": \"mm2_kernel2\",\"source_code\": \"__global__ void mm2_kernel2(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *C, DATA_TYPE *D)\\\\n{\\\\n\\\\tint j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\tint i = blockIdx.y * blockDim.y + threadIdx.y;\\\\n\\\\n\\\\tif ((i < _PB_NI) && (j < _PB_NL))\\\\n\\\\t{ \\\\n\\\\t\\\\tD[i * NL + j] *= beta;\\\\n\\\\t\\\\tint k;\\\\n\\\\t\\\\tfor (k = 0; k < _PB_NJ; k++)\\\\n\\\\t\\\\t{\\\\n\\\\t\\\\t\\\\tD[i * NL + j] += tmp[i * NJ + k] * C[k * NL + j];\\\\n\\\\t\\\\t}\\\\n\\\\t}\\\\n}\"},\\n', '{\"kernel_name\": \"atax_kernel1\",\"source_code\": \"__global__ void atax_kernel1(int nx, int ny, DATA_TYPE *A, DATA_TYPE *x, DATA_TYPE *tmp)\\\\n{\\\\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n  if (i < _PB_NX)\\\\n  {\\\\n    tmp[i] = 0;\\\\n    int j;\\\\n    for(j=0; j < _PB_NY; j++)\\\\n    {\\\\n      tmp[i] += A[i*NY+j] * x[j];\\\\n    }\\\\n  }\\\\n}\"},\\n', '{\"kernel_name\": \"atax_kernel2\",\"source_code\": \"__global__ void atax_kernel2(int nx, int ny, DATA_TYPE *A, DATA_TYPE *y, DATA_TYPE *tmp)\\\\n{\\\\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n  \\\\n  if (j < _PB_NY)\\\\n  {\\\\n    y[j] = 0;\\\\n    int i;\\\\n    for(i=0; i < _PB_NX; i++)\\\\n    {\\\\n      y[j] += A[i*NY+j] * tmp[i];\\\\n    }\\\\n  }\\\\n}\"},\\n', '{\"kernel_name\": \"bicg_kernel1\",\"source_code\": \"__global__ void bicg_kernel1(int nx, int ny, DATA_TYPE *A, DATA_TYPE *r, DATA_TYPE *s)\\\\n{\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    \\\\n    if (j < _PB_NY)\\\\n    {\\\\n        s[j] = 0.0f;\\\\n\\\\n        int i;\\\\n        for(i = 0; i < _PB_NX; i++)\\\\n        {\\\\n            s[j] += r[i] * A[i * NY + j];\\\\n        }\\\\n    }    \\\\n}\"},\\n', '{\"kernel_name\": \"bicg_kernel1\",\"source_code\": \"__global__ void bicg_kernel2(int nx, int ny, DATA_TYPE *A, DATA_TYPE *p, DATA_TYPE *q)\\\\n{\\\\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    \\\\n    if (i < _PB_NX)\\\\n    {\\\\n        q[i] = 0.0f;\\\\n\\\\n        int j;\\\\n        for(j=0; j < _PB_NY; j++)\\\\n        {\\\\n            q[i] += A[i * NY + j] * p[j];\\\\n        }\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"corr_mean_kernel\",\"source_code\": \"__global__ void mean_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *data)\\\\n{\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n    if (j < _PB_M)\\\\n    {\\\\n        mean[j] = 0.0;\\\\n\\\\n        int i;\\\\n        for(i=0; i < _PB_N; i++)\\\\n        {\\\\n            mean[j] += data[i*M + j];\\\\n        }\\\\n\\\\n        mean[j] /= (DATA_TYPE)FLOAT_N;\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"corr_std_kernel\",\"source_code\": \"__global__ void std_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *std, DATA_TYPE *data)\\\\n{\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n    if (j < _PB_M)\\\\n    {\\\\n        std[j] = 0.0;\\\\n\\\\n        int i;\\\\n        for(i = 0; i < _PB_N; i++)\\\\n        {\\\\n            std[j] += (data[i*M + j] - mean[j]) * (data[i*M + j] - mean[j]);\\\\n        }\\\\n        std[j] /= (FLOAT_N);\\\\n        std[j] = sqrt(std[j]);\\\\n        if(std[j] <= EPS) \\\\n        {\\\\n            std[j] = 1.0;\\\\n        }\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"corr_reduce_kernel\",\"source_code\": \"__global__ void reduce_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *std, DATA_TYPE *data) {\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    int i = blockIdx.y * blockDim.y + threadIdx.y;\\\\n    if ((i < _PB_N) && (j < _PB_M)) {\\\\n        data[i*M + j] -= mean[j];\\\\n        data[i*M + j] /= (sqrt(FLOAT_N) * std[j]);\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"corr_kernel\",\"source_code\": \"__global__ void corr_kernel(int m, int n, DATA_TYPE *symmat, DATA_TYPE *data)\\\\n{\\\\n    int j1 = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n    int i, j2;\\\\n    if (j1 < (_PB_M-1))\\\\n    {\\\\n        symmat[j1*M + j1] = 1.0;\\\\n\\\\n        for (j2 = (j1 + 1); j2 < _PB_M; j2++)\\\\n        {\\\\n            symmat[j1*M + j2] = 0.0;\\\\n\\\\n            for(i = 0; i < _PB_N; i++)\\\\n            {\\\\n                symmat[j1*M + j2] += data[i*M + j1] * data[i*M + j2];\\\\n            }\\\\n            symmat[j2*M + j1] = symmat[j1*M + j2];\\\\n        }\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"covar_mean_kernel\",\"source_code\": \"__global__ void mean_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *data)\\\\n{\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n    if (j < _PB_M)\\\\n    {\\\\n        mean[j] = 0.0;\\\\n\\\\n        int i;\\\\n        for(i = 0; i < _PB_N; i++)\\\\n        {\\\\n            mean[j] += data[i * M + j];\\\\n        }\\\\n        mean[j] /= (DATA_TYPE)FLOAT_N;\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"covar_reduce_kernel\",\"source_code\": \"__global__ void reduce_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *data)\\\\n{\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    int i = blockIdx.y * blockDim.y + threadIdx.y;\\\\n    \\\\n    if ((i < _PB_N) && (j < _PB_M))\\\\n    {\\\\n        data[i * M + j] -= mean[j]; \\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"covar_kernel\",\"source_code\": \"__global__ void covar_kernel(int m, int n, DATA_TYPE *symmat, DATA_TYPE *data)\\\\n{\\\\n    int j1 = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    int i, j2;\\\\n\\\\n    if (j1 < _PB_M)\\\\n    {\\\\n        for (j2 = j1; j2 < _PB_M; j2++)\\\\n        {\\\\n            symmat[j1*M + j2] = 0.0;\\\\n            for(i = 0; i < _PB_N; i++)\\\\n            {\\\\n                symmat[j1 * M + j2] += data[i * M + j1] * data[i * M + j2];\\\\n            }\\\\n            symmat[j2 * M + j1] = symmat[j1 * M + j2];\\\\n        }\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"gesummv_kernel\",\"source_code\": \"__global__ void gesummv_kernel(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* tmp, DATA_TYPE* x, DATA_TYPE* y)\\\\n{\\\\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n    if (i < _PB_N)\\\\n    {\\\\n        int j;\\\\n        for(j = 0; j < _PB_N; j++)\\\\n        {   \\\\n            tmp[i] += A[i * N + j] * x[j];\\\\n            y[i] += B[i * N + j] * x[j];\\\\n        }\\\\n        y[i] = alpha * tmp[i] + beta  * y[i];\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"gramschmidt_kernel1\",\"source_code\": \"__global__ void gramschmidt_kernel1(int ni, int nj, DATA_TYPE *a, DATA_TYPE *r, DATA_TYPE *q, int k)\\\\n{\\\\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\n    if(tid==0)\\\\n    {\\\\n        DATA_TYPE nrm = 0.0;\\\\n        int i;\\\\n        for (i = 0; i < _PB_NI; i++)\\\\n        {\\\\n            nrm += a[i * NJ + k] * a[i * NJ + k];\\\\n        }\\\\n        r[k * NJ + k] = sqrt(nrm);\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"gramschmidt_kernel2\",\"source_code\": \"__global__ void gramschmidt_kernel2(int ni, int nj, DATA_TYPE *a, DATA_TYPE *r, DATA_TYPE *q, int k) {\\\\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    if (i < _PB_NI) {\\\\n        q[i * NJ + k] = a[i * NJ + k] / r[k * NJ + k];\\\\n    }\\\\n}\"},\\n', '{\"kernel_name\": \"gramschmidt_kernel3\",\"source_code\": \"__global__ void gramschmidt_kernel3(int ni, int nj, DATA_TYPE *a, DATA_TYPE *r, DATA_TYPE *q, int k) {\\\\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n    if ((j > k) && (j < _PB_NJ)) {\\\\n        r[k*NJ + j] = 0.0;\\\\n        int i;\\\\n        for (i = 0; i < _PB_NI; i++) {\\\\n            r[k*NJ + j] += q[i*NJ + k] * a[i*NJ + j];\\\\n        }\\\\n        for (i = 0; i < _PB_NI; i++) {\\\\n            a[i*NJ + j] -= q[i*NJ + k] * r[k*NJ + j];\\\\n        }\\\\n    }\\\\n}\"}']\n",
      "['{\"kernel_name\": \"mm2_kernel1\",\"source_code\": \"__global__ void mm2_kernel1(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *A, DATA_TYPE *B)\\\\n{\\\\n\\\\tint j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\tint i = blockIdx.y * blockDim.y + threadIdx.y;\\\\n\\\\n\\\\tif ((i < _PB_NI) && (j < _PB_NJ))\\\\n\\\\t{ \\\\n\\\\t\\\\ttmp[i * NJ + j] = 0;\\\\n\\\\t\\\\tint k;\\\\n\\\\t\\\\tfor (k = 0; k < _PB_NK; k++)\\\\n\\\\t\\\\t{\\\\n\\\\t\\\\t\\\\ttmp[i * NJ + j] += alpha * A[i * NK + k] * B[k * NJ + j];\\\\n\\\\t\\\\t}\\\\n\\\\t}\\\\n}\"},\\n', '{\"kernel_name\": \"mm2_kernel2\",\"source_code\": \"__global__ void mm2_kernel2(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *C, DATA_TYPE *D)\\\\n{\\\\n\\\\tint j = blockIdx.x * blockDim.x + threadIdx.x;\\\\n\\\\tint i = blockIdx.y * blockDim.y + threadIdx.y;\\\\n\\\\n\\\\tif ((i < _PB_NI) && (j < _PB_NL))\\\\n\\\\t{ \\\\n\\\\t\\\\tD[i * NL + j] *= beta;\\\\n\\\\t\\\\tint k;\\\\n\\\\t\\\\tfor (k = 0; k < _PB_NJ; k++)\\\\n\\\\t\\\\t{\\\\n\\\\t\\\\t\\\\tD[i * NL + j] += tmp[i * NJ + k] * C[k * NL + j];\\\\n\\\\t\\\\t}\\\\n\\\\t}\\\\n}\"},\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('/home/pm/performance_modeling/per_model/new_process/code.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(lines)\n",
    "    print(lines[:2])  # 打印前5行以检查是否有格式问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c92fe199-b059-42b3-863e-7e1a0db66d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to extracted_code.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_kernel_source_code(input_file, output_file):\n",
    "    \"\"\"\n",
    "    从输入的 code.json 文件中提取 'kernel_name' 和 'source_code' 字段，\n",
    "    并生成一个新的 JSON 文件。\n",
    "    \n",
    "    :param input_file: 原始 JSON 文件路径\n",
    "    :param output_file: 输出的新 JSON 文件路径\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 打开并读取原始 JSON 文件\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = json.load(f)  # 读取整个 JSON 文件\n",
    "        \n",
    "        # 创建一个新列表来存储提取的数据\n",
    "        extracted_data = []\n",
    "        \n",
    "        # 遍历 JSON 数据并提取所需字段\n",
    "        for entry in data:\n",
    "            if 'kernel_name' in entry and 'source_code' in entry:\n",
    "                extracted_data.append({\n",
    "                    'kernel_name': entry['kernel_name'],\n",
    "                    'source_code': entry['source_code']\n",
    "                })\n",
    "        \n",
    "        # 将提取的数据写入新的 JSON 文件\n",
    "        with open(output_file, 'w') as f_out:\n",
    "            json.dump(extracted_data, f_out, indent=2)  \n",
    "            \n",
    "        print(f\"Extracted data saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "# 调用函数，替换为你的实际文件路径\n",
    "input_file = '/home/pm/performance_modeling/per_model/new_process/code.json'  # 替换为你的输入文件路径\n",
    "output_file = 'extracted_code.json'  # 替换为你想保存的输出文件路径\n",
    "\n",
    "extract_kernel_source_code(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cca86c-21b0-44d6-a087-4bb458acb4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存为 /home/pm/performance_modeling/per_model/new_process/reformatted_kernels.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 加载 JSON 数据\n",
    "with open(\"/home/pm/performance_modeling/per_model/new_process/ir_embedding.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 重新格式化数据，将每个 embedding 合并为一个数组\n",
    "reformatted_data = []\n",
    "for item in data:\n",
    "    row = {\n",
    "        \"kernel_name\": item[\"kernel_name\"],\n",
    "        \"embedding\": f\"[{', '.join(map(str, item['embedding']))}]\"\n",
    "    }\n",
    "    reformatted_data.append(row)\n",
    "\n",
    "# 创建 DataFrame\n",
    "reformatted_df = pd.DataFrame(reformatted_data)\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "output_path = \"/home/pm/performance_modeling/per_model/new_process/reformatted_kernels.csv\"\n",
    "reformatted_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"文件已保存为 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4991429e-7c12-46cb-9956-47937f28b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved to: /home/pm/performance_modeling/per_model/new_process/reformatted_kernels.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_merge_csv(file1, output_json):\n",
    "    # 1. 加载两个CSV文件\n",
    "    df1 = pd.read_csv(file1)\n",
    "\n",
    "    # 5. 将最终的CSV数据转换为JSON文件\n",
    "    df1.to_json(output_json, orient=\"records\", lines=True)\n",
    "    print(f\"JSON file saved to: {output_json}\")\n",
    "    \n",
    "# 主程序调用\n",
    "file1 = '/home/pm/performance_modeling/per_model/new_process/reformatted_kernels.csv'  # 请替换为实际的CSV文件路径\n",
    "\n",
    "output_json = '/home/pm/performance_modeling/per_model/new_process/reformatted_kernels.json'  # 合并后的JSON输出路径\n",
    "\n",
    "load_and_merge_csv(file1, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e22f2-ffb9-463f-9652-6d0da0e79d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
