; ModuleID = '../data/hip_kernels/740/144/main.cu'
source_filename = "../data/hip_kernels/740/144/main.cu"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

; Function Attrs: argmemonly mustprogress nofree norecurse nosync nounwind
define protected amdgpu_kernel void @_Z18executeFourthLayerPfS_S_(float addrspace(1)* nocapture readonly %0, float addrspace(1)* nocapture readonly %1, float addrspace(1)* nocapture writeonly %2) local_unnamed_addr #0 {
  %4 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %5 = mul nsw i32 %4, 101
  %6 = sext i32 %5 to i64
  %7 = getelementptr inbounds float, float addrspace(1)* %1, i64 %6
  %8 = load float, float addrspace(1)* %7, align 4, !tbaa !4, !amdgpu.noclobber !8
  %9 = fadd contract float %8, 0.000000e+00
  %10 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %11 = mul i32 %10, 100
  %12 = zext i32 %11 to i64
  %13 = getelementptr inbounds float, float addrspace(1)* %0, i64 %12
  %14 = load float, float addrspace(1)* %13, align 4, !tbaa !4, !amdgpu.noclobber !8
  %15 = add i32 %5, 1
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds float, float addrspace(1)* %1, i64 %16
  %18 = load float, float addrspace(1)* %17, align 4, !tbaa !4, !amdgpu.noclobber !8
  %19 = fmul contract float %14, %18
  %20 = fadd contract float %9, %19
  %21 = or i32 %11, 1
  %22 = zext i32 %21 to i64
  %23 = getelementptr inbounds float, float addrspace(1)* %0, i64 %22
  %24 = load float, float addrspace(1)* %23, align 4, !tbaa !4, !amdgpu.noclobber !8
  %25 = add i32 %5, 2
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds float, float addrspace(1)* %1, i64 %26
  %28 = load float, float addrspace(1)* %27, align 4, !tbaa !4, !amdgpu.noclobber !8
  %29 = fmul contract float %24, %28
  %30 = fadd contract float %20, %29
  %31 = or i32 %11, 2
  %32 = zext i32 %31 to i64
  %33 = getelementptr inbounds float, float addrspace(1)* %0, i64 %32
  %34 = load float, float addrspace(1)* %33, align 4, !tbaa !4, !amdgpu.noclobber !8
  %35 = add i32 %5, 3
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds float, float addrspace(1)* %1, i64 %36
  %38 = load float, float addrspace(1)* %37, align 4, !tbaa !4, !amdgpu.noclobber !8
  %39 = fmul contract float %34, %38
  %40 = fadd contract float %30, %39
  %41 = or i32 %11, 3
  %42 = zext i32 %41 to i64
  %43 = getelementptr inbounds float, float addrspace(1)* %0, i64 %42
  %44 = load float, float addrspace(1)* %43, align 4, !tbaa !4, !amdgpu.noclobber !8
  %45 = add i32 %5, 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds float, float addrspace(1)* %1, i64 %46
  %48 = load float, float addrspace(1)* %47, align 4, !tbaa !4, !amdgpu.noclobber !8
  %49 = fmul contract float %44, %48
  %50 = fadd contract float %40, %49
  %51 = add i32 %11, 4
  %52 = zext i32 %51 to i64
  %53 = getelementptr inbounds float, float addrspace(1)* %0, i64 %52
  %54 = load float, float addrspace(1)* %53, align 4, !tbaa !4, !amdgpu.noclobber !8
  %55 = add i32 %5, 5
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds float, float addrspace(1)* %1, i64 %56
  %58 = load float, float addrspace(1)* %57, align 4, !tbaa !4, !amdgpu.noclobber !8
  %59 = fmul contract float %54, %58
  %60 = fadd contract float %50, %59
  %61 = add i32 %11, 5
  %62 = zext i32 %61 to i64
  %63 = getelementptr inbounds float, float addrspace(1)* %0, i64 %62
  %64 = load float, float addrspace(1)* %63, align 4, !tbaa !4, !amdgpu.noclobber !8
  %65 = add i32 %5, 6
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float addrspace(1)* %1, i64 %66
  %68 = load float, float addrspace(1)* %67, align 4, !tbaa !4, !amdgpu.noclobber !8
  %69 = fmul contract float %64, %68
  %70 = fadd contract float %60, %69
  %71 = add i32 %11, 6
  %72 = zext i32 %71 to i64
  %73 = getelementptr inbounds float, float addrspace(1)* %0, i64 %72
  %74 = load float, float addrspace(1)* %73, align 4, !tbaa !4, !amdgpu.noclobber !8
  %75 = add i32 %5, 7
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds float, float addrspace(1)* %1, i64 %76
  %78 = load float, float addrspace(1)* %77, align 4, !tbaa !4, !amdgpu.noclobber !8
  %79 = fmul contract float %74, %78
  %80 = fadd contract float %70, %79
  %81 = add i32 %11, 7
  %82 = zext i32 %81 to i64
  %83 = getelementptr inbounds float, float addrspace(1)* %0, i64 %82
  %84 = load float, float addrspace(1)* %83, align 4, !tbaa !4, !amdgpu.noclobber !8
  %85 = add i32 %5, 8
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds float, float addrspace(1)* %1, i64 %86
  %88 = load float, float addrspace(1)* %87, align 4, !tbaa !4, !amdgpu.noclobber !8
  %89 = fmul contract float %84, %88
  %90 = fadd contract float %80, %89
  %91 = add i32 %11, 8
  %92 = zext i32 %91 to i64
  %93 = getelementptr inbounds float, float addrspace(1)* %0, i64 %92
  %94 = load float, float addrspace(1)* %93, align 4, !tbaa !4, !amdgpu.noclobber !8
  %95 = add i32 %5, 9
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float addrspace(1)* %1, i64 %96
  %98 = load float, float addrspace(1)* %97, align 4, !tbaa !4, !amdgpu.noclobber !8
  %99 = fmul contract float %94, %98
  %100 = fadd contract float %90, %99
  %101 = add i32 %11, 9
  %102 = zext i32 %101 to i64
  %103 = getelementptr inbounds float, float addrspace(1)* %0, i64 %102
  %104 = load float, float addrspace(1)* %103, align 4, !tbaa !4, !amdgpu.noclobber !8
  %105 = add i32 %5, 10
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float addrspace(1)* %1, i64 %106
  %108 = load float, float addrspace(1)* %107, align 4, !tbaa !4, !amdgpu.noclobber !8
  %109 = fmul contract float %104, %108
  %110 = fadd contract float %100, %109
  %111 = add i32 %11, 10
  %112 = zext i32 %111 to i64
  %113 = getelementptr inbounds float, float addrspace(1)* %0, i64 %112
  %114 = load float, float addrspace(1)* %113, align 4, !tbaa !4, !amdgpu.noclobber !8
  %115 = add i32 %5, 11
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float addrspace(1)* %1, i64 %116
  %118 = load float, float addrspace(1)* %117, align 4, !tbaa !4, !amdgpu.noclobber !8
  %119 = fmul contract float %114, %118
  %120 = fadd contract float %110, %119
  %121 = add i32 %11, 11
  %122 = zext i32 %121 to i64
  %123 = getelementptr inbounds float, float addrspace(1)* %0, i64 %122
  %124 = load float, float addrspace(1)* %123, align 4, !tbaa !4, !amdgpu.noclobber !8
  %125 = add i32 %5, 12
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float addrspace(1)* %1, i64 %126
  %128 = load float, float addrspace(1)* %127, align 4, !tbaa !4, !amdgpu.noclobber !8
  %129 = fmul contract float %124, %128
  %130 = fadd contract float %120, %129
  %131 = add i32 %11, 12
  %132 = zext i32 %131 to i64
  %133 = getelementptr inbounds float, float addrspace(1)* %0, i64 %132
  %134 = load float, float addrspace(1)* %133, align 4, !tbaa !4, !amdgpu.noclobber !8
  %135 = add i32 %5, 13
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float addrspace(1)* %1, i64 %136
  %138 = load float, float addrspace(1)* %137, align 4, !tbaa !4, !amdgpu.noclobber !8
  %139 = fmul contract float %134, %138
  %140 = fadd contract float %130, %139
  %141 = add i32 %11, 13
  %142 = zext i32 %141 to i64
  %143 = getelementptr inbounds float, float addrspace(1)* %0, i64 %142
  %144 = load float, float addrspace(1)* %143, align 4, !tbaa !4, !amdgpu.noclobber !8
  %145 = add i32 %5, 14
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float addrspace(1)* %1, i64 %146
  %148 = load float, float addrspace(1)* %147, align 4, !tbaa !4, !amdgpu.noclobber !8
  %149 = fmul contract float %144, %148
  %150 = fadd contract float %140, %149
  %151 = add i32 %11, 14
  %152 = zext i32 %151 to i64
  %153 = getelementptr inbounds float, float addrspace(1)* %0, i64 %152
  %154 = load float, float addrspace(1)* %153, align 4, !tbaa !4, !amdgpu.noclobber !8
  %155 = add i32 %5, 15
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float addrspace(1)* %1, i64 %156
  %158 = load float, float addrspace(1)* %157, align 4, !tbaa !4, !amdgpu.noclobber !8
  %159 = fmul contract float %154, %158
  %160 = fadd contract float %150, %159
  %161 = add i32 %11, 15
  %162 = zext i32 %161 to i64
  %163 = getelementptr inbounds float, float addrspace(1)* %0, i64 %162
  %164 = load float, float addrspace(1)* %163, align 4, !tbaa !4, !amdgpu.noclobber !8
  %165 = add i32 %5, 16
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float addrspace(1)* %1, i64 %166
  %168 = load float, float addrspace(1)* %167, align 4, !tbaa !4, !amdgpu.noclobber !8
  %169 = fmul contract float %164, %168
  %170 = fadd contract float %160, %169
  %171 = add i32 %11, 16
  %172 = zext i32 %171 to i64
  %173 = getelementptr inbounds float, float addrspace(1)* %0, i64 %172
  %174 = load float, float addrspace(1)* %173, align 4, !tbaa !4, !amdgpu.noclobber !8
  %175 = add i32 %5, 17
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds float, float addrspace(1)* %1, i64 %176
  %178 = load float, float addrspace(1)* %177, align 4, !tbaa !4, !amdgpu.noclobber !8
  %179 = fmul contract float %174, %178
  %180 = fadd contract float %170, %179
  %181 = add i32 %11, 17
  %182 = zext i32 %181 to i64
  %183 = getelementptr inbounds float, float addrspace(1)* %0, i64 %182
  %184 = load float, float addrspace(1)* %183, align 4, !tbaa !4, !amdgpu.noclobber !8
  %185 = add i32 %5, 18
  %186 = sext i32 %185 to i64
  %187 = getelementptr inbounds float, float addrspace(1)* %1, i64 %186
  %188 = load float, float addrspace(1)* %187, align 4, !tbaa !4, !amdgpu.noclobber !8
  %189 = fmul contract float %184, %188
  %190 = fadd contract float %180, %189
  %191 = add i32 %11, 18
  %192 = zext i32 %191 to i64
  %193 = getelementptr inbounds float, float addrspace(1)* %0, i64 %192
  %194 = load float, float addrspace(1)* %193, align 4, !tbaa !4, !amdgpu.noclobber !8
  %195 = add i32 %5, 19
  %196 = sext i32 %195 to i64
  %197 = getelementptr inbounds float, float addrspace(1)* %1, i64 %196
  %198 = load float, float addrspace(1)* %197, align 4, !tbaa !4, !amdgpu.noclobber !8
  %199 = fmul contract float %194, %198
  %200 = fadd contract float %190, %199
  %201 = add i32 %11, 19
  %202 = zext i32 %201 to i64
  %203 = getelementptr inbounds float, float addrspace(1)* %0, i64 %202
  %204 = load float, float addrspace(1)* %203, align 4, !tbaa !4, !amdgpu.noclobber !8
  %205 = add i32 %5, 20
  %206 = sext i32 %205 to i64
  %207 = getelementptr inbounds float, float addrspace(1)* %1, i64 %206
  %208 = load float, float addrspace(1)* %207, align 4, !tbaa !4, !amdgpu.noclobber !8
  %209 = fmul contract float %204, %208
  %210 = fadd contract float %200, %209
  %211 = add i32 %11, 20
  %212 = zext i32 %211 to i64
  %213 = getelementptr inbounds float, float addrspace(1)* %0, i64 %212
  %214 = load float, float addrspace(1)* %213, align 4, !tbaa !4, !amdgpu.noclobber !8
  %215 = add i32 %5, 21
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds float, float addrspace(1)* %1, i64 %216
  %218 = load float, float addrspace(1)* %217, align 4, !tbaa !4, !amdgpu.noclobber !8
  %219 = fmul contract float %214, %218
  %220 = fadd contract float %210, %219
  %221 = add i32 %11, 21
  %222 = zext i32 %221 to i64
  %223 = getelementptr inbounds float, float addrspace(1)* %0, i64 %222
  %224 = load float, float addrspace(1)* %223, align 4, !tbaa !4, !amdgpu.noclobber !8
  %225 = add i32 %5, 22
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds float, float addrspace(1)* %1, i64 %226
  %228 = load float, float addrspace(1)* %227, align 4, !tbaa !4, !amdgpu.noclobber !8
  %229 = fmul contract float %224, %228
  %230 = fadd contract float %220, %229
  %231 = add i32 %11, 22
  %232 = zext i32 %231 to i64
  %233 = getelementptr inbounds float, float addrspace(1)* %0, i64 %232
  %234 = load float, float addrspace(1)* %233, align 4, !tbaa !4, !amdgpu.noclobber !8
  %235 = add i32 %5, 23
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds float, float addrspace(1)* %1, i64 %236
  %238 = load float, float addrspace(1)* %237, align 4, !tbaa !4, !amdgpu.noclobber !8
  %239 = fmul contract float %234, %238
  %240 = fadd contract float %230, %239
  %241 = add i32 %11, 23
  %242 = zext i32 %241 to i64
  %243 = getelementptr inbounds float, float addrspace(1)* %0, i64 %242
  %244 = load float, float addrspace(1)* %243, align 4, !tbaa !4, !amdgpu.noclobber !8
  %245 = add i32 %5, 24
  %246 = sext i32 %245 to i64
  %247 = getelementptr inbounds float, float addrspace(1)* %1, i64 %246
  %248 = load float, float addrspace(1)* %247, align 4, !tbaa !4, !amdgpu.noclobber !8
  %249 = fmul contract float %244, %248
  %250 = fadd contract float %240, %249
  %251 = add i32 %11, 24
  %252 = zext i32 %251 to i64
  %253 = getelementptr inbounds float, float addrspace(1)* %0, i64 %252
  %254 = load float, float addrspace(1)* %253, align 4, !tbaa !4, !amdgpu.noclobber !8
  %255 = add i32 %5, 25
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds float, float addrspace(1)* %1, i64 %256
  %258 = load float, float addrspace(1)* %257, align 4, !tbaa !4, !amdgpu.noclobber !8
  %259 = fmul contract float %254, %258
  %260 = fadd contract float %250, %259
  %261 = add i32 %11, 25
  %262 = zext i32 %261 to i64
  %263 = getelementptr inbounds float, float addrspace(1)* %0, i64 %262
  %264 = load float, float addrspace(1)* %263, align 4, !tbaa !4, !amdgpu.noclobber !8
  %265 = add i32 %5, 26
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds float, float addrspace(1)* %1, i64 %266
  %268 = load float, float addrspace(1)* %267, align 4, !tbaa !4, !amdgpu.noclobber !8
  %269 = fmul contract float %264, %268
  %270 = fadd contract float %260, %269
  %271 = add i32 %11, 26
  %272 = zext i32 %271 to i64
  %273 = getelementptr inbounds float, float addrspace(1)* %0, i64 %272
  %274 = load float, float addrspace(1)* %273, align 4, !tbaa !4, !amdgpu.noclobber !8
  %275 = add i32 %5, 27
  %276 = sext i32 %275 to i64
  %277 = getelementptr inbounds float, float addrspace(1)* %1, i64 %276
  %278 = load float, float addrspace(1)* %277, align 4, !tbaa !4, !amdgpu.noclobber !8
  %279 = fmul contract float %274, %278
  %280 = fadd contract float %270, %279
  %281 = add i32 %11, 27
  %282 = zext i32 %281 to i64
  %283 = getelementptr inbounds float, float addrspace(1)* %0, i64 %282
  %284 = load float, float addrspace(1)* %283, align 4, !tbaa !4, !amdgpu.noclobber !8
  %285 = add i32 %5, 28
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds float, float addrspace(1)* %1, i64 %286
  %288 = load float, float addrspace(1)* %287, align 4, !tbaa !4, !amdgpu.noclobber !8
  %289 = fmul contract float %284, %288
  %290 = fadd contract float %280, %289
  %291 = add i32 %11, 28
  %292 = zext i32 %291 to i64
  %293 = getelementptr inbounds float, float addrspace(1)* %0, i64 %292
  %294 = load float, float addrspace(1)* %293, align 4, !tbaa !4, !amdgpu.noclobber !8
  %295 = add i32 %5, 29
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds float, float addrspace(1)* %1, i64 %296
  %298 = load float, float addrspace(1)* %297, align 4, !tbaa !4, !amdgpu.noclobber !8
  %299 = fmul contract float %294, %298
  %300 = fadd contract float %290, %299
  %301 = add i32 %11, 29
  %302 = zext i32 %301 to i64
  %303 = getelementptr inbounds float, float addrspace(1)* %0, i64 %302
  %304 = load float, float addrspace(1)* %303, align 4, !tbaa !4, !amdgpu.noclobber !8
  %305 = add i32 %5, 30
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds float, float addrspace(1)* %1, i64 %306
  %308 = load float, float addrspace(1)* %307, align 4, !tbaa !4, !amdgpu.noclobber !8
  %309 = fmul contract float %304, %308
  %310 = fadd contract float %300, %309
  %311 = add i32 %11, 30
  %312 = zext i32 %311 to i64
  %313 = getelementptr inbounds float, float addrspace(1)* %0, i64 %312
  %314 = load float, float addrspace(1)* %313, align 4, !tbaa !4, !amdgpu.noclobber !8
  %315 = add i32 %5, 31
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds float, float addrspace(1)* %1, i64 %316
  %318 = load float, float addrspace(1)* %317, align 4, !tbaa !4, !amdgpu.noclobber !8
  %319 = fmul contract float %314, %318
  %320 = fadd contract float %310, %319
  %321 = add i32 %11, 31
  %322 = zext i32 %321 to i64
  %323 = getelementptr inbounds float, float addrspace(1)* %0, i64 %322
  %324 = load float, float addrspace(1)* %323, align 4, !tbaa !4, !amdgpu.noclobber !8
  %325 = add i32 %5, 32
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds float, float addrspace(1)* %1, i64 %326
  %328 = load float, float addrspace(1)* %327, align 4, !tbaa !4, !amdgpu.noclobber !8
  %329 = fmul contract float %324, %328
  %330 = fadd contract float %320, %329
  %331 = add i32 %11, 32
  %332 = zext i32 %331 to i64
  %333 = getelementptr inbounds float, float addrspace(1)* %0, i64 %332
  %334 = load float, float addrspace(1)* %333, align 4, !tbaa !4, !amdgpu.noclobber !8
  %335 = add i32 %5, 33
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds float, float addrspace(1)* %1, i64 %336
  %338 = load float, float addrspace(1)* %337, align 4, !tbaa !4, !amdgpu.noclobber !8
  %339 = fmul contract float %334, %338
  %340 = fadd contract float %330, %339
  %341 = add i32 %11, 33
  %342 = zext i32 %341 to i64
  %343 = getelementptr inbounds float, float addrspace(1)* %0, i64 %342
  %344 = load float, float addrspace(1)* %343, align 4, !tbaa !4, !amdgpu.noclobber !8
  %345 = add i32 %5, 34
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds float, float addrspace(1)* %1, i64 %346
  %348 = load float, float addrspace(1)* %347, align 4, !tbaa !4, !amdgpu.noclobber !8
  %349 = fmul contract float %344, %348
  %350 = fadd contract float %340, %349
  %351 = add i32 %11, 34
  %352 = zext i32 %351 to i64
  %353 = getelementptr inbounds float, float addrspace(1)* %0, i64 %352
  %354 = load float, float addrspace(1)* %353, align 4, !tbaa !4, !amdgpu.noclobber !8
  %355 = add i32 %5, 35
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds float, float addrspace(1)* %1, i64 %356
  %358 = load float, float addrspace(1)* %357, align 4, !tbaa !4, !amdgpu.noclobber !8
  %359 = fmul contract float %354, %358
  %360 = fadd contract float %350, %359
  %361 = add i32 %11, 35
  %362 = zext i32 %361 to i64
  %363 = getelementptr inbounds float, float addrspace(1)* %0, i64 %362
  %364 = load float, float addrspace(1)* %363, align 4, !tbaa !4, !amdgpu.noclobber !8
  %365 = add i32 %5, 36
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds float, float addrspace(1)* %1, i64 %366
  %368 = load float, float addrspace(1)* %367, align 4, !tbaa !4, !amdgpu.noclobber !8
  %369 = fmul contract float %364, %368
  %370 = fadd contract float %360, %369
  %371 = add i32 %11, 36
  %372 = zext i32 %371 to i64
  %373 = getelementptr inbounds float, float addrspace(1)* %0, i64 %372
  %374 = load float, float addrspace(1)* %373, align 4, !tbaa !4, !amdgpu.noclobber !8
  %375 = add i32 %5, 37
  %376 = sext i32 %375 to i64
  %377 = getelementptr inbounds float, float addrspace(1)* %1, i64 %376
  %378 = load float, float addrspace(1)* %377, align 4, !tbaa !4, !amdgpu.noclobber !8
  %379 = fmul contract float %374, %378
  %380 = fadd contract float %370, %379
  %381 = add i32 %11, 37
  %382 = zext i32 %381 to i64
  %383 = getelementptr inbounds float, float addrspace(1)* %0, i64 %382
  %384 = load float, float addrspace(1)* %383, align 4, !tbaa !4, !amdgpu.noclobber !8
  %385 = add i32 %5, 38
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds float, float addrspace(1)* %1, i64 %386
  %388 = load float, float addrspace(1)* %387, align 4, !tbaa !4, !amdgpu.noclobber !8
  %389 = fmul contract float %384, %388
  %390 = fadd contract float %380, %389
  %391 = add i32 %11, 38
  %392 = zext i32 %391 to i64
  %393 = getelementptr inbounds float, float addrspace(1)* %0, i64 %392
  %394 = load float, float addrspace(1)* %393, align 4, !tbaa !4, !amdgpu.noclobber !8
  %395 = add i32 %5, 39
  %396 = sext i32 %395 to i64
  %397 = getelementptr inbounds float, float addrspace(1)* %1, i64 %396
  %398 = load float, float addrspace(1)* %397, align 4, !tbaa !4, !amdgpu.noclobber !8
  %399 = fmul contract float %394, %398
  %400 = fadd contract float %390, %399
  %401 = add i32 %11, 39
  %402 = zext i32 %401 to i64
  %403 = getelementptr inbounds float, float addrspace(1)* %0, i64 %402
  %404 = load float, float addrspace(1)* %403, align 4, !tbaa !4, !amdgpu.noclobber !8
  %405 = add i32 %5, 40
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds float, float addrspace(1)* %1, i64 %406
  %408 = load float, float addrspace(1)* %407, align 4, !tbaa !4, !amdgpu.noclobber !8
  %409 = fmul contract float %404, %408
  %410 = fadd contract float %400, %409
  %411 = add i32 %11, 40
  %412 = zext i32 %411 to i64
  %413 = getelementptr inbounds float, float addrspace(1)* %0, i64 %412
  %414 = load float, float addrspace(1)* %413, align 4, !tbaa !4, !amdgpu.noclobber !8
  %415 = add i32 %5, 41
  %416 = sext i32 %415 to i64
  %417 = getelementptr inbounds float, float addrspace(1)* %1, i64 %416
  %418 = load float, float addrspace(1)* %417, align 4, !tbaa !4, !amdgpu.noclobber !8
  %419 = fmul contract float %414, %418
  %420 = fadd contract float %410, %419
  %421 = add i32 %11, 41
  %422 = zext i32 %421 to i64
  %423 = getelementptr inbounds float, float addrspace(1)* %0, i64 %422
  %424 = load float, float addrspace(1)* %423, align 4, !tbaa !4, !amdgpu.noclobber !8
  %425 = add i32 %5, 42
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds float, float addrspace(1)* %1, i64 %426
  %428 = load float, float addrspace(1)* %427, align 4, !tbaa !4, !amdgpu.noclobber !8
  %429 = fmul contract float %424, %428
  %430 = fadd contract float %420, %429
  %431 = add i32 %11, 42
  %432 = zext i32 %431 to i64
  %433 = getelementptr inbounds float, float addrspace(1)* %0, i64 %432
  %434 = load float, float addrspace(1)* %433, align 4, !tbaa !4, !amdgpu.noclobber !8
  %435 = add i32 %5, 43
  %436 = sext i32 %435 to i64
  %437 = getelementptr inbounds float, float addrspace(1)* %1, i64 %436
  %438 = load float, float addrspace(1)* %437, align 4, !tbaa !4, !amdgpu.noclobber !8
  %439 = fmul contract float %434, %438
  %440 = fadd contract float %430, %439
  %441 = add i32 %11, 43
  %442 = zext i32 %441 to i64
  %443 = getelementptr inbounds float, float addrspace(1)* %0, i64 %442
  %444 = load float, float addrspace(1)* %443, align 4, !tbaa !4, !amdgpu.noclobber !8
  %445 = add i32 %5, 44
  %446 = sext i32 %445 to i64
  %447 = getelementptr inbounds float, float addrspace(1)* %1, i64 %446
  %448 = load float, float addrspace(1)* %447, align 4, !tbaa !4, !amdgpu.noclobber !8
  %449 = fmul contract float %444, %448
  %450 = fadd contract float %440, %449
  %451 = add i32 %11, 44
  %452 = zext i32 %451 to i64
  %453 = getelementptr inbounds float, float addrspace(1)* %0, i64 %452
  %454 = load float, float addrspace(1)* %453, align 4, !tbaa !4, !amdgpu.noclobber !8
  %455 = add i32 %5, 45
  %456 = sext i32 %455 to i64
  %457 = getelementptr inbounds float, float addrspace(1)* %1, i64 %456
  %458 = load float, float addrspace(1)* %457, align 4, !tbaa !4, !amdgpu.noclobber !8
  %459 = fmul contract float %454, %458
  %460 = fadd contract float %450, %459
  %461 = add i32 %11, 45
  %462 = zext i32 %461 to i64
  %463 = getelementptr inbounds float, float addrspace(1)* %0, i64 %462
  %464 = load float, float addrspace(1)* %463, align 4, !tbaa !4, !amdgpu.noclobber !8
  %465 = add i32 %5, 46
  %466 = sext i32 %465 to i64
  %467 = getelementptr inbounds float, float addrspace(1)* %1, i64 %466
  %468 = load float, float addrspace(1)* %467, align 4, !tbaa !4, !amdgpu.noclobber !8
  %469 = fmul contract float %464, %468
  %470 = fadd contract float %460, %469
  %471 = add i32 %11, 46
  %472 = zext i32 %471 to i64
  %473 = getelementptr inbounds float, float addrspace(1)* %0, i64 %472
  %474 = load float, float addrspace(1)* %473, align 4, !tbaa !4, !amdgpu.noclobber !8
  %475 = add i32 %5, 47
  %476 = sext i32 %475 to i64
  %477 = getelementptr inbounds float, float addrspace(1)* %1, i64 %476
  %478 = load float, float addrspace(1)* %477, align 4, !tbaa !4, !amdgpu.noclobber !8
  %479 = fmul contract float %474, %478
  %480 = fadd contract float %470, %479
  %481 = add i32 %11, 47
  %482 = zext i32 %481 to i64
  %483 = getelementptr inbounds float, float addrspace(1)* %0, i64 %482
  %484 = load float, float addrspace(1)* %483, align 4, !tbaa !4, !amdgpu.noclobber !8
  %485 = add i32 %5, 48
  %486 = sext i32 %485 to i64
  %487 = getelementptr inbounds float, float addrspace(1)* %1, i64 %486
  %488 = load float, float addrspace(1)* %487, align 4, !tbaa !4, !amdgpu.noclobber !8
  %489 = fmul contract float %484, %488
  %490 = fadd contract float %480, %489
  %491 = add i32 %11, 48
  %492 = zext i32 %491 to i64
  %493 = getelementptr inbounds float, float addrspace(1)* %0, i64 %492
  %494 = load float, float addrspace(1)* %493, align 4, !tbaa !4, !amdgpu.noclobber !8
  %495 = add i32 %5, 49
  %496 = sext i32 %495 to i64
  %497 = getelementptr inbounds float, float addrspace(1)* %1, i64 %496
  %498 = load float, float addrspace(1)* %497, align 4, !tbaa !4, !amdgpu.noclobber !8
  %499 = fmul contract float %494, %498
  %500 = fadd contract float %490, %499
  %501 = add i32 %11, 49
  %502 = zext i32 %501 to i64
  %503 = getelementptr inbounds float, float addrspace(1)* %0, i64 %502
  %504 = load float, float addrspace(1)* %503, align 4, !tbaa !4, !amdgpu.noclobber !8
  %505 = add i32 %5, 50
  %506 = sext i32 %505 to i64
  %507 = getelementptr inbounds float, float addrspace(1)* %1, i64 %506
  %508 = load float, float addrspace(1)* %507, align 4, !tbaa !4, !amdgpu.noclobber !8
  %509 = fmul contract float %504, %508
  %510 = fadd contract float %500, %509
  %511 = add i32 %11, 50
  %512 = zext i32 %511 to i64
  %513 = getelementptr inbounds float, float addrspace(1)* %0, i64 %512
  %514 = load float, float addrspace(1)* %513, align 4, !tbaa !4, !amdgpu.noclobber !8
  %515 = add i32 %5, 51
  %516 = sext i32 %515 to i64
  %517 = getelementptr inbounds float, float addrspace(1)* %1, i64 %516
  %518 = load float, float addrspace(1)* %517, align 4, !tbaa !4, !amdgpu.noclobber !8
  %519 = fmul contract float %514, %518
  %520 = fadd contract float %510, %519
  %521 = add i32 %11, 51
  %522 = zext i32 %521 to i64
  %523 = getelementptr inbounds float, float addrspace(1)* %0, i64 %522
  %524 = load float, float addrspace(1)* %523, align 4, !tbaa !4, !amdgpu.noclobber !8
  %525 = add i32 %5, 52
  %526 = sext i32 %525 to i64
  %527 = getelementptr inbounds float, float addrspace(1)* %1, i64 %526
  %528 = load float, float addrspace(1)* %527, align 4, !tbaa !4, !amdgpu.noclobber !8
  %529 = fmul contract float %524, %528
  %530 = fadd contract float %520, %529
  %531 = add i32 %11, 52
  %532 = zext i32 %531 to i64
  %533 = getelementptr inbounds float, float addrspace(1)* %0, i64 %532
  %534 = load float, float addrspace(1)* %533, align 4, !tbaa !4, !amdgpu.noclobber !8
  %535 = add i32 %5, 53
  %536 = sext i32 %535 to i64
  %537 = getelementptr inbounds float, float addrspace(1)* %1, i64 %536
  %538 = load float, float addrspace(1)* %537, align 4, !tbaa !4, !amdgpu.noclobber !8
  %539 = fmul contract float %534, %538
  %540 = fadd contract float %530, %539
  %541 = add i32 %11, 53
  %542 = zext i32 %541 to i64
  %543 = getelementptr inbounds float, float addrspace(1)* %0, i64 %542
  %544 = load float, float addrspace(1)* %543, align 4, !tbaa !4, !amdgpu.noclobber !8
  %545 = add i32 %5, 54
  %546 = sext i32 %545 to i64
  %547 = getelementptr inbounds float, float addrspace(1)* %1, i64 %546
  %548 = load float, float addrspace(1)* %547, align 4, !tbaa !4, !amdgpu.noclobber !8
  %549 = fmul contract float %544, %548
  %550 = fadd contract float %540, %549
  %551 = add i32 %11, 54
  %552 = zext i32 %551 to i64
  %553 = getelementptr inbounds float, float addrspace(1)* %0, i64 %552
  %554 = load float, float addrspace(1)* %553, align 4, !tbaa !4, !amdgpu.noclobber !8
  %555 = add i32 %5, 55
  %556 = sext i32 %555 to i64
  %557 = getelementptr inbounds float, float addrspace(1)* %1, i64 %556
  %558 = load float, float addrspace(1)* %557, align 4, !tbaa !4, !amdgpu.noclobber !8
  %559 = fmul contract float %554, %558
  %560 = fadd contract float %550, %559
  %561 = add i32 %11, 55
  %562 = zext i32 %561 to i64
  %563 = getelementptr inbounds float, float addrspace(1)* %0, i64 %562
  %564 = load float, float addrspace(1)* %563, align 4, !tbaa !4, !amdgpu.noclobber !8
  %565 = add i32 %5, 56
  %566 = sext i32 %565 to i64
  %567 = getelementptr inbounds float, float addrspace(1)* %1, i64 %566
  %568 = load float, float addrspace(1)* %567, align 4, !tbaa !4, !amdgpu.noclobber !8
  %569 = fmul contract float %564, %568
  %570 = fadd contract float %560, %569
  %571 = add i32 %11, 56
  %572 = zext i32 %571 to i64
  %573 = getelementptr inbounds float, float addrspace(1)* %0, i64 %572
  %574 = load float, float addrspace(1)* %573, align 4, !tbaa !4, !amdgpu.noclobber !8
  %575 = add i32 %5, 57
  %576 = sext i32 %575 to i64
  %577 = getelementptr inbounds float, float addrspace(1)* %1, i64 %576
  %578 = load float, float addrspace(1)* %577, align 4, !tbaa !4, !amdgpu.noclobber !8
  %579 = fmul contract float %574, %578
  %580 = fadd contract float %570, %579
  %581 = add i32 %11, 57
  %582 = zext i32 %581 to i64
  %583 = getelementptr inbounds float, float addrspace(1)* %0, i64 %582
  %584 = load float, float addrspace(1)* %583, align 4, !tbaa !4, !amdgpu.noclobber !8
  %585 = add i32 %5, 58
  %586 = sext i32 %585 to i64
  %587 = getelementptr inbounds float, float addrspace(1)* %1, i64 %586
  %588 = load float, float addrspace(1)* %587, align 4, !tbaa !4, !amdgpu.noclobber !8
  %589 = fmul contract float %584, %588
  %590 = fadd contract float %580, %589
  %591 = add i32 %11, 58
  %592 = zext i32 %591 to i64
  %593 = getelementptr inbounds float, float addrspace(1)* %0, i64 %592
  %594 = load float, float addrspace(1)* %593, align 4, !tbaa !4, !amdgpu.noclobber !8
  %595 = add i32 %5, 59
  %596 = sext i32 %595 to i64
  %597 = getelementptr inbounds float, float addrspace(1)* %1, i64 %596
  %598 = load float, float addrspace(1)* %597, align 4, !tbaa !4, !amdgpu.noclobber !8
  %599 = fmul contract float %594, %598
  %600 = fadd contract float %590, %599
  %601 = add i32 %11, 59
  %602 = zext i32 %601 to i64
  %603 = getelementptr inbounds float, float addrspace(1)* %0, i64 %602
  %604 = load float, float addrspace(1)* %603, align 4, !tbaa !4, !amdgpu.noclobber !8
  %605 = add i32 %5, 60
  %606 = sext i32 %605 to i64
  %607 = getelementptr inbounds float, float addrspace(1)* %1, i64 %606
  %608 = load float, float addrspace(1)* %607, align 4, !tbaa !4, !amdgpu.noclobber !8
  %609 = fmul contract float %604, %608
  %610 = fadd contract float %600, %609
  %611 = add i32 %11, 60
  %612 = zext i32 %611 to i64
  %613 = getelementptr inbounds float, float addrspace(1)* %0, i64 %612
  %614 = load float, float addrspace(1)* %613, align 4, !tbaa !4, !amdgpu.noclobber !8
  %615 = add i32 %5, 61
  %616 = sext i32 %615 to i64
  %617 = getelementptr inbounds float, float addrspace(1)* %1, i64 %616
  %618 = load float, float addrspace(1)* %617, align 4, !tbaa !4, !amdgpu.noclobber !8
  %619 = fmul contract float %614, %618
  %620 = fadd contract float %610, %619
  %621 = add i32 %11, 61
  %622 = zext i32 %621 to i64
  %623 = getelementptr inbounds float, float addrspace(1)* %0, i64 %622
  %624 = load float, float addrspace(1)* %623, align 4, !tbaa !4, !amdgpu.noclobber !8
  %625 = add i32 %5, 62
  %626 = sext i32 %625 to i64
  %627 = getelementptr inbounds float, float addrspace(1)* %1, i64 %626
  %628 = load float, float addrspace(1)* %627, align 4, !tbaa !4, !amdgpu.noclobber !8
  %629 = fmul contract float %624, %628
  %630 = fadd contract float %620, %629
  %631 = add i32 %11, 62
  %632 = zext i32 %631 to i64
  %633 = getelementptr inbounds float, float addrspace(1)* %0, i64 %632
  %634 = load float, float addrspace(1)* %633, align 4, !tbaa !4, !amdgpu.noclobber !8
  %635 = add i32 %5, 63
  %636 = sext i32 %635 to i64
  %637 = getelementptr inbounds float, float addrspace(1)* %1, i64 %636
  %638 = load float, float addrspace(1)* %637, align 4, !tbaa !4, !amdgpu.noclobber !8
  %639 = fmul contract float %634, %638
  %640 = fadd contract float %630, %639
  %641 = add i32 %11, 63
  %642 = zext i32 %641 to i64
  %643 = getelementptr inbounds float, float addrspace(1)* %0, i64 %642
  %644 = load float, float addrspace(1)* %643, align 4, !tbaa !4, !amdgpu.noclobber !8
  %645 = add i32 %5, 64
  %646 = sext i32 %645 to i64
  %647 = getelementptr inbounds float, float addrspace(1)* %1, i64 %646
  %648 = load float, float addrspace(1)* %647, align 4, !tbaa !4, !amdgpu.noclobber !8
  %649 = fmul contract float %644, %648
  %650 = fadd contract float %640, %649
  %651 = add i32 %11, 64
  %652 = zext i32 %651 to i64
  %653 = getelementptr inbounds float, float addrspace(1)* %0, i64 %652
  %654 = load float, float addrspace(1)* %653, align 4, !tbaa !4, !amdgpu.noclobber !8
  %655 = add i32 %5, 65
  %656 = sext i32 %655 to i64
  %657 = getelementptr inbounds float, float addrspace(1)* %1, i64 %656
  %658 = load float, float addrspace(1)* %657, align 4, !tbaa !4, !amdgpu.noclobber !8
  %659 = fmul contract float %654, %658
  %660 = fadd contract float %650, %659
  %661 = add i32 %11, 65
  %662 = zext i32 %661 to i64
  %663 = getelementptr inbounds float, float addrspace(1)* %0, i64 %662
  %664 = load float, float addrspace(1)* %663, align 4, !tbaa !4, !amdgpu.noclobber !8
  %665 = add i32 %5, 66
  %666 = sext i32 %665 to i64
  %667 = getelementptr inbounds float, float addrspace(1)* %1, i64 %666
  %668 = load float, float addrspace(1)* %667, align 4, !tbaa !4, !amdgpu.noclobber !8
  %669 = fmul contract float %664, %668
  %670 = fadd contract float %660, %669
  %671 = add i32 %11, 66
  %672 = zext i32 %671 to i64
  %673 = getelementptr inbounds float, float addrspace(1)* %0, i64 %672
  %674 = load float, float addrspace(1)* %673, align 4, !tbaa !4, !amdgpu.noclobber !8
  %675 = add i32 %5, 67
  %676 = sext i32 %675 to i64
  %677 = getelementptr inbounds float, float addrspace(1)* %1, i64 %676
  %678 = load float, float addrspace(1)* %677, align 4, !tbaa !4, !amdgpu.noclobber !8
  %679 = fmul contract float %674, %678
  %680 = fadd contract float %670, %679
  %681 = add i32 %11, 67
  %682 = zext i32 %681 to i64
  %683 = getelementptr inbounds float, float addrspace(1)* %0, i64 %682
  %684 = load float, float addrspace(1)* %683, align 4, !tbaa !4, !amdgpu.noclobber !8
  %685 = add i32 %5, 68
  %686 = sext i32 %685 to i64
  %687 = getelementptr inbounds float, float addrspace(1)* %1, i64 %686
  %688 = load float, float addrspace(1)* %687, align 4, !tbaa !4, !amdgpu.noclobber !8
  %689 = fmul contract float %684, %688
  %690 = fadd contract float %680, %689
  %691 = add i32 %11, 68
  %692 = zext i32 %691 to i64
  %693 = getelementptr inbounds float, float addrspace(1)* %0, i64 %692
  %694 = load float, float addrspace(1)* %693, align 4, !tbaa !4, !amdgpu.noclobber !8
  %695 = add i32 %5, 69
  %696 = sext i32 %695 to i64
  %697 = getelementptr inbounds float, float addrspace(1)* %1, i64 %696
  %698 = load float, float addrspace(1)* %697, align 4, !tbaa !4, !amdgpu.noclobber !8
  %699 = fmul contract float %694, %698
  %700 = fadd contract float %690, %699
  %701 = add i32 %11, 69
  %702 = zext i32 %701 to i64
  %703 = getelementptr inbounds float, float addrspace(1)* %0, i64 %702
  %704 = load float, float addrspace(1)* %703, align 4, !tbaa !4, !amdgpu.noclobber !8
  %705 = add i32 %5, 70
  %706 = sext i32 %705 to i64
  %707 = getelementptr inbounds float, float addrspace(1)* %1, i64 %706
  %708 = load float, float addrspace(1)* %707, align 4, !tbaa !4, !amdgpu.noclobber !8
  %709 = fmul contract float %704, %708
  %710 = fadd contract float %700, %709
  %711 = add i32 %11, 70
  %712 = zext i32 %711 to i64
  %713 = getelementptr inbounds float, float addrspace(1)* %0, i64 %712
  %714 = load float, float addrspace(1)* %713, align 4, !tbaa !4, !amdgpu.noclobber !8
  %715 = add i32 %5, 71
  %716 = sext i32 %715 to i64
  %717 = getelementptr inbounds float, float addrspace(1)* %1, i64 %716
  %718 = load float, float addrspace(1)* %717, align 4, !tbaa !4, !amdgpu.noclobber !8
  %719 = fmul contract float %714, %718
  %720 = fadd contract float %710, %719
  %721 = add i32 %11, 71
  %722 = zext i32 %721 to i64
  %723 = getelementptr inbounds float, float addrspace(1)* %0, i64 %722
  %724 = load float, float addrspace(1)* %723, align 4, !tbaa !4, !amdgpu.noclobber !8
  %725 = add i32 %5, 72
  %726 = sext i32 %725 to i64
  %727 = getelementptr inbounds float, float addrspace(1)* %1, i64 %726
  %728 = load float, float addrspace(1)* %727, align 4, !tbaa !4, !amdgpu.noclobber !8
  %729 = fmul contract float %724, %728
  %730 = fadd contract float %720, %729
  %731 = add i32 %11, 72
  %732 = zext i32 %731 to i64
  %733 = getelementptr inbounds float, float addrspace(1)* %0, i64 %732
  %734 = load float, float addrspace(1)* %733, align 4, !tbaa !4, !amdgpu.noclobber !8
  %735 = add i32 %5, 73
  %736 = sext i32 %735 to i64
  %737 = getelementptr inbounds float, float addrspace(1)* %1, i64 %736
  %738 = load float, float addrspace(1)* %737, align 4, !tbaa !4, !amdgpu.noclobber !8
  %739 = fmul contract float %734, %738
  %740 = fadd contract float %730, %739
  %741 = add i32 %11, 73
  %742 = zext i32 %741 to i64
  %743 = getelementptr inbounds float, float addrspace(1)* %0, i64 %742
  %744 = load float, float addrspace(1)* %743, align 4, !tbaa !4, !amdgpu.noclobber !8
  %745 = add i32 %5, 74
  %746 = sext i32 %745 to i64
  %747 = getelementptr inbounds float, float addrspace(1)* %1, i64 %746
  %748 = load float, float addrspace(1)* %747, align 4, !tbaa !4, !amdgpu.noclobber !8
  %749 = fmul contract float %744, %748
  %750 = fadd contract float %740, %749
  %751 = add i32 %11, 74
  %752 = zext i32 %751 to i64
  %753 = getelementptr inbounds float, float addrspace(1)* %0, i64 %752
  %754 = load float, float addrspace(1)* %753, align 4, !tbaa !4, !amdgpu.noclobber !8
  %755 = add i32 %5, 75
  %756 = sext i32 %755 to i64
  %757 = getelementptr inbounds float, float addrspace(1)* %1, i64 %756
  %758 = load float, float addrspace(1)* %757, align 4, !tbaa !4, !amdgpu.noclobber !8
  %759 = fmul contract float %754, %758
  %760 = fadd contract float %750, %759
  %761 = add i32 %11, 75
  %762 = zext i32 %761 to i64
  %763 = getelementptr inbounds float, float addrspace(1)* %0, i64 %762
  %764 = load float, float addrspace(1)* %763, align 4, !tbaa !4, !amdgpu.noclobber !8
  %765 = add i32 %5, 76
  %766 = sext i32 %765 to i64
  %767 = getelementptr inbounds float, float addrspace(1)* %1, i64 %766
  %768 = load float, float addrspace(1)* %767, align 4, !tbaa !4, !amdgpu.noclobber !8
  %769 = fmul contract float %764, %768
  %770 = fadd contract float %760, %769
  %771 = add i32 %11, 76
  %772 = zext i32 %771 to i64
  %773 = getelementptr inbounds float, float addrspace(1)* %0, i64 %772
  %774 = load float, float addrspace(1)* %773, align 4, !tbaa !4, !amdgpu.noclobber !8
  %775 = add i32 %5, 77
  %776 = sext i32 %775 to i64
  %777 = getelementptr inbounds float, float addrspace(1)* %1, i64 %776
  %778 = load float, float addrspace(1)* %777, align 4, !tbaa !4, !amdgpu.noclobber !8
  %779 = fmul contract float %774, %778
  %780 = fadd contract float %770, %779
  %781 = add i32 %11, 77
  %782 = zext i32 %781 to i64
  %783 = getelementptr inbounds float, float addrspace(1)* %0, i64 %782
  %784 = load float, float addrspace(1)* %783, align 4, !tbaa !4, !amdgpu.noclobber !8
  %785 = add i32 %5, 78
  %786 = sext i32 %785 to i64
  %787 = getelementptr inbounds float, float addrspace(1)* %1, i64 %786
  %788 = load float, float addrspace(1)* %787, align 4, !tbaa !4, !amdgpu.noclobber !8
  %789 = fmul contract float %784, %788
  %790 = fadd contract float %780, %789
  %791 = add i32 %11, 78
  %792 = zext i32 %791 to i64
  %793 = getelementptr inbounds float, float addrspace(1)* %0, i64 %792
  %794 = load float, float addrspace(1)* %793, align 4, !tbaa !4, !amdgpu.noclobber !8
  %795 = add i32 %5, 79
  %796 = sext i32 %795 to i64
  %797 = getelementptr inbounds float, float addrspace(1)* %1, i64 %796
  %798 = load float, float addrspace(1)* %797, align 4, !tbaa !4, !amdgpu.noclobber !8
  %799 = fmul contract float %794, %798
  %800 = fadd contract float %790, %799
  %801 = add i32 %11, 79
  %802 = zext i32 %801 to i64
  %803 = getelementptr inbounds float, float addrspace(1)* %0, i64 %802
  %804 = load float, float addrspace(1)* %803, align 4, !tbaa !4, !amdgpu.noclobber !8
  %805 = add i32 %5, 80
  %806 = sext i32 %805 to i64
  %807 = getelementptr inbounds float, float addrspace(1)* %1, i64 %806
  %808 = load float, float addrspace(1)* %807, align 4, !tbaa !4, !amdgpu.noclobber !8
  %809 = fmul contract float %804, %808
  %810 = fadd contract float %800, %809
  %811 = add i32 %11, 80
  %812 = zext i32 %811 to i64
  %813 = getelementptr inbounds float, float addrspace(1)* %0, i64 %812
  %814 = load float, float addrspace(1)* %813, align 4, !tbaa !4, !amdgpu.noclobber !8
  %815 = add i32 %5, 81
  %816 = sext i32 %815 to i64
  %817 = getelementptr inbounds float, float addrspace(1)* %1, i64 %816
  %818 = load float, float addrspace(1)* %817, align 4, !tbaa !4, !amdgpu.noclobber !8
  %819 = fmul contract float %814, %818
  %820 = fadd contract float %810, %819
  %821 = add i32 %11, 81
  %822 = zext i32 %821 to i64
  %823 = getelementptr inbounds float, float addrspace(1)* %0, i64 %822
  %824 = load float, float addrspace(1)* %823, align 4, !tbaa !4, !amdgpu.noclobber !8
  %825 = add i32 %5, 82
  %826 = sext i32 %825 to i64
  %827 = getelementptr inbounds float, float addrspace(1)* %1, i64 %826
  %828 = load float, float addrspace(1)* %827, align 4, !tbaa !4, !amdgpu.noclobber !8
  %829 = fmul contract float %824, %828
  %830 = fadd contract float %820, %829
  %831 = add i32 %11, 82
  %832 = zext i32 %831 to i64
  %833 = getelementptr inbounds float, float addrspace(1)* %0, i64 %832
  %834 = load float, float addrspace(1)* %833, align 4, !tbaa !4, !amdgpu.noclobber !8
  %835 = add i32 %5, 83
  %836 = sext i32 %835 to i64
  %837 = getelementptr inbounds float, float addrspace(1)* %1, i64 %836
  %838 = load float, float addrspace(1)* %837, align 4, !tbaa !4, !amdgpu.noclobber !8
  %839 = fmul contract float %834, %838
  %840 = fadd contract float %830, %839
  %841 = add i32 %11, 83
  %842 = zext i32 %841 to i64
  %843 = getelementptr inbounds float, float addrspace(1)* %0, i64 %842
  %844 = load float, float addrspace(1)* %843, align 4, !tbaa !4, !amdgpu.noclobber !8
  %845 = add i32 %5, 84
  %846 = sext i32 %845 to i64
  %847 = getelementptr inbounds float, float addrspace(1)* %1, i64 %846
  %848 = load float, float addrspace(1)* %847, align 4, !tbaa !4, !amdgpu.noclobber !8
  %849 = fmul contract float %844, %848
  %850 = fadd contract float %840, %849
  %851 = add i32 %11, 84
  %852 = zext i32 %851 to i64
  %853 = getelementptr inbounds float, float addrspace(1)* %0, i64 %852
  %854 = load float, float addrspace(1)* %853, align 4, !tbaa !4, !amdgpu.noclobber !8
  %855 = add i32 %5, 85
  %856 = sext i32 %855 to i64
  %857 = getelementptr inbounds float, float addrspace(1)* %1, i64 %856
  %858 = load float, float addrspace(1)* %857, align 4, !tbaa !4, !amdgpu.noclobber !8
  %859 = fmul contract float %854, %858
  %860 = fadd contract float %850, %859
  %861 = add i32 %11, 85
  %862 = zext i32 %861 to i64
  %863 = getelementptr inbounds float, float addrspace(1)* %0, i64 %862
  %864 = load float, float addrspace(1)* %863, align 4, !tbaa !4, !amdgpu.noclobber !8
  %865 = add i32 %5, 86
  %866 = sext i32 %865 to i64
  %867 = getelementptr inbounds float, float addrspace(1)* %1, i64 %866
  %868 = load float, float addrspace(1)* %867, align 4, !tbaa !4, !amdgpu.noclobber !8
  %869 = fmul contract float %864, %868
  %870 = fadd contract float %860, %869
  %871 = add i32 %11, 86
  %872 = zext i32 %871 to i64
  %873 = getelementptr inbounds float, float addrspace(1)* %0, i64 %872
  %874 = load float, float addrspace(1)* %873, align 4, !tbaa !4, !amdgpu.noclobber !8
  %875 = add i32 %5, 87
  %876 = sext i32 %875 to i64
  %877 = getelementptr inbounds float, float addrspace(1)* %1, i64 %876
  %878 = load float, float addrspace(1)* %877, align 4, !tbaa !4, !amdgpu.noclobber !8
  %879 = fmul contract float %874, %878
  %880 = fadd contract float %870, %879
  %881 = add i32 %11, 87
  %882 = zext i32 %881 to i64
  %883 = getelementptr inbounds float, float addrspace(1)* %0, i64 %882
  %884 = load float, float addrspace(1)* %883, align 4, !tbaa !4, !amdgpu.noclobber !8
  %885 = add i32 %5, 88
  %886 = sext i32 %885 to i64
  %887 = getelementptr inbounds float, float addrspace(1)* %1, i64 %886
  %888 = load float, float addrspace(1)* %887, align 4, !tbaa !4, !amdgpu.noclobber !8
  %889 = fmul contract float %884, %888
  %890 = fadd contract float %880, %889
  %891 = add i32 %11, 88
  %892 = zext i32 %891 to i64
  %893 = getelementptr inbounds float, float addrspace(1)* %0, i64 %892
  %894 = load float, float addrspace(1)* %893, align 4, !tbaa !4, !amdgpu.noclobber !8
  %895 = add i32 %5, 89
  %896 = sext i32 %895 to i64
  %897 = getelementptr inbounds float, float addrspace(1)* %1, i64 %896
  %898 = load float, float addrspace(1)* %897, align 4, !tbaa !4, !amdgpu.noclobber !8
  %899 = fmul contract float %894, %898
  %900 = fadd contract float %890, %899
  %901 = add i32 %11, 89
  %902 = zext i32 %901 to i64
  %903 = getelementptr inbounds float, float addrspace(1)* %0, i64 %902
  %904 = load float, float addrspace(1)* %903, align 4, !tbaa !4, !amdgpu.noclobber !8
  %905 = add i32 %5, 90
  %906 = sext i32 %905 to i64
  %907 = getelementptr inbounds float, float addrspace(1)* %1, i64 %906
  %908 = load float, float addrspace(1)* %907, align 4, !tbaa !4, !amdgpu.noclobber !8
  %909 = fmul contract float %904, %908
  %910 = fadd contract float %900, %909
  %911 = add i32 %11, 90
  %912 = zext i32 %911 to i64
  %913 = getelementptr inbounds float, float addrspace(1)* %0, i64 %912
  %914 = load float, float addrspace(1)* %913, align 4, !tbaa !4, !amdgpu.noclobber !8
  %915 = add i32 %5, 91
  %916 = sext i32 %915 to i64
  %917 = getelementptr inbounds float, float addrspace(1)* %1, i64 %916
  %918 = load float, float addrspace(1)* %917, align 4, !tbaa !4, !amdgpu.noclobber !8
  %919 = fmul contract float %914, %918
  %920 = fadd contract float %910, %919
  %921 = add i32 %11, 91
  %922 = zext i32 %921 to i64
  %923 = getelementptr inbounds float, float addrspace(1)* %0, i64 %922
  %924 = load float, float addrspace(1)* %923, align 4, !tbaa !4, !amdgpu.noclobber !8
  %925 = add i32 %5, 92
  %926 = sext i32 %925 to i64
  %927 = getelementptr inbounds float, float addrspace(1)* %1, i64 %926
  %928 = load float, float addrspace(1)* %927, align 4, !tbaa !4, !amdgpu.noclobber !8
  %929 = fmul contract float %924, %928
  %930 = fadd contract float %920, %929
  %931 = add i32 %11, 92
  %932 = zext i32 %931 to i64
  %933 = getelementptr inbounds float, float addrspace(1)* %0, i64 %932
  %934 = load float, float addrspace(1)* %933, align 4, !tbaa !4, !amdgpu.noclobber !8
  %935 = add i32 %5, 93
  %936 = sext i32 %935 to i64
  %937 = getelementptr inbounds float, float addrspace(1)* %1, i64 %936
  %938 = load float, float addrspace(1)* %937, align 4, !tbaa !4, !amdgpu.noclobber !8
  %939 = fmul contract float %934, %938
  %940 = fadd contract float %930, %939
  %941 = add i32 %11, 93
  %942 = zext i32 %941 to i64
  %943 = getelementptr inbounds float, float addrspace(1)* %0, i64 %942
  %944 = load float, float addrspace(1)* %943, align 4, !tbaa !4, !amdgpu.noclobber !8
  %945 = add i32 %5, 94
  %946 = sext i32 %945 to i64
  %947 = getelementptr inbounds float, float addrspace(1)* %1, i64 %946
  %948 = load float, float addrspace(1)* %947, align 4, !tbaa !4, !amdgpu.noclobber !8
  %949 = fmul contract float %944, %948
  %950 = fadd contract float %940, %949
  %951 = add i32 %11, 94
  %952 = zext i32 %951 to i64
  %953 = getelementptr inbounds float, float addrspace(1)* %0, i64 %952
  %954 = load float, float addrspace(1)* %953, align 4, !tbaa !4, !amdgpu.noclobber !8
  %955 = add i32 %5, 95
  %956 = sext i32 %955 to i64
  %957 = getelementptr inbounds float, float addrspace(1)* %1, i64 %956
  %958 = load float, float addrspace(1)* %957, align 4, !tbaa !4, !amdgpu.noclobber !8
  %959 = fmul contract float %954, %958
  %960 = fadd contract float %950, %959
  %961 = add i32 %11, 95
  %962 = zext i32 %961 to i64
  %963 = getelementptr inbounds float, float addrspace(1)* %0, i64 %962
  %964 = load float, float addrspace(1)* %963, align 4, !tbaa !4, !amdgpu.noclobber !8
  %965 = add i32 %5, 96
  %966 = sext i32 %965 to i64
  %967 = getelementptr inbounds float, float addrspace(1)* %1, i64 %966
  %968 = load float, float addrspace(1)* %967, align 4, !tbaa !4, !amdgpu.noclobber !8
  %969 = fmul contract float %964, %968
  %970 = fadd contract float %960, %969
  %971 = add i32 %11, 96
  %972 = zext i32 %971 to i64
  %973 = getelementptr inbounds float, float addrspace(1)* %0, i64 %972
  %974 = load float, float addrspace(1)* %973, align 4, !tbaa !4, !amdgpu.noclobber !8
  %975 = add i32 %5, 97
  %976 = sext i32 %975 to i64
  %977 = getelementptr inbounds float, float addrspace(1)* %1, i64 %976
  %978 = load float, float addrspace(1)* %977, align 4, !tbaa !4, !amdgpu.noclobber !8
  %979 = fmul contract float %974, %978
  %980 = fadd contract float %970, %979
  %981 = add i32 %11, 97
  %982 = zext i32 %981 to i64
  %983 = getelementptr inbounds float, float addrspace(1)* %0, i64 %982
  %984 = load float, float addrspace(1)* %983, align 4, !tbaa !4, !amdgpu.noclobber !8
  %985 = add i32 %5, 98
  %986 = sext i32 %985 to i64
  %987 = getelementptr inbounds float, float addrspace(1)* %1, i64 %986
  %988 = load float, float addrspace(1)* %987, align 4, !tbaa !4, !amdgpu.noclobber !8
  %989 = fmul contract float %984, %988
  %990 = fadd contract float %980, %989
  %991 = add i32 %11, 98
  %992 = zext i32 %991 to i64
  %993 = getelementptr inbounds float, float addrspace(1)* %0, i64 %992
  %994 = load float, float addrspace(1)* %993, align 4, !tbaa !4, !amdgpu.noclobber !8
  %995 = add i32 %5, 99
  %996 = sext i32 %995 to i64
  %997 = getelementptr inbounds float, float addrspace(1)* %1, i64 %996
  %998 = load float, float addrspace(1)* %997, align 4, !tbaa !4, !amdgpu.noclobber !8
  %999 = fmul contract float %994, %998
  %1000 = fadd contract float %990, %999
  %1001 = add i32 %11, 99
  %1002 = zext i32 %1001 to i64
  %1003 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1002
  %1004 = load float, float addrspace(1)* %1003, align 4, !tbaa !4, !amdgpu.noclobber !8
  %1005 = add i32 %5, 100
  %1006 = sext i32 %1005 to i64
  %1007 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1006
  %1008 = load float, float addrspace(1)* %1007, align 4, !tbaa !4, !amdgpu.noclobber !8
  %1009 = fmul contract float %1004, %1008
  %1010 = fadd contract float %1000, %1009
  %1011 = fpext float %1010 to double
  %1012 = fmul contract double %1011, 0x3FE55555571F7693
  %1013 = fptrunc double %1012 to float
  %1014 = tail call float @llvm.fabs.f32(float %1013)
  %1015 = fcmp olt float %1014, 6.250000e-01
  br i1 %1015, label %1016, label %1024

1016:                                             ; preds = %3
  %1017 = fmul float %1013, %1013
  %1018 = tail call float @llvm.fmuladd.f32(float %1017, float 0xBF7758E7A0000000, float 0x3F95211920000000)
  %1019 = tail call float @llvm.fmuladd.f32(float %1017, float %1018, float 0xBFAB8389C0000000)
  %1020 = tail call float @llvm.fmuladd.f32(float %1017, float %1019, float 0x3FC1107040000000)
  %1021 = tail call float @llvm.fmuladd.f32(float %1017, float %1020, float 0xBFD5555320000000)
  %1022 = fmul float %1014, %1021
  %1023 = tail call float @llvm.fmuladd.f32(float %1017, float %1022, float %1014)
  br label %1041

1024:                                             ; preds = %3
  %1025 = fmul float %1014, 2.000000e+00
  %1026 = fmul float %1025, 0x3FF7154760000000
  %1027 = tail call float @llvm.rint.f32(float %1026)
  %1028 = fcmp ogt float %1025, 0x40562E4300000000
  %1029 = fneg float %1026
  %1030 = tail call float @llvm.fma.f32(float %1025, float 0x3FF7154760000000, float %1029)
  %1031 = tail call float @llvm.fma.f32(float %1025, float 0x3E54AE0BE0000000, float %1030)
  %1032 = fsub float %1026, %1027
  %1033 = fadd float %1031, %1032
  %1034 = tail call float @llvm.exp2.f32(float %1033)
  %1035 = fptosi float %1027 to i32
  %1036 = tail call float @llvm.amdgcn.ldexp.f32(float %1034, i32 %1035)
  %1037 = fadd float %1036, 1.000000e+00
  %1038 = select i1 %1028, float 0x7FF0000000000000, float %1037
  %1039 = tail call float @llvm.amdgcn.rcp.f32(float %1038)
  %1040 = tail call float @llvm.fmuladd.f32(float %1039, float -2.000000e+00, float 1.000000e+00)
  br label %1041

1041:                                             ; preds = %1016, %1024
  %1042 = phi float [ %1023, %1016 ], [ %1040, %1024 ]
  %1043 = tail call float @llvm.copysign.f32(float %1042, float %1013)
  %1044 = fpext float %1043 to double
  %1045 = fmul contract double %1044, 1.715900e+00
  %1046 = fptrunc double %1045 to float
  %1047 = mul i32 %10, 10
  %1048 = add i32 %1047, %4
  %1049 = zext i32 %1048 to i64
  %1050 = getelementptr inbounds float, float addrspace(1)* %2, i64 %1049
  store float %1046, float addrspace(1)* %1050, align 4, !tbaa !4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.fabs.f32(float) #1

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.amdgcn.rcp.f32(float) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.copysign.f32(float, float) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.exp2.f32(float) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.fma.f32(float, float, float) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.rint.f32(float) #1

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.amdgcn.ldexp.f32(float, i32) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.fmuladd.f32(float, float, float) #1

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.x() #2

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.y() #2

attributes #0 = { argmemonly mustprogress nofree norecurse nosync nounwind "amdgpu-flat-work-group-size"="1,256" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx906" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+s-memrealtime,+s-memtime-inst,+sramecc" "uniform-work-group-size"="true" }
attributes #1 = { mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn }
attributes #2 = { mustprogress nofree nosync nounwind readnone speculatable willreturn }

!llvm.module.flags = !{!0, !1}
!opencl.ocl.version = !{!2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 1}
!2 = !{i32 2, i32 0}
!3 = !{!"clang version 15.0.0 (http://10.15.3.7/dcutoolkit/driverruntime/llvm-project.git 340750feeda88c9c2ce8ad481b11d9aa7f033d39)"}
!4 = !{!5, !5, i64 0}
!5 = !{!"float", !6, i64 0}
!6 = !{!"omnipotent char", !7, i64 0}
!7 = !{!"Simple C++ TBAA"}
!8 = !{}
