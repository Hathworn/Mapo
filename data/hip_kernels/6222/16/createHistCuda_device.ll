; ModuleID = '../data/hip_kernels/6222/16/main.cu'
source_filename = "../data/hip_kernels/6222/16/main.cu"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@_ZZ14createHistCudaPfS_iiS_E7cosines = internal unnamed_addr addrspace(3) global [1024 x [2 x float]] undef, align 16

; Function Attrs: convergent mustprogress norecurse nounwind
define protected amdgpu_kernel void @_Z14createHistCudaPfS_iiS_(float addrspace(1)* nocapture readonly %0, float addrspace(1)* nocapture readonly %1, i32 %2, i32 %3, float addrspace(1)* nocapture writeonly %4) local_unnamed_addr #0 {
  %6 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %7 = tail call align 4 dereferenceable(64) i8 addrspace(4)* @llvm.amdgcn.dispatch.ptr()
  %8 = getelementptr i8, i8 addrspace(4)* %7, i64 4
  %9 = bitcast i8 addrspace(4)* %8 to i16 addrspace(4)*
  %10 = load i16, i16 addrspace(4)* %9, align 4, !range !4, !invariant.load !5
  %11 = zext i16 %10 to i32
  %12 = getelementptr inbounds i8, i8 addrspace(4)* %7, i64 12
  %13 = bitcast i8 addrspace(4)* %12 to i32 addrspace(4)*
  %14 = load i32, i32 addrspace(4)* %13, align 4, !tbaa !6
  %15 = mul i32 %6, %11
  %16 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !15
  %17 = add i32 %15, %16
  %18 = zext i32 %17 to i64
  %19 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %20 = sext i32 %2 to i64
  %21 = icmp ult i64 %18, %20
  br i1 %21, label %22, label %1896

22:                                               ; preds = %5
  %23 = shl i32 %17, 7
  %24 = shl i32 %19, 7
  %25 = sext i32 %23 to i64
  %26 = getelementptr inbounds float, float addrspace(1)* %0, i64 %25
  %27 = load float, float addrspace(1)* %26, align 4, !tbaa !16, !amdgpu.noclobber !5
  %28 = sext i32 %24 to i64
  %29 = getelementptr inbounds float, float addrspace(1)* %1, i64 %28
  %30 = load float, float addrspace(1)* %29, align 4, !tbaa !16, !amdgpu.noclobber !5
  %31 = fmul contract float %27, %30
  %32 = fadd contract float %31, 0.000000e+00
  %33 = fmul contract float %30, %30
  %34 = fadd contract float %33, 0.000000e+00
  %35 = fmul contract float %27, %27
  %36 = fadd contract float %35, 0.000000e+00
  %37 = add nuw nsw i32 %23, 1
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds float, float addrspace(1)* %0, i64 %38
  %40 = load float, float addrspace(1)* %39, align 4, !tbaa !16, !amdgpu.noclobber !5
  %41 = add nuw nsw i32 %24, 1
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds float, float addrspace(1)* %1, i64 %42
  %44 = load float, float addrspace(1)* %43, align 4, !tbaa !16, !amdgpu.noclobber !5
  %45 = fmul contract float %40, %44
  %46 = fadd contract float %32, %45
  %47 = fmul contract float %44, %44
  %48 = fadd contract float %34, %47
  %49 = fmul contract float %40, %40
  %50 = fadd contract float %36, %49
  %51 = add nuw nsw i32 %23, 2
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds float, float addrspace(1)* %0, i64 %52
  %54 = load float, float addrspace(1)* %53, align 4, !tbaa !16, !amdgpu.noclobber !5
  %55 = add nuw nsw i32 %24, 2
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds float, float addrspace(1)* %1, i64 %56
  %58 = load float, float addrspace(1)* %57, align 4, !tbaa !16, !amdgpu.noclobber !5
  %59 = fmul contract float %54, %58
  %60 = fadd contract float %46, %59
  %61 = fmul contract float %58, %58
  %62 = fadd contract float %48, %61
  %63 = fmul contract float %54, %54
  %64 = fadd contract float %50, %63
  %65 = add nuw nsw i32 %23, 3
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float addrspace(1)* %0, i64 %66
  %68 = load float, float addrspace(1)* %67, align 4, !tbaa !16, !amdgpu.noclobber !5
  %69 = add nuw nsw i32 %24, 3
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds float, float addrspace(1)* %1, i64 %70
  %72 = load float, float addrspace(1)* %71, align 4, !tbaa !16, !amdgpu.noclobber !5
  %73 = fmul contract float %68, %72
  %74 = fadd contract float %60, %73
  %75 = fmul contract float %72, %72
  %76 = fadd contract float %62, %75
  %77 = fmul contract float %68, %68
  %78 = fadd contract float %64, %77
  %79 = add nuw nsw i32 %23, 4
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds float, float addrspace(1)* %0, i64 %80
  %82 = load float, float addrspace(1)* %81, align 4, !tbaa !16, !amdgpu.noclobber !5
  %83 = add nuw nsw i32 %24, 4
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds float, float addrspace(1)* %1, i64 %84
  %86 = load float, float addrspace(1)* %85, align 4, !tbaa !16, !amdgpu.noclobber !5
  %87 = fmul contract float %82, %86
  %88 = fadd contract float %74, %87
  %89 = fmul contract float %86, %86
  %90 = fadd contract float %76, %89
  %91 = fmul contract float %82, %82
  %92 = fadd contract float %78, %91
  %93 = add nuw nsw i32 %23, 5
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float addrspace(1)* %0, i64 %94
  %96 = load float, float addrspace(1)* %95, align 4, !tbaa !16, !amdgpu.noclobber !5
  %97 = add nuw nsw i32 %24, 5
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float addrspace(1)* %1, i64 %98
  %100 = load float, float addrspace(1)* %99, align 4, !tbaa !16, !amdgpu.noclobber !5
  %101 = fmul contract float %96, %100
  %102 = fadd contract float %88, %101
  %103 = fmul contract float %100, %100
  %104 = fadd contract float %90, %103
  %105 = fmul contract float %96, %96
  %106 = fadd contract float %92, %105
  %107 = add nuw nsw i32 %23, 6
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds float, float addrspace(1)* %0, i64 %108
  %110 = load float, float addrspace(1)* %109, align 4, !tbaa !16, !amdgpu.noclobber !5
  %111 = add nuw nsw i32 %24, 6
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds float, float addrspace(1)* %1, i64 %112
  %114 = load float, float addrspace(1)* %113, align 4, !tbaa !16, !amdgpu.noclobber !5
  %115 = fmul contract float %110, %114
  %116 = fadd contract float %102, %115
  %117 = fmul contract float %114, %114
  %118 = fadd contract float %104, %117
  %119 = fmul contract float %110, %110
  %120 = fadd contract float %106, %119
  %121 = add nuw nsw i32 %23, 7
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds float, float addrspace(1)* %0, i64 %122
  %124 = load float, float addrspace(1)* %123, align 4, !tbaa !16, !amdgpu.noclobber !5
  %125 = add nuw nsw i32 %24, 7
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float addrspace(1)* %1, i64 %126
  %128 = load float, float addrspace(1)* %127, align 4, !tbaa !16, !amdgpu.noclobber !5
  %129 = fmul contract float %124, %128
  %130 = fadd contract float %116, %129
  %131 = fmul contract float %128, %128
  %132 = fadd contract float %118, %131
  %133 = fmul contract float %124, %124
  %134 = fadd contract float %120, %133
  %135 = add nuw nsw i32 %23, 8
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float addrspace(1)* %0, i64 %136
  %138 = load float, float addrspace(1)* %137, align 4, !tbaa !16, !amdgpu.noclobber !5
  %139 = add nuw nsw i32 %24, 8
  %140 = sext i32 %139 to i64
  %141 = getelementptr inbounds float, float addrspace(1)* %1, i64 %140
  %142 = load float, float addrspace(1)* %141, align 4, !tbaa !16, !amdgpu.noclobber !5
  %143 = fmul contract float %138, %142
  %144 = fadd contract float %130, %143
  %145 = fmul contract float %142, %142
  %146 = fadd contract float %132, %145
  %147 = fmul contract float %138, %138
  %148 = fadd contract float %134, %147
  %149 = add nuw nsw i32 %23, 9
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds float, float addrspace(1)* %0, i64 %150
  %152 = load float, float addrspace(1)* %151, align 4, !tbaa !16, !amdgpu.noclobber !5
  %153 = add nuw nsw i32 %24, 9
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float addrspace(1)* %1, i64 %154
  %156 = load float, float addrspace(1)* %155, align 4, !tbaa !16, !amdgpu.noclobber !5
  %157 = fmul contract float %152, %156
  %158 = fadd contract float %144, %157
  %159 = fmul contract float %156, %156
  %160 = fadd contract float %146, %159
  %161 = fmul contract float %152, %152
  %162 = fadd contract float %148, %161
  %163 = add nuw nsw i32 %23, 10
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds float, float addrspace(1)* %0, i64 %164
  %166 = load float, float addrspace(1)* %165, align 4, !tbaa !16, !amdgpu.noclobber !5
  %167 = add nuw nsw i32 %24, 10
  %168 = sext i32 %167 to i64
  %169 = getelementptr inbounds float, float addrspace(1)* %1, i64 %168
  %170 = load float, float addrspace(1)* %169, align 4, !tbaa !16, !amdgpu.noclobber !5
  %171 = fmul contract float %166, %170
  %172 = fadd contract float %158, %171
  %173 = fmul contract float %170, %170
  %174 = fadd contract float %160, %173
  %175 = fmul contract float %166, %166
  %176 = fadd contract float %162, %175
  %177 = add nuw nsw i32 %23, 11
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds float, float addrspace(1)* %0, i64 %178
  %180 = load float, float addrspace(1)* %179, align 4, !tbaa !16, !amdgpu.noclobber !5
  %181 = add nuw nsw i32 %24, 11
  %182 = sext i32 %181 to i64
  %183 = getelementptr inbounds float, float addrspace(1)* %1, i64 %182
  %184 = load float, float addrspace(1)* %183, align 4, !tbaa !16, !amdgpu.noclobber !5
  %185 = fmul contract float %180, %184
  %186 = fadd contract float %172, %185
  %187 = fmul contract float %184, %184
  %188 = fadd contract float %174, %187
  %189 = fmul contract float %180, %180
  %190 = fadd contract float %176, %189
  %191 = add nuw nsw i32 %23, 12
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds float, float addrspace(1)* %0, i64 %192
  %194 = load float, float addrspace(1)* %193, align 4, !tbaa !16, !amdgpu.noclobber !5
  %195 = add nuw nsw i32 %24, 12
  %196 = sext i32 %195 to i64
  %197 = getelementptr inbounds float, float addrspace(1)* %1, i64 %196
  %198 = load float, float addrspace(1)* %197, align 4, !tbaa !16, !amdgpu.noclobber !5
  %199 = fmul contract float %194, %198
  %200 = fadd contract float %186, %199
  %201 = fmul contract float %198, %198
  %202 = fadd contract float %188, %201
  %203 = fmul contract float %194, %194
  %204 = fadd contract float %190, %203
  %205 = add nuw nsw i32 %23, 13
  %206 = sext i32 %205 to i64
  %207 = getelementptr inbounds float, float addrspace(1)* %0, i64 %206
  %208 = load float, float addrspace(1)* %207, align 4, !tbaa !16, !amdgpu.noclobber !5
  %209 = add nuw nsw i32 %24, 13
  %210 = sext i32 %209 to i64
  %211 = getelementptr inbounds float, float addrspace(1)* %1, i64 %210
  %212 = load float, float addrspace(1)* %211, align 4, !tbaa !16, !amdgpu.noclobber !5
  %213 = fmul contract float %208, %212
  %214 = fadd contract float %200, %213
  %215 = fmul contract float %212, %212
  %216 = fadd contract float %202, %215
  %217 = fmul contract float %208, %208
  %218 = fadd contract float %204, %217
  %219 = add nuw nsw i32 %23, 14
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds float, float addrspace(1)* %0, i64 %220
  %222 = load float, float addrspace(1)* %221, align 4, !tbaa !16, !amdgpu.noclobber !5
  %223 = add nuw nsw i32 %24, 14
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds float, float addrspace(1)* %1, i64 %224
  %226 = load float, float addrspace(1)* %225, align 4, !tbaa !16, !amdgpu.noclobber !5
  %227 = fmul contract float %222, %226
  %228 = fadd contract float %214, %227
  %229 = fmul contract float %226, %226
  %230 = fadd contract float %216, %229
  %231 = fmul contract float %222, %222
  %232 = fadd contract float %218, %231
  %233 = add nuw nsw i32 %23, 15
  %234 = sext i32 %233 to i64
  %235 = getelementptr inbounds float, float addrspace(1)* %0, i64 %234
  %236 = load float, float addrspace(1)* %235, align 4, !tbaa !16, !amdgpu.noclobber !5
  %237 = add nuw nsw i32 %24, 15
  %238 = sext i32 %237 to i64
  %239 = getelementptr inbounds float, float addrspace(1)* %1, i64 %238
  %240 = load float, float addrspace(1)* %239, align 4, !tbaa !16, !amdgpu.noclobber !5
  %241 = fmul contract float %236, %240
  %242 = fadd contract float %228, %241
  %243 = fmul contract float %240, %240
  %244 = fadd contract float %230, %243
  %245 = fmul contract float %236, %236
  %246 = fadd contract float %232, %245
  %247 = add nuw nsw i32 %23, 16
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds float, float addrspace(1)* %0, i64 %248
  %250 = load float, float addrspace(1)* %249, align 4, !tbaa !16, !amdgpu.noclobber !5
  %251 = add nuw nsw i32 %24, 16
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds float, float addrspace(1)* %1, i64 %252
  %254 = load float, float addrspace(1)* %253, align 4, !tbaa !16, !amdgpu.noclobber !5
  %255 = fmul contract float %250, %254
  %256 = fadd contract float %242, %255
  %257 = fmul contract float %254, %254
  %258 = fadd contract float %244, %257
  %259 = fmul contract float %250, %250
  %260 = fadd contract float %246, %259
  %261 = add nuw nsw i32 %23, 17
  %262 = sext i32 %261 to i64
  %263 = getelementptr inbounds float, float addrspace(1)* %0, i64 %262
  %264 = load float, float addrspace(1)* %263, align 4, !tbaa !16, !amdgpu.noclobber !5
  %265 = add nuw nsw i32 %24, 17
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds float, float addrspace(1)* %1, i64 %266
  %268 = load float, float addrspace(1)* %267, align 4, !tbaa !16, !amdgpu.noclobber !5
  %269 = fmul contract float %264, %268
  %270 = fadd contract float %256, %269
  %271 = fmul contract float %268, %268
  %272 = fadd contract float %258, %271
  %273 = fmul contract float %264, %264
  %274 = fadd contract float %260, %273
  %275 = add nuw nsw i32 %23, 18
  %276 = sext i32 %275 to i64
  %277 = getelementptr inbounds float, float addrspace(1)* %0, i64 %276
  %278 = load float, float addrspace(1)* %277, align 4, !tbaa !16, !amdgpu.noclobber !5
  %279 = add nuw nsw i32 %24, 18
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds float, float addrspace(1)* %1, i64 %280
  %282 = load float, float addrspace(1)* %281, align 4, !tbaa !16, !amdgpu.noclobber !5
  %283 = fmul contract float %278, %282
  %284 = fadd contract float %270, %283
  %285 = fmul contract float %282, %282
  %286 = fadd contract float %272, %285
  %287 = fmul contract float %278, %278
  %288 = fadd contract float %274, %287
  %289 = add nuw nsw i32 %23, 19
  %290 = sext i32 %289 to i64
  %291 = getelementptr inbounds float, float addrspace(1)* %0, i64 %290
  %292 = load float, float addrspace(1)* %291, align 4, !tbaa !16, !amdgpu.noclobber !5
  %293 = add nuw nsw i32 %24, 19
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds float, float addrspace(1)* %1, i64 %294
  %296 = load float, float addrspace(1)* %295, align 4, !tbaa !16, !amdgpu.noclobber !5
  %297 = fmul contract float %292, %296
  %298 = fadd contract float %284, %297
  %299 = fmul contract float %296, %296
  %300 = fadd contract float %286, %299
  %301 = fmul contract float %292, %292
  %302 = fadd contract float %288, %301
  %303 = add nuw nsw i32 %23, 20
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds float, float addrspace(1)* %0, i64 %304
  %306 = load float, float addrspace(1)* %305, align 4, !tbaa !16, !amdgpu.noclobber !5
  %307 = add nuw nsw i32 %24, 20
  %308 = sext i32 %307 to i64
  %309 = getelementptr inbounds float, float addrspace(1)* %1, i64 %308
  %310 = load float, float addrspace(1)* %309, align 4, !tbaa !16, !amdgpu.noclobber !5
  %311 = fmul contract float %306, %310
  %312 = fadd contract float %298, %311
  %313 = fmul contract float %310, %310
  %314 = fadd contract float %300, %313
  %315 = fmul contract float %306, %306
  %316 = fadd contract float %302, %315
  %317 = add nuw nsw i32 %23, 21
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds float, float addrspace(1)* %0, i64 %318
  %320 = load float, float addrspace(1)* %319, align 4, !tbaa !16, !amdgpu.noclobber !5
  %321 = add nuw nsw i32 %24, 21
  %322 = sext i32 %321 to i64
  %323 = getelementptr inbounds float, float addrspace(1)* %1, i64 %322
  %324 = load float, float addrspace(1)* %323, align 4, !tbaa !16, !amdgpu.noclobber !5
  %325 = fmul contract float %320, %324
  %326 = fadd contract float %312, %325
  %327 = fmul contract float %324, %324
  %328 = fadd contract float %314, %327
  %329 = fmul contract float %320, %320
  %330 = fadd contract float %316, %329
  %331 = add nuw nsw i32 %23, 22
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds float, float addrspace(1)* %0, i64 %332
  %334 = load float, float addrspace(1)* %333, align 4, !tbaa !16, !amdgpu.noclobber !5
  %335 = add nuw nsw i32 %24, 22
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds float, float addrspace(1)* %1, i64 %336
  %338 = load float, float addrspace(1)* %337, align 4, !tbaa !16, !amdgpu.noclobber !5
  %339 = fmul contract float %334, %338
  %340 = fadd contract float %326, %339
  %341 = fmul contract float %338, %338
  %342 = fadd contract float %328, %341
  %343 = fmul contract float %334, %334
  %344 = fadd contract float %330, %343
  %345 = add nuw nsw i32 %23, 23
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds float, float addrspace(1)* %0, i64 %346
  %348 = load float, float addrspace(1)* %347, align 4, !tbaa !16, !amdgpu.noclobber !5
  %349 = add nuw nsw i32 %24, 23
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds float, float addrspace(1)* %1, i64 %350
  %352 = load float, float addrspace(1)* %351, align 4, !tbaa !16, !amdgpu.noclobber !5
  %353 = fmul contract float %348, %352
  %354 = fadd contract float %340, %353
  %355 = fmul contract float %352, %352
  %356 = fadd contract float %342, %355
  %357 = fmul contract float %348, %348
  %358 = fadd contract float %344, %357
  %359 = add nuw nsw i32 %23, 24
  %360 = sext i32 %359 to i64
  %361 = getelementptr inbounds float, float addrspace(1)* %0, i64 %360
  %362 = load float, float addrspace(1)* %361, align 4, !tbaa !16, !amdgpu.noclobber !5
  %363 = add nuw nsw i32 %24, 24
  %364 = sext i32 %363 to i64
  %365 = getelementptr inbounds float, float addrspace(1)* %1, i64 %364
  %366 = load float, float addrspace(1)* %365, align 4, !tbaa !16, !amdgpu.noclobber !5
  %367 = fmul contract float %362, %366
  %368 = fadd contract float %354, %367
  %369 = fmul contract float %366, %366
  %370 = fadd contract float %356, %369
  %371 = fmul contract float %362, %362
  %372 = fadd contract float %358, %371
  %373 = add nuw nsw i32 %23, 25
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds float, float addrspace(1)* %0, i64 %374
  %376 = load float, float addrspace(1)* %375, align 4, !tbaa !16, !amdgpu.noclobber !5
  %377 = add nuw nsw i32 %24, 25
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds float, float addrspace(1)* %1, i64 %378
  %380 = load float, float addrspace(1)* %379, align 4, !tbaa !16, !amdgpu.noclobber !5
  %381 = fmul contract float %376, %380
  %382 = fadd contract float %368, %381
  %383 = fmul contract float %380, %380
  %384 = fadd contract float %370, %383
  %385 = fmul contract float %376, %376
  %386 = fadd contract float %372, %385
  %387 = add nuw nsw i32 %23, 26
  %388 = sext i32 %387 to i64
  %389 = getelementptr inbounds float, float addrspace(1)* %0, i64 %388
  %390 = load float, float addrspace(1)* %389, align 4, !tbaa !16, !amdgpu.noclobber !5
  %391 = add nuw nsw i32 %24, 26
  %392 = sext i32 %391 to i64
  %393 = getelementptr inbounds float, float addrspace(1)* %1, i64 %392
  %394 = load float, float addrspace(1)* %393, align 4, !tbaa !16, !amdgpu.noclobber !5
  %395 = fmul contract float %390, %394
  %396 = fadd contract float %382, %395
  %397 = fmul contract float %394, %394
  %398 = fadd contract float %384, %397
  %399 = fmul contract float %390, %390
  %400 = fadd contract float %386, %399
  %401 = add nuw nsw i32 %23, 27
  %402 = sext i32 %401 to i64
  %403 = getelementptr inbounds float, float addrspace(1)* %0, i64 %402
  %404 = load float, float addrspace(1)* %403, align 4, !tbaa !16, !amdgpu.noclobber !5
  %405 = add nuw nsw i32 %24, 27
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds float, float addrspace(1)* %1, i64 %406
  %408 = load float, float addrspace(1)* %407, align 4, !tbaa !16, !amdgpu.noclobber !5
  %409 = fmul contract float %404, %408
  %410 = fadd contract float %396, %409
  %411 = fmul contract float %408, %408
  %412 = fadd contract float %398, %411
  %413 = fmul contract float %404, %404
  %414 = fadd contract float %400, %413
  %415 = add nuw nsw i32 %23, 28
  %416 = sext i32 %415 to i64
  %417 = getelementptr inbounds float, float addrspace(1)* %0, i64 %416
  %418 = load float, float addrspace(1)* %417, align 4, !tbaa !16, !amdgpu.noclobber !5
  %419 = add nuw nsw i32 %24, 28
  %420 = sext i32 %419 to i64
  %421 = getelementptr inbounds float, float addrspace(1)* %1, i64 %420
  %422 = load float, float addrspace(1)* %421, align 4, !tbaa !16, !amdgpu.noclobber !5
  %423 = fmul contract float %418, %422
  %424 = fadd contract float %410, %423
  %425 = fmul contract float %422, %422
  %426 = fadd contract float %412, %425
  %427 = fmul contract float %418, %418
  %428 = fadd contract float %414, %427
  %429 = add nuw nsw i32 %23, 29
  %430 = sext i32 %429 to i64
  %431 = getelementptr inbounds float, float addrspace(1)* %0, i64 %430
  %432 = load float, float addrspace(1)* %431, align 4, !tbaa !16, !amdgpu.noclobber !5
  %433 = add nuw nsw i32 %24, 29
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds float, float addrspace(1)* %1, i64 %434
  %436 = load float, float addrspace(1)* %435, align 4, !tbaa !16, !amdgpu.noclobber !5
  %437 = fmul contract float %432, %436
  %438 = fadd contract float %424, %437
  %439 = fmul contract float %436, %436
  %440 = fadd contract float %426, %439
  %441 = fmul contract float %432, %432
  %442 = fadd contract float %428, %441
  %443 = add nuw nsw i32 %23, 30
  %444 = sext i32 %443 to i64
  %445 = getelementptr inbounds float, float addrspace(1)* %0, i64 %444
  %446 = load float, float addrspace(1)* %445, align 4, !tbaa !16, !amdgpu.noclobber !5
  %447 = add nuw nsw i32 %24, 30
  %448 = sext i32 %447 to i64
  %449 = getelementptr inbounds float, float addrspace(1)* %1, i64 %448
  %450 = load float, float addrspace(1)* %449, align 4, !tbaa !16, !amdgpu.noclobber !5
  %451 = fmul contract float %446, %450
  %452 = fadd contract float %438, %451
  %453 = fmul contract float %450, %450
  %454 = fadd contract float %440, %453
  %455 = fmul contract float %446, %446
  %456 = fadd contract float %442, %455
  %457 = add nuw nsw i32 %23, 31
  %458 = sext i32 %457 to i64
  %459 = getelementptr inbounds float, float addrspace(1)* %0, i64 %458
  %460 = load float, float addrspace(1)* %459, align 4, !tbaa !16, !amdgpu.noclobber !5
  %461 = add nuw nsw i32 %24, 31
  %462 = sext i32 %461 to i64
  %463 = getelementptr inbounds float, float addrspace(1)* %1, i64 %462
  %464 = load float, float addrspace(1)* %463, align 4, !tbaa !16, !amdgpu.noclobber !5
  %465 = fmul contract float %460, %464
  %466 = fadd contract float %452, %465
  %467 = fmul contract float %464, %464
  %468 = fadd contract float %454, %467
  %469 = fmul contract float %460, %460
  %470 = fadd contract float %456, %469
  %471 = add nuw nsw i32 %23, 32
  %472 = sext i32 %471 to i64
  %473 = getelementptr inbounds float, float addrspace(1)* %0, i64 %472
  %474 = load float, float addrspace(1)* %473, align 4, !tbaa !16, !amdgpu.noclobber !5
  %475 = add nuw nsw i32 %24, 32
  %476 = sext i32 %475 to i64
  %477 = getelementptr inbounds float, float addrspace(1)* %1, i64 %476
  %478 = load float, float addrspace(1)* %477, align 4, !tbaa !16, !amdgpu.noclobber !5
  %479 = fmul contract float %474, %478
  %480 = fadd contract float %466, %479
  %481 = fmul contract float %478, %478
  %482 = fadd contract float %468, %481
  %483 = fmul contract float %474, %474
  %484 = fadd contract float %470, %483
  %485 = add nuw nsw i32 %23, 33
  %486 = sext i32 %485 to i64
  %487 = getelementptr inbounds float, float addrspace(1)* %0, i64 %486
  %488 = load float, float addrspace(1)* %487, align 4, !tbaa !16, !amdgpu.noclobber !5
  %489 = add nuw nsw i32 %24, 33
  %490 = sext i32 %489 to i64
  %491 = getelementptr inbounds float, float addrspace(1)* %1, i64 %490
  %492 = load float, float addrspace(1)* %491, align 4, !tbaa !16, !amdgpu.noclobber !5
  %493 = fmul contract float %488, %492
  %494 = fadd contract float %480, %493
  %495 = fmul contract float %492, %492
  %496 = fadd contract float %482, %495
  %497 = fmul contract float %488, %488
  %498 = fadd contract float %484, %497
  %499 = add nuw nsw i32 %23, 34
  %500 = sext i32 %499 to i64
  %501 = getelementptr inbounds float, float addrspace(1)* %0, i64 %500
  %502 = load float, float addrspace(1)* %501, align 4, !tbaa !16, !amdgpu.noclobber !5
  %503 = add nuw nsw i32 %24, 34
  %504 = sext i32 %503 to i64
  %505 = getelementptr inbounds float, float addrspace(1)* %1, i64 %504
  %506 = load float, float addrspace(1)* %505, align 4, !tbaa !16, !amdgpu.noclobber !5
  %507 = fmul contract float %502, %506
  %508 = fadd contract float %494, %507
  %509 = fmul contract float %506, %506
  %510 = fadd contract float %496, %509
  %511 = fmul contract float %502, %502
  %512 = fadd contract float %498, %511
  %513 = add nuw nsw i32 %23, 35
  %514 = sext i32 %513 to i64
  %515 = getelementptr inbounds float, float addrspace(1)* %0, i64 %514
  %516 = load float, float addrspace(1)* %515, align 4, !tbaa !16, !amdgpu.noclobber !5
  %517 = add nuw nsw i32 %24, 35
  %518 = sext i32 %517 to i64
  %519 = getelementptr inbounds float, float addrspace(1)* %1, i64 %518
  %520 = load float, float addrspace(1)* %519, align 4, !tbaa !16, !amdgpu.noclobber !5
  %521 = fmul contract float %516, %520
  %522 = fadd contract float %508, %521
  %523 = fmul contract float %520, %520
  %524 = fadd contract float %510, %523
  %525 = fmul contract float %516, %516
  %526 = fadd contract float %512, %525
  %527 = add nuw nsw i32 %23, 36
  %528 = sext i32 %527 to i64
  %529 = getelementptr inbounds float, float addrspace(1)* %0, i64 %528
  %530 = load float, float addrspace(1)* %529, align 4, !tbaa !16, !amdgpu.noclobber !5
  %531 = add nuw nsw i32 %24, 36
  %532 = sext i32 %531 to i64
  %533 = getelementptr inbounds float, float addrspace(1)* %1, i64 %532
  %534 = load float, float addrspace(1)* %533, align 4, !tbaa !16, !amdgpu.noclobber !5
  %535 = fmul contract float %530, %534
  %536 = fadd contract float %522, %535
  %537 = fmul contract float %534, %534
  %538 = fadd contract float %524, %537
  %539 = fmul contract float %530, %530
  %540 = fadd contract float %526, %539
  %541 = add nuw nsw i32 %23, 37
  %542 = sext i32 %541 to i64
  %543 = getelementptr inbounds float, float addrspace(1)* %0, i64 %542
  %544 = load float, float addrspace(1)* %543, align 4, !tbaa !16, !amdgpu.noclobber !5
  %545 = add nuw nsw i32 %24, 37
  %546 = sext i32 %545 to i64
  %547 = getelementptr inbounds float, float addrspace(1)* %1, i64 %546
  %548 = load float, float addrspace(1)* %547, align 4, !tbaa !16, !amdgpu.noclobber !5
  %549 = fmul contract float %544, %548
  %550 = fadd contract float %536, %549
  %551 = fmul contract float %548, %548
  %552 = fadd contract float %538, %551
  %553 = fmul contract float %544, %544
  %554 = fadd contract float %540, %553
  %555 = add nuw nsw i32 %23, 38
  %556 = sext i32 %555 to i64
  %557 = getelementptr inbounds float, float addrspace(1)* %0, i64 %556
  %558 = load float, float addrspace(1)* %557, align 4, !tbaa !16, !amdgpu.noclobber !5
  %559 = add nuw nsw i32 %24, 38
  %560 = sext i32 %559 to i64
  %561 = getelementptr inbounds float, float addrspace(1)* %1, i64 %560
  %562 = load float, float addrspace(1)* %561, align 4, !tbaa !16, !amdgpu.noclobber !5
  %563 = fmul contract float %558, %562
  %564 = fadd contract float %550, %563
  %565 = fmul contract float %562, %562
  %566 = fadd contract float %552, %565
  %567 = fmul contract float %558, %558
  %568 = fadd contract float %554, %567
  %569 = add nuw nsw i32 %23, 39
  %570 = sext i32 %569 to i64
  %571 = getelementptr inbounds float, float addrspace(1)* %0, i64 %570
  %572 = load float, float addrspace(1)* %571, align 4, !tbaa !16, !amdgpu.noclobber !5
  %573 = add nuw nsw i32 %24, 39
  %574 = sext i32 %573 to i64
  %575 = getelementptr inbounds float, float addrspace(1)* %1, i64 %574
  %576 = load float, float addrspace(1)* %575, align 4, !tbaa !16, !amdgpu.noclobber !5
  %577 = fmul contract float %572, %576
  %578 = fadd contract float %564, %577
  %579 = fmul contract float %576, %576
  %580 = fadd contract float %566, %579
  %581 = fmul contract float %572, %572
  %582 = fadd contract float %568, %581
  %583 = add nuw nsw i32 %23, 40
  %584 = sext i32 %583 to i64
  %585 = getelementptr inbounds float, float addrspace(1)* %0, i64 %584
  %586 = load float, float addrspace(1)* %585, align 4, !tbaa !16, !amdgpu.noclobber !5
  %587 = add nuw nsw i32 %24, 40
  %588 = sext i32 %587 to i64
  %589 = getelementptr inbounds float, float addrspace(1)* %1, i64 %588
  %590 = load float, float addrspace(1)* %589, align 4, !tbaa !16, !amdgpu.noclobber !5
  %591 = fmul contract float %586, %590
  %592 = fadd contract float %578, %591
  %593 = fmul contract float %590, %590
  %594 = fadd contract float %580, %593
  %595 = fmul contract float %586, %586
  %596 = fadd contract float %582, %595
  %597 = add nuw nsw i32 %23, 41
  %598 = sext i32 %597 to i64
  %599 = getelementptr inbounds float, float addrspace(1)* %0, i64 %598
  %600 = load float, float addrspace(1)* %599, align 4, !tbaa !16, !amdgpu.noclobber !5
  %601 = add nuw nsw i32 %24, 41
  %602 = sext i32 %601 to i64
  %603 = getelementptr inbounds float, float addrspace(1)* %1, i64 %602
  %604 = load float, float addrspace(1)* %603, align 4, !tbaa !16, !amdgpu.noclobber !5
  %605 = fmul contract float %600, %604
  %606 = fadd contract float %592, %605
  %607 = fmul contract float %604, %604
  %608 = fadd contract float %594, %607
  %609 = fmul contract float %600, %600
  %610 = fadd contract float %596, %609
  %611 = add nuw nsw i32 %23, 42
  %612 = sext i32 %611 to i64
  %613 = getelementptr inbounds float, float addrspace(1)* %0, i64 %612
  %614 = load float, float addrspace(1)* %613, align 4, !tbaa !16, !amdgpu.noclobber !5
  %615 = add nuw nsw i32 %24, 42
  %616 = sext i32 %615 to i64
  %617 = getelementptr inbounds float, float addrspace(1)* %1, i64 %616
  %618 = load float, float addrspace(1)* %617, align 4, !tbaa !16, !amdgpu.noclobber !5
  %619 = fmul contract float %614, %618
  %620 = fadd contract float %606, %619
  %621 = fmul contract float %618, %618
  %622 = fadd contract float %608, %621
  %623 = fmul contract float %614, %614
  %624 = fadd contract float %610, %623
  %625 = add nuw nsw i32 %23, 43
  %626 = sext i32 %625 to i64
  %627 = getelementptr inbounds float, float addrspace(1)* %0, i64 %626
  %628 = load float, float addrspace(1)* %627, align 4, !tbaa !16, !amdgpu.noclobber !5
  %629 = add nuw nsw i32 %24, 43
  %630 = sext i32 %629 to i64
  %631 = getelementptr inbounds float, float addrspace(1)* %1, i64 %630
  %632 = load float, float addrspace(1)* %631, align 4, !tbaa !16, !amdgpu.noclobber !5
  %633 = fmul contract float %628, %632
  %634 = fadd contract float %620, %633
  %635 = fmul contract float %632, %632
  %636 = fadd contract float %622, %635
  %637 = fmul contract float %628, %628
  %638 = fadd contract float %624, %637
  %639 = add nuw nsw i32 %23, 44
  %640 = sext i32 %639 to i64
  %641 = getelementptr inbounds float, float addrspace(1)* %0, i64 %640
  %642 = load float, float addrspace(1)* %641, align 4, !tbaa !16, !amdgpu.noclobber !5
  %643 = add nuw nsw i32 %24, 44
  %644 = sext i32 %643 to i64
  %645 = getelementptr inbounds float, float addrspace(1)* %1, i64 %644
  %646 = load float, float addrspace(1)* %645, align 4, !tbaa !16, !amdgpu.noclobber !5
  %647 = fmul contract float %642, %646
  %648 = fadd contract float %634, %647
  %649 = fmul contract float %646, %646
  %650 = fadd contract float %636, %649
  %651 = fmul contract float %642, %642
  %652 = fadd contract float %638, %651
  %653 = add nuw nsw i32 %23, 45
  %654 = sext i32 %653 to i64
  %655 = getelementptr inbounds float, float addrspace(1)* %0, i64 %654
  %656 = load float, float addrspace(1)* %655, align 4, !tbaa !16, !amdgpu.noclobber !5
  %657 = add nuw nsw i32 %24, 45
  %658 = sext i32 %657 to i64
  %659 = getelementptr inbounds float, float addrspace(1)* %1, i64 %658
  %660 = load float, float addrspace(1)* %659, align 4, !tbaa !16, !amdgpu.noclobber !5
  %661 = fmul contract float %656, %660
  %662 = fadd contract float %648, %661
  %663 = fmul contract float %660, %660
  %664 = fadd contract float %650, %663
  %665 = fmul contract float %656, %656
  %666 = fadd contract float %652, %665
  %667 = add nuw nsw i32 %23, 46
  %668 = sext i32 %667 to i64
  %669 = getelementptr inbounds float, float addrspace(1)* %0, i64 %668
  %670 = load float, float addrspace(1)* %669, align 4, !tbaa !16, !amdgpu.noclobber !5
  %671 = add nuw nsw i32 %24, 46
  %672 = sext i32 %671 to i64
  %673 = getelementptr inbounds float, float addrspace(1)* %1, i64 %672
  %674 = load float, float addrspace(1)* %673, align 4, !tbaa !16, !amdgpu.noclobber !5
  %675 = fmul contract float %670, %674
  %676 = fadd contract float %662, %675
  %677 = fmul contract float %674, %674
  %678 = fadd contract float %664, %677
  %679 = fmul contract float %670, %670
  %680 = fadd contract float %666, %679
  %681 = add nuw nsw i32 %23, 47
  %682 = sext i32 %681 to i64
  %683 = getelementptr inbounds float, float addrspace(1)* %0, i64 %682
  %684 = load float, float addrspace(1)* %683, align 4, !tbaa !16, !amdgpu.noclobber !5
  %685 = add nuw nsw i32 %24, 47
  %686 = sext i32 %685 to i64
  %687 = getelementptr inbounds float, float addrspace(1)* %1, i64 %686
  %688 = load float, float addrspace(1)* %687, align 4, !tbaa !16, !amdgpu.noclobber !5
  %689 = fmul contract float %684, %688
  %690 = fadd contract float %676, %689
  %691 = fmul contract float %688, %688
  %692 = fadd contract float %678, %691
  %693 = fmul contract float %684, %684
  %694 = fadd contract float %680, %693
  %695 = add nuw nsw i32 %23, 48
  %696 = sext i32 %695 to i64
  %697 = getelementptr inbounds float, float addrspace(1)* %0, i64 %696
  %698 = load float, float addrspace(1)* %697, align 4, !tbaa !16, !amdgpu.noclobber !5
  %699 = add nuw nsw i32 %24, 48
  %700 = sext i32 %699 to i64
  %701 = getelementptr inbounds float, float addrspace(1)* %1, i64 %700
  %702 = load float, float addrspace(1)* %701, align 4, !tbaa !16, !amdgpu.noclobber !5
  %703 = fmul contract float %698, %702
  %704 = fadd contract float %690, %703
  %705 = fmul contract float %702, %702
  %706 = fadd contract float %692, %705
  %707 = fmul contract float %698, %698
  %708 = fadd contract float %694, %707
  %709 = add nuw nsw i32 %23, 49
  %710 = sext i32 %709 to i64
  %711 = getelementptr inbounds float, float addrspace(1)* %0, i64 %710
  %712 = load float, float addrspace(1)* %711, align 4, !tbaa !16, !amdgpu.noclobber !5
  %713 = add nuw nsw i32 %24, 49
  %714 = sext i32 %713 to i64
  %715 = getelementptr inbounds float, float addrspace(1)* %1, i64 %714
  %716 = load float, float addrspace(1)* %715, align 4, !tbaa !16, !amdgpu.noclobber !5
  %717 = fmul contract float %712, %716
  %718 = fadd contract float %704, %717
  %719 = fmul contract float %716, %716
  %720 = fadd contract float %706, %719
  %721 = fmul contract float %712, %712
  %722 = fadd contract float %708, %721
  %723 = add nuw nsw i32 %23, 50
  %724 = sext i32 %723 to i64
  %725 = getelementptr inbounds float, float addrspace(1)* %0, i64 %724
  %726 = load float, float addrspace(1)* %725, align 4, !tbaa !16, !amdgpu.noclobber !5
  %727 = add nuw nsw i32 %24, 50
  %728 = sext i32 %727 to i64
  %729 = getelementptr inbounds float, float addrspace(1)* %1, i64 %728
  %730 = load float, float addrspace(1)* %729, align 4, !tbaa !16, !amdgpu.noclobber !5
  %731 = fmul contract float %726, %730
  %732 = fadd contract float %718, %731
  %733 = fmul contract float %730, %730
  %734 = fadd contract float %720, %733
  %735 = fmul contract float %726, %726
  %736 = fadd contract float %722, %735
  %737 = add nuw nsw i32 %23, 51
  %738 = sext i32 %737 to i64
  %739 = getelementptr inbounds float, float addrspace(1)* %0, i64 %738
  %740 = load float, float addrspace(1)* %739, align 4, !tbaa !16, !amdgpu.noclobber !5
  %741 = add nuw nsw i32 %24, 51
  %742 = sext i32 %741 to i64
  %743 = getelementptr inbounds float, float addrspace(1)* %1, i64 %742
  %744 = load float, float addrspace(1)* %743, align 4, !tbaa !16, !amdgpu.noclobber !5
  %745 = fmul contract float %740, %744
  %746 = fadd contract float %732, %745
  %747 = fmul contract float %744, %744
  %748 = fadd contract float %734, %747
  %749 = fmul contract float %740, %740
  %750 = fadd contract float %736, %749
  %751 = add nuw nsw i32 %23, 52
  %752 = sext i32 %751 to i64
  %753 = getelementptr inbounds float, float addrspace(1)* %0, i64 %752
  %754 = load float, float addrspace(1)* %753, align 4, !tbaa !16, !amdgpu.noclobber !5
  %755 = add nuw nsw i32 %24, 52
  %756 = sext i32 %755 to i64
  %757 = getelementptr inbounds float, float addrspace(1)* %1, i64 %756
  %758 = load float, float addrspace(1)* %757, align 4, !tbaa !16, !amdgpu.noclobber !5
  %759 = fmul contract float %754, %758
  %760 = fadd contract float %746, %759
  %761 = fmul contract float %758, %758
  %762 = fadd contract float %748, %761
  %763 = fmul contract float %754, %754
  %764 = fadd contract float %750, %763
  %765 = add nuw nsw i32 %23, 53
  %766 = sext i32 %765 to i64
  %767 = getelementptr inbounds float, float addrspace(1)* %0, i64 %766
  %768 = load float, float addrspace(1)* %767, align 4, !tbaa !16, !amdgpu.noclobber !5
  %769 = add nuw nsw i32 %24, 53
  %770 = sext i32 %769 to i64
  %771 = getelementptr inbounds float, float addrspace(1)* %1, i64 %770
  %772 = load float, float addrspace(1)* %771, align 4, !tbaa !16, !amdgpu.noclobber !5
  %773 = fmul contract float %768, %772
  %774 = fadd contract float %760, %773
  %775 = fmul contract float %772, %772
  %776 = fadd contract float %762, %775
  %777 = fmul contract float %768, %768
  %778 = fadd contract float %764, %777
  %779 = add nuw nsw i32 %23, 54
  %780 = sext i32 %779 to i64
  %781 = getelementptr inbounds float, float addrspace(1)* %0, i64 %780
  %782 = load float, float addrspace(1)* %781, align 4, !tbaa !16, !amdgpu.noclobber !5
  %783 = add nuw nsw i32 %24, 54
  %784 = sext i32 %783 to i64
  %785 = getelementptr inbounds float, float addrspace(1)* %1, i64 %784
  %786 = load float, float addrspace(1)* %785, align 4, !tbaa !16, !amdgpu.noclobber !5
  %787 = fmul contract float %782, %786
  %788 = fadd contract float %774, %787
  %789 = fmul contract float %786, %786
  %790 = fadd contract float %776, %789
  %791 = fmul contract float %782, %782
  %792 = fadd contract float %778, %791
  %793 = add nuw nsw i32 %23, 55
  %794 = sext i32 %793 to i64
  %795 = getelementptr inbounds float, float addrspace(1)* %0, i64 %794
  %796 = load float, float addrspace(1)* %795, align 4, !tbaa !16, !amdgpu.noclobber !5
  %797 = add nuw nsw i32 %24, 55
  %798 = sext i32 %797 to i64
  %799 = getelementptr inbounds float, float addrspace(1)* %1, i64 %798
  %800 = load float, float addrspace(1)* %799, align 4, !tbaa !16, !amdgpu.noclobber !5
  %801 = fmul contract float %796, %800
  %802 = fadd contract float %788, %801
  %803 = fmul contract float %800, %800
  %804 = fadd contract float %790, %803
  %805 = fmul contract float %796, %796
  %806 = fadd contract float %792, %805
  %807 = add nuw nsw i32 %23, 56
  %808 = sext i32 %807 to i64
  %809 = getelementptr inbounds float, float addrspace(1)* %0, i64 %808
  %810 = load float, float addrspace(1)* %809, align 4, !tbaa !16, !amdgpu.noclobber !5
  %811 = add nuw nsw i32 %24, 56
  %812 = sext i32 %811 to i64
  %813 = getelementptr inbounds float, float addrspace(1)* %1, i64 %812
  %814 = load float, float addrspace(1)* %813, align 4, !tbaa !16, !amdgpu.noclobber !5
  %815 = fmul contract float %810, %814
  %816 = fadd contract float %802, %815
  %817 = fmul contract float %814, %814
  %818 = fadd contract float %804, %817
  %819 = fmul contract float %810, %810
  %820 = fadd contract float %806, %819
  %821 = add nuw nsw i32 %23, 57
  %822 = sext i32 %821 to i64
  %823 = getelementptr inbounds float, float addrspace(1)* %0, i64 %822
  %824 = load float, float addrspace(1)* %823, align 4, !tbaa !16, !amdgpu.noclobber !5
  %825 = add nuw nsw i32 %24, 57
  %826 = sext i32 %825 to i64
  %827 = getelementptr inbounds float, float addrspace(1)* %1, i64 %826
  %828 = load float, float addrspace(1)* %827, align 4, !tbaa !16, !amdgpu.noclobber !5
  %829 = fmul contract float %824, %828
  %830 = fadd contract float %816, %829
  %831 = fmul contract float %828, %828
  %832 = fadd contract float %818, %831
  %833 = fmul contract float %824, %824
  %834 = fadd contract float %820, %833
  %835 = add nuw nsw i32 %23, 58
  %836 = sext i32 %835 to i64
  %837 = getelementptr inbounds float, float addrspace(1)* %0, i64 %836
  %838 = load float, float addrspace(1)* %837, align 4, !tbaa !16, !amdgpu.noclobber !5
  %839 = add nuw nsw i32 %24, 58
  %840 = sext i32 %839 to i64
  %841 = getelementptr inbounds float, float addrspace(1)* %1, i64 %840
  %842 = load float, float addrspace(1)* %841, align 4, !tbaa !16, !amdgpu.noclobber !5
  %843 = fmul contract float %838, %842
  %844 = fadd contract float %830, %843
  %845 = fmul contract float %842, %842
  %846 = fadd contract float %832, %845
  %847 = fmul contract float %838, %838
  %848 = fadd contract float %834, %847
  %849 = add nuw nsw i32 %23, 59
  %850 = sext i32 %849 to i64
  %851 = getelementptr inbounds float, float addrspace(1)* %0, i64 %850
  %852 = load float, float addrspace(1)* %851, align 4, !tbaa !16, !amdgpu.noclobber !5
  %853 = add nuw nsw i32 %24, 59
  %854 = sext i32 %853 to i64
  %855 = getelementptr inbounds float, float addrspace(1)* %1, i64 %854
  %856 = load float, float addrspace(1)* %855, align 4, !tbaa !16, !amdgpu.noclobber !5
  %857 = fmul contract float %852, %856
  %858 = fadd contract float %844, %857
  %859 = fmul contract float %856, %856
  %860 = fadd contract float %846, %859
  %861 = fmul contract float %852, %852
  %862 = fadd contract float %848, %861
  %863 = add nuw nsw i32 %23, 60
  %864 = sext i32 %863 to i64
  %865 = getelementptr inbounds float, float addrspace(1)* %0, i64 %864
  %866 = load float, float addrspace(1)* %865, align 4, !tbaa !16, !amdgpu.noclobber !5
  %867 = add nuw nsw i32 %24, 60
  %868 = sext i32 %867 to i64
  %869 = getelementptr inbounds float, float addrspace(1)* %1, i64 %868
  %870 = load float, float addrspace(1)* %869, align 4, !tbaa !16, !amdgpu.noclobber !5
  %871 = fmul contract float %866, %870
  %872 = fadd contract float %858, %871
  %873 = fmul contract float %870, %870
  %874 = fadd contract float %860, %873
  %875 = fmul contract float %866, %866
  %876 = fadd contract float %862, %875
  %877 = add nuw nsw i32 %23, 61
  %878 = sext i32 %877 to i64
  %879 = getelementptr inbounds float, float addrspace(1)* %0, i64 %878
  %880 = load float, float addrspace(1)* %879, align 4, !tbaa !16, !amdgpu.noclobber !5
  %881 = add nuw nsw i32 %24, 61
  %882 = sext i32 %881 to i64
  %883 = getelementptr inbounds float, float addrspace(1)* %1, i64 %882
  %884 = load float, float addrspace(1)* %883, align 4, !tbaa !16, !amdgpu.noclobber !5
  %885 = fmul contract float %880, %884
  %886 = fadd contract float %872, %885
  %887 = fmul contract float %884, %884
  %888 = fadd contract float %874, %887
  %889 = fmul contract float %880, %880
  %890 = fadd contract float %876, %889
  %891 = add nuw nsw i32 %23, 62
  %892 = sext i32 %891 to i64
  %893 = getelementptr inbounds float, float addrspace(1)* %0, i64 %892
  %894 = load float, float addrspace(1)* %893, align 4, !tbaa !16, !amdgpu.noclobber !5
  %895 = add nuw nsw i32 %24, 62
  %896 = sext i32 %895 to i64
  %897 = getelementptr inbounds float, float addrspace(1)* %1, i64 %896
  %898 = load float, float addrspace(1)* %897, align 4, !tbaa !16, !amdgpu.noclobber !5
  %899 = fmul contract float %894, %898
  %900 = fadd contract float %886, %899
  %901 = fmul contract float %898, %898
  %902 = fadd contract float %888, %901
  %903 = fmul contract float %894, %894
  %904 = fadd contract float %890, %903
  %905 = add nuw nsw i32 %23, 63
  %906 = sext i32 %905 to i64
  %907 = getelementptr inbounds float, float addrspace(1)* %0, i64 %906
  %908 = load float, float addrspace(1)* %907, align 4, !tbaa !16, !amdgpu.noclobber !5
  %909 = add nuw nsw i32 %24, 63
  %910 = sext i32 %909 to i64
  %911 = getelementptr inbounds float, float addrspace(1)* %1, i64 %910
  %912 = load float, float addrspace(1)* %911, align 4, !tbaa !16, !amdgpu.noclobber !5
  %913 = fmul contract float %908, %912
  %914 = fadd contract float %900, %913
  %915 = fmul contract float %912, %912
  %916 = fadd contract float %902, %915
  %917 = fmul contract float %908, %908
  %918 = fadd contract float %904, %917
  %919 = add nuw nsw i32 %23, 64
  %920 = sext i32 %919 to i64
  %921 = getelementptr inbounds float, float addrspace(1)* %0, i64 %920
  %922 = load float, float addrspace(1)* %921, align 4, !tbaa !16, !amdgpu.noclobber !5
  %923 = add nuw nsw i32 %24, 64
  %924 = sext i32 %923 to i64
  %925 = getelementptr inbounds float, float addrspace(1)* %1, i64 %924
  %926 = load float, float addrspace(1)* %925, align 4, !tbaa !16, !amdgpu.noclobber !5
  %927 = fmul contract float %922, %926
  %928 = fadd contract float %914, %927
  %929 = fmul contract float %926, %926
  %930 = fadd contract float %916, %929
  %931 = fmul contract float %922, %922
  %932 = fadd contract float %918, %931
  %933 = add nuw nsw i32 %23, 65
  %934 = sext i32 %933 to i64
  %935 = getelementptr inbounds float, float addrspace(1)* %0, i64 %934
  %936 = load float, float addrspace(1)* %935, align 4, !tbaa !16, !amdgpu.noclobber !5
  %937 = add nuw nsw i32 %24, 65
  %938 = sext i32 %937 to i64
  %939 = getelementptr inbounds float, float addrspace(1)* %1, i64 %938
  %940 = load float, float addrspace(1)* %939, align 4, !tbaa !16, !amdgpu.noclobber !5
  %941 = fmul contract float %936, %940
  %942 = fadd contract float %928, %941
  %943 = fmul contract float %940, %940
  %944 = fadd contract float %930, %943
  %945 = fmul contract float %936, %936
  %946 = fadd contract float %932, %945
  %947 = add nuw nsw i32 %23, 66
  %948 = sext i32 %947 to i64
  %949 = getelementptr inbounds float, float addrspace(1)* %0, i64 %948
  %950 = load float, float addrspace(1)* %949, align 4, !tbaa !16, !amdgpu.noclobber !5
  %951 = add nuw nsw i32 %24, 66
  %952 = sext i32 %951 to i64
  %953 = getelementptr inbounds float, float addrspace(1)* %1, i64 %952
  %954 = load float, float addrspace(1)* %953, align 4, !tbaa !16, !amdgpu.noclobber !5
  %955 = fmul contract float %950, %954
  %956 = fadd contract float %942, %955
  %957 = fmul contract float %954, %954
  %958 = fadd contract float %944, %957
  %959 = fmul contract float %950, %950
  %960 = fadd contract float %946, %959
  %961 = add nuw nsw i32 %23, 67
  %962 = sext i32 %961 to i64
  %963 = getelementptr inbounds float, float addrspace(1)* %0, i64 %962
  %964 = load float, float addrspace(1)* %963, align 4, !tbaa !16, !amdgpu.noclobber !5
  %965 = add nuw nsw i32 %24, 67
  %966 = sext i32 %965 to i64
  %967 = getelementptr inbounds float, float addrspace(1)* %1, i64 %966
  %968 = load float, float addrspace(1)* %967, align 4, !tbaa !16, !amdgpu.noclobber !5
  %969 = fmul contract float %964, %968
  %970 = fadd contract float %956, %969
  %971 = fmul contract float %968, %968
  %972 = fadd contract float %958, %971
  %973 = fmul contract float %964, %964
  %974 = fadd contract float %960, %973
  %975 = add nuw nsw i32 %23, 68
  %976 = sext i32 %975 to i64
  %977 = getelementptr inbounds float, float addrspace(1)* %0, i64 %976
  %978 = load float, float addrspace(1)* %977, align 4, !tbaa !16, !amdgpu.noclobber !5
  %979 = add nuw nsw i32 %24, 68
  %980 = sext i32 %979 to i64
  %981 = getelementptr inbounds float, float addrspace(1)* %1, i64 %980
  %982 = load float, float addrspace(1)* %981, align 4, !tbaa !16, !amdgpu.noclobber !5
  %983 = fmul contract float %978, %982
  %984 = fadd contract float %970, %983
  %985 = fmul contract float %982, %982
  %986 = fadd contract float %972, %985
  %987 = fmul contract float %978, %978
  %988 = fadd contract float %974, %987
  %989 = add nuw nsw i32 %23, 69
  %990 = sext i32 %989 to i64
  %991 = getelementptr inbounds float, float addrspace(1)* %0, i64 %990
  %992 = load float, float addrspace(1)* %991, align 4, !tbaa !16, !amdgpu.noclobber !5
  %993 = add nuw nsw i32 %24, 69
  %994 = sext i32 %993 to i64
  %995 = getelementptr inbounds float, float addrspace(1)* %1, i64 %994
  %996 = load float, float addrspace(1)* %995, align 4, !tbaa !16, !amdgpu.noclobber !5
  %997 = fmul contract float %992, %996
  %998 = fadd contract float %984, %997
  %999 = fmul contract float %996, %996
  %1000 = fadd contract float %986, %999
  %1001 = fmul contract float %992, %992
  %1002 = fadd contract float %988, %1001
  %1003 = add nuw nsw i32 %23, 70
  %1004 = sext i32 %1003 to i64
  %1005 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1004
  %1006 = load float, float addrspace(1)* %1005, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1007 = add nuw nsw i32 %24, 70
  %1008 = sext i32 %1007 to i64
  %1009 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1008
  %1010 = load float, float addrspace(1)* %1009, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1011 = fmul contract float %1006, %1010
  %1012 = fadd contract float %998, %1011
  %1013 = fmul contract float %1010, %1010
  %1014 = fadd contract float %1000, %1013
  %1015 = fmul contract float %1006, %1006
  %1016 = fadd contract float %1002, %1015
  %1017 = add nuw nsw i32 %23, 71
  %1018 = sext i32 %1017 to i64
  %1019 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1018
  %1020 = load float, float addrspace(1)* %1019, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1021 = add nuw nsw i32 %24, 71
  %1022 = sext i32 %1021 to i64
  %1023 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1022
  %1024 = load float, float addrspace(1)* %1023, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1025 = fmul contract float %1020, %1024
  %1026 = fadd contract float %1012, %1025
  %1027 = fmul contract float %1024, %1024
  %1028 = fadd contract float %1014, %1027
  %1029 = fmul contract float %1020, %1020
  %1030 = fadd contract float %1016, %1029
  %1031 = add nuw nsw i32 %23, 72
  %1032 = sext i32 %1031 to i64
  %1033 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1032
  %1034 = load float, float addrspace(1)* %1033, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1035 = add nuw nsw i32 %24, 72
  %1036 = sext i32 %1035 to i64
  %1037 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1036
  %1038 = load float, float addrspace(1)* %1037, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1039 = fmul contract float %1034, %1038
  %1040 = fadd contract float %1026, %1039
  %1041 = fmul contract float %1038, %1038
  %1042 = fadd contract float %1028, %1041
  %1043 = fmul contract float %1034, %1034
  %1044 = fadd contract float %1030, %1043
  %1045 = add nuw nsw i32 %23, 73
  %1046 = sext i32 %1045 to i64
  %1047 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1046
  %1048 = load float, float addrspace(1)* %1047, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1049 = add nuw nsw i32 %24, 73
  %1050 = sext i32 %1049 to i64
  %1051 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1050
  %1052 = load float, float addrspace(1)* %1051, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1053 = fmul contract float %1048, %1052
  %1054 = fadd contract float %1040, %1053
  %1055 = fmul contract float %1052, %1052
  %1056 = fadd contract float %1042, %1055
  %1057 = fmul contract float %1048, %1048
  %1058 = fadd contract float %1044, %1057
  %1059 = add nuw nsw i32 %23, 74
  %1060 = sext i32 %1059 to i64
  %1061 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1060
  %1062 = load float, float addrspace(1)* %1061, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1063 = add nuw nsw i32 %24, 74
  %1064 = sext i32 %1063 to i64
  %1065 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1064
  %1066 = load float, float addrspace(1)* %1065, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1067 = fmul contract float %1062, %1066
  %1068 = fadd contract float %1054, %1067
  %1069 = fmul contract float %1066, %1066
  %1070 = fadd contract float %1056, %1069
  %1071 = fmul contract float %1062, %1062
  %1072 = fadd contract float %1058, %1071
  %1073 = add nuw nsw i32 %23, 75
  %1074 = sext i32 %1073 to i64
  %1075 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1074
  %1076 = load float, float addrspace(1)* %1075, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1077 = add nuw nsw i32 %24, 75
  %1078 = sext i32 %1077 to i64
  %1079 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1078
  %1080 = load float, float addrspace(1)* %1079, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1081 = fmul contract float %1076, %1080
  %1082 = fadd contract float %1068, %1081
  %1083 = fmul contract float %1080, %1080
  %1084 = fadd contract float %1070, %1083
  %1085 = fmul contract float %1076, %1076
  %1086 = fadd contract float %1072, %1085
  %1087 = add nuw nsw i32 %23, 76
  %1088 = sext i32 %1087 to i64
  %1089 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1088
  %1090 = load float, float addrspace(1)* %1089, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1091 = add nuw nsw i32 %24, 76
  %1092 = sext i32 %1091 to i64
  %1093 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1092
  %1094 = load float, float addrspace(1)* %1093, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1095 = fmul contract float %1090, %1094
  %1096 = fadd contract float %1082, %1095
  %1097 = fmul contract float %1094, %1094
  %1098 = fadd contract float %1084, %1097
  %1099 = fmul contract float %1090, %1090
  %1100 = fadd contract float %1086, %1099
  %1101 = add nuw nsw i32 %23, 77
  %1102 = sext i32 %1101 to i64
  %1103 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1102
  %1104 = load float, float addrspace(1)* %1103, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1105 = add nuw nsw i32 %24, 77
  %1106 = sext i32 %1105 to i64
  %1107 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1106
  %1108 = load float, float addrspace(1)* %1107, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1109 = fmul contract float %1104, %1108
  %1110 = fadd contract float %1096, %1109
  %1111 = fmul contract float %1108, %1108
  %1112 = fadd contract float %1098, %1111
  %1113 = fmul contract float %1104, %1104
  %1114 = fadd contract float %1100, %1113
  %1115 = add nuw nsw i32 %23, 78
  %1116 = sext i32 %1115 to i64
  %1117 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1116
  %1118 = load float, float addrspace(1)* %1117, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1119 = add nuw nsw i32 %24, 78
  %1120 = sext i32 %1119 to i64
  %1121 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1120
  %1122 = load float, float addrspace(1)* %1121, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1123 = fmul contract float %1118, %1122
  %1124 = fadd contract float %1110, %1123
  %1125 = fmul contract float %1122, %1122
  %1126 = fadd contract float %1112, %1125
  %1127 = fmul contract float %1118, %1118
  %1128 = fadd contract float %1114, %1127
  %1129 = add nuw nsw i32 %23, 79
  %1130 = sext i32 %1129 to i64
  %1131 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1130
  %1132 = load float, float addrspace(1)* %1131, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1133 = add nuw nsw i32 %24, 79
  %1134 = sext i32 %1133 to i64
  %1135 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1134
  %1136 = load float, float addrspace(1)* %1135, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1137 = fmul contract float %1132, %1136
  %1138 = fadd contract float %1124, %1137
  %1139 = fmul contract float %1136, %1136
  %1140 = fadd contract float %1126, %1139
  %1141 = fmul contract float %1132, %1132
  %1142 = fadd contract float %1128, %1141
  %1143 = add nuw nsw i32 %23, 80
  %1144 = sext i32 %1143 to i64
  %1145 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1144
  %1146 = load float, float addrspace(1)* %1145, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1147 = add nuw nsw i32 %24, 80
  %1148 = sext i32 %1147 to i64
  %1149 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1148
  %1150 = load float, float addrspace(1)* %1149, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1151 = fmul contract float %1146, %1150
  %1152 = fadd contract float %1138, %1151
  %1153 = fmul contract float %1150, %1150
  %1154 = fadd contract float %1140, %1153
  %1155 = fmul contract float %1146, %1146
  %1156 = fadd contract float %1142, %1155
  %1157 = add nuw nsw i32 %23, 81
  %1158 = sext i32 %1157 to i64
  %1159 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1158
  %1160 = load float, float addrspace(1)* %1159, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1161 = add nuw nsw i32 %24, 81
  %1162 = sext i32 %1161 to i64
  %1163 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1162
  %1164 = load float, float addrspace(1)* %1163, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1165 = fmul contract float %1160, %1164
  %1166 = fadd contract float %1152, %1165
  %1167 = fmul contract float %1164, %1164
  %1168 = fadd contract float %1154, %1167
  %1169 = fmul contract float %1160, %1160
  %1170 = fadd contract float %1156, %1169
  %1171 = add nuw nsw i32 %23, 82
  %1172 = sext i32 %1171 to i64
  %1173 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1172
  %1174 = load float, float addrspace(1)* %1173, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1175 = add nuw nsw i32 %24, 82
  %1176 = sext i32 %1175 to i64
  %1177 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1176
  %1178 = load float, float addrspace(1)* %1177, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1179 = fmul contract float %1174, %1178
  %1180 = fadd contract float %1166, %1179
  %1181 = fmul contract float %1178, %1178
  %1182 = fadd contract float %1168, %1181
  %1183 = fmul contract float %1174, %1174
  %1184 = fadd contract float %1170, %1183
  %1185 = add nuw nsw i32 %23, 83
  %1186 = sext i32 %1185 to i64
  %1187 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1186
  %1188 = load float, float addrspace(1)* %1187, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1189 = add nuw nsw i32 %24, 83
  %1190 = sext i32 %1189 to i64
  %1191 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1190
  %1192 = load float, float addrspace(1)* %1191, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1193 = fmul contract float %1188, %1192
  %1194 = fadd contract float %1180, %1193
  %1195 = fmul contract float %1192, %1192
  %1196 = fadd contract float %1182, %1195
  %1197 = fmul contract float %1188, %1188
  %1198 = fadd contract float %1184, %1197
  %1199 = add nuw nsw i32 %23, 84
  %1200 = sext i32 %1199 to i64
  %1201 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1200
  %1202 = load float, float addrspace(1)* %1201, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1203 = add nuw nsw i32 %24, 84
  %1204 = sext i32 %1203 to i64
  %1205 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1204
  %1206 = load float, float addrspace(1)* %1205, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1207 = fmul contract float %1202, %1206
  %1208 = fadd contract float %1194, %1207
  %1209 = fmul contract float %1206, %1206
  %1210 = fadd contract float %1196, %1209
  %1211 = fmul contract float %1202, %1202
  %1212 = fadd contract float %1198, %1211
  %1213 = add nuw nsw i32 %23, 85
  %1214 = sext i32 %1213 to i64
  %1215 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1214
  %1216 = load float, float addrspace(1)* %1215, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1217 = add nuw nsw i32 %24, 85
  %1218 = sext i32 %1217 to i64
  %1219 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1218
  %1220 = load float, float addrspace(1)* %1219, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1221 = fmul contract float %1216, %1220
  %1222 = fadd contract float %1208, %1221
  %1223 = fmul contract float %1220, %1220
  %1224 = fadd contract float %1210, %1223
  %1225 = fmul contract float %1216, %1216
  %1226 = fadd contract float %1212, %1225
  %1227 = add nuw nsw i32 %23, 86
  %1228 = sext i32 %1227 to i64
  %1229 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1228
  %1230 = load float, float addrspace(1)* %1229, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1231 = add nuw nsw i32 %24, 86
  %1232 = sext i32 %1231 to i64
  %1233 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1232
  %1234 = load float, float addrspace(1)* %1233, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1235 = fmul contract float %1230, %1234
  %1236 = fadd contract float %1222, %1235
  %1237 = fmul contract float %1234, %1234
  %1238 = fadd contract float %1224, %1237
  %1239 = fmul contract float %1230, %1230
  %1240 = fadd contract float %1226, %1239
  %1241 = add nuw nsw i32 %23, 87
  %1242 = sext i32 %1241 to i64
  %1243 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1242
  %1244 = load float, float addrspace(1)* %1243, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1245 = add nuw nsw i32 %24, 87
  %1246 = sext i32 %1245 to i64
  %1247 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1246
  %1248 = load float, float addrspace(1)* %1247, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1249 = fmul contract float %1244, %1248
  %1250 = fadd contract float %1236, %1249
  %1251 = fmul contract float %1248, %1248
  %1252 = fadd contract float %1238, %1251
  %1253 = fmul contract float %1244, %1244
  %1254 = fadd contract float %1240, %1253
  %1255 = add nuw nsw i32 %23, 88
  %1256 = sext i32 %1255 to i64
  %1257 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1256
  %1258 = load float, float addrspace(1)* %1257, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1259 = add nuw nsw i32 %24, 88
  %1260 = sext i32 %1259 to i64
  %1261 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1260
  %1262 = load float, float addrspace(1)* %1261, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1263 = fmul contract float %1258, %1262
  %1264 = fadd contract float %1250, %1263
  %1265 = fmul contract float %1262, %1262
  %1266 = fadd contract float %1252, %1265
  %1267 = fmul contract float %1258, %1258
  %1268 = fadd contract float %1254, %1267
  %1269 = add nuw nsw i32 %23, 89
  %1270 = sext i32 %1269 to i64
  %1271 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1270
  %1272 = load float, float addrspace(1)* %1271, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1273 = add nuw nsw i32 %24, 89
  %1274 = sext i32 %1273 to i64
  %1275 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1274
  %1276 = load float, float addrspace(1)* %1275, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1277 = fmul contract float %1272, %1276
  %1278 = fadd contract float %1264, %1277
  %1279 = fmul contract float %1276, %1276
  %1280 = fadd contract float %1266, %1279
  %1281 = fmul contract float %1272, %1272
  %1282 = fadd contract float %1268, %1281
  %1283 = add nuw nsw i32 %23, 90
  %1284 = sext i32 %1283 to i64
  %1285 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1284
  %1286 = load float, float addrspace(1)* %1285, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1287 = add nuw nsw i32 %24, 90
  %1288 = sext i32 %1287 to i64
  %1289 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1288
  %1290 = load float, float addrspace(1)* %1289, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1291 = fmul contract float %1286, %1290
  %1292 = fadd contract float %1278, %1291
  %1293 = fmul contract float %1290, %1290
  %1294 = fadd contract float %1280, %1293
  %1295 = fmul contract float %1286, %1286
  %1296 = fadd contract float %1282, %1295
  %1297 = add nuw nsw i32 %23, 91
  %1298 = sext i32 %1297 to i64
  %1299 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1298
  %1300 = load float, float addrspace(1)* %1299, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1301 = add nuw nsw i32 %24, 91
  %1302 = sext i32 %1301 to i64
  %1303 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1302
  %1304 = load float, float addrspace(1)* %1303, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1305 = fmul contract float %1300, %1304
  %1306 = fadd contract float %1292, %1305
  %1307 = fmul contract float %1304, %1304
  %1308 = fadd contract float %1294, %1307
  %1309 = fmul contract float %1300, %1300
  %1310 = fadd contract float %1296, %1309
  %1311 = add nuw nsw i32 %23, 92
  %1312 = sext i32 %1311 to i64
  %1313 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1312
  %1314 = load float, float addrspace(1)* %1313, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1315 = add nuw nsw i32 %24, 92
  %1316 = sext i32 %1315 to i64
  %1317 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1316
  %1318 = load float, float addrspace(1)* %1317, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1319 = fmul contract float %1314, %1318
  %1320 = fadd contract float %1306, %1319
  %1321 = fmul contract float %1318, %1318
  %1322 = fadd contract float %1308, %1321
  %1323 = fmul contract float %1314, %1314
  %1324 = fadd contract float %1310, %1323
  %1325 = add nuw nsw i32 %23, 93
  %1326 = sext i32 %1325 to i64
  %1327 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1326
  %1328 = load float, float addrspace(1)* %1327, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1329 = add nuw nsw i32 %24, 93
  %1330 = sext i32 %1329 to i64
  %1331 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1330
  %1332 = load float, float addrspace(1)* %1331, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1333 = fmul contract float %1328, %1332
  %1334 = fadd contract float %1320, %1333
  %1335 = fmul contract float %1332, %1332
  %1336 = fadd contract float %1322, %1335
  %1337 = fmul contract float %1328, %1328
  %1338 = fadd contract float %1324, %1337
  %1339 = add nuw nsw i32 %23, 94
  %1340 = sext i32 %1339 to i64
  %1341 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1340
  %1342 = load float, float addrspace(1)* %1341, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1343 = add nuw nsw i32 %24, 94
  %1344 = sext i32 %1343 to i64
  %1345 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1344
  %1346 = load float, float addrspace(1)* %1345, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1347 = fmul contract float %1342, %1346
  %1348 = fadd contract float %1334, %1347
  %1349 = fmul contract float %1346, %1346
  %1350 = fadd contract float %1336, %1349
  %1351 = fmul contract float %1342, %1342
  %1352 = fadd contract float %1338, %1351
  %1353 = add nuw nsw i32 %23, 95
  %1354 = sext i32 %1353 to i64
  %1355 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1354
  %1356 = load float, float addrspace(1)* %1355, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1357 = add nuw nsw i32 %24, 95
  %1358 = sext i32 %1357 to i64
  %1359 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1358
  %1360 = load float, float addrspace(1)* %1359, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1361 = fmul contract float %1356, %1360
  %1362 = fadd contract float %1348, %1361
  %1363 = fmul contract float %1360, %1360
  %1364 = fadd contract float %1350, %1363
  %1365 = fmul contract float %1356, %1356
  %1366 = fadd contract float %1352, %1365
  %1367 = add nuw nsw i32 %23, 96
  %1368 = sext i32 %1367 to i64
  %1369 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1368
  %1370 = load float, float addrspace(1)* %1369, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1371 = add nuw nsw i32 %24, 96
  %1372 = sext i32 %1371 to i64
  %1373 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1372
  %1374 = load float, float addrspace(1)* %1373, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1375 = fmul contract float %1370, %1374
  %1376 = fadd contract float %1362, %1375
  %1377 = fmul contract float %1374, %1374
  %1378 = fadd contract float %1364, %1377
  %1379 = fmul contract float %1370, %1370
  %1380 = fadd contract float %1366, %1379
  %1381 = add nuw nsw i32 %23, 97
  %1382 = sext i32 %1381 to i64
  %1383 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1382
  %1384 = load float, float addrspace(1)* %1383, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1385 = add nuw nsw i32 %24, 97
  %1386 = sext i32 %1385 to i64
  %1387 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1386
  %1388 = load float, float addrspace(1)* %1387, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1389 = fmul contract float %1384, %1388
  %1390 = fadd contract float %1376, %1389
  %1391 = fmul contract float %1388, %1388
  %1392 = fadd contract float %1378, %1391
  %1393 = fmul contract float %1384, %1384
  %1394 = fadd contract float %1380, %1393
  %1395 = add nuw nsw i32 %23, 98
  %1396 = sext i32 %1395 to i64
  %1397 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1396
  %1398 = load float, float addrspace(1)* %1397, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1399 = add nuw nsw i32 %24, 98
  %1400 = sext i32 %1399 to i64
  %1401 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1400
  %1402 = load float, float addrspace(1)* %1401, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1403 = fmul contract float %1398, %1402
  %1404 = fadd contract float %1390, %1403
  %1405 = fmul contract float %1402, %1402
  %1406 = fadd contract float %1392, %1405
  %1407 = fmul contract float %1398, %1398
  %1408 = fadd contract float %1394, %1407
  %1409 = add nuw nsw i32 %23, 99
  %1410 = sext i32 %1409 to i64
  %1411 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1410
  %1412 = load float, float addrspace(1)* %1411, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1413 = add nuw nsw i32 %24, 99
  %1414 = sext i32 %1413 to i64
  %1415 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1414
  %1416 = load float, float addrspace(1)* %1415, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1417 = fmul contract float %1412, %1416
  %1418 = fadd contract float %1404, %1417
  %1419 = fmul contract float %1416, %1416
  %1420 = fadd contract float %1406, %1419
  %1421 = fmul contract float %1412, %1412
  %1422 = fadd contract float %1408, %1421
  %1423 = add nuw nsw i32 %23, 100
  %1424 = sext i32 %1423 to i64
  %1425 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1424
  %1426 = load float, float addrspace(1)* %1425, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1427 = add nuw nsw i32 %24, 100
  %1428 = sext i32 %1427 to i64
  %1429 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1428
  %1430 = load float, float addrspace(1)* %1429, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1431 = fmul contract float %1426, %1430
  %1432 = fadd contract float %1418, %1431
  %1433 = fmul contract float %1430, %1430
  %1434 = fadd contract float %1420, %1433
  %1435 = fmul contract float %1426, %1426
  %1436 = fadd contract float %1422, %1435
  %1437 = add nuw nsw i32 %23, 101
  %1438 = sext i32 %1437 to i64
  %1439 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1438
  %1440 = load float, float addrspace(1)* %1439, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1441 = add nuw nsw i32 %24, 101
  %1442 = sext i32 %1441 to i64
  %1443 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1442
  %1444 = load float, float addrspace(1)* %1443, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1445 = fmul contract float %1440, %1444
  %1446 = fadd contract float %1432, %1445
  %1447 = fmul contract float %1444, %1444
  %1448 = fadd contract float %1434, %1447
  %1449 = fmul contract float %1440, %1440
  %1450 = fadd contract float %1436, %1449
  %1451 = add nuw nsw i32 %23, 102
  %1452 = sext i32 %1451 to i64
  %1453 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1452
  %1454 = load float, float addrspace(1)* %1453, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1455 = add nuw nsw i32 %24, 102
  %1456 = sext i32 %1455 to i64
  %1457 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1456
  %1458 = load float, float addrspace(1)* %1457, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1459 = fmul contract float %1454, %1458
  %1460 = fadd contract float %1446, %1459
  %1461 = fmul contract float %1458, %1458
  %1462 = fadd contract float %1448, %1461
  %1463 = fmul contract float %1454, %1454
  %1464 = fadd contract float %1450, %1463
  %1465 = add nuw nsw i32 %23, 103
  %1466 = sext i32 %1465 to i64
  %1467 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1466
  %1468 = load float, float addrspace(1)* %1467, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1469 = add nuw nsw i32 %24, 103
  %1470 = sext i32 %1469 to i64
  %1471 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1470
  %1472 = load float, float addrspace(1)* %1471, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1473 = fmul contract float %1468, %1472
  %1474 = fadd contract float %1460, %1473
  %1475 = fmul contract float %1472, %1472
  %1476 = fadd contract float %1462, %1475
  %1477 = fmul contract float %1468, %1468
  %1478 = fadd contract float %1464, %1477
  %1479 = add nuw nsw i32 %23, 104
  %1480 = sext i32 %1479 to i64
  %1481 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1480
  %1482 = load float, float addrspace(1)* %1481, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1483 = add nuw nsw i32 %24, 104
  %1484 = sext i32 %1483 to i64
  %1485 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1484
  %1486 = load float, float addrspace(1)* %1485, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1487 = fmul contract float %1482, %1486
  %1488 = fadd contract float %1474, %1487
  %1489 = fmul contract float %1486, %1486
  %1490 = fadd contract float %1476, %1489
  %1491 = fmul contract float %1482, %1482
  %1492 = fadd contract float %1478, %1491
  %1493 = add nuw nsw i32 %23, 105
  %1494 = sext i32 %1493 to i64
  %1495 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1494
  %1496 = load float, float addrspace(1)* %1495, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1497 = add nuw nsw i32 %24, 105
  %1498 = sext i32 %1497 to i64
  %1499 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1498
  %1500 = load float, float addrspace(1)* %1499, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1501 = fmul contract float %1496, %1500
  %1502 = fadd contract float %1488, %1501
  %1503 = fmul contract float %1500, %1500
  %1504 = fadd contract float %1490, %1503
  %1505 = fmul contract float %1496, %1496
  %1506 = fadd contract float %1492, %1505
  %1507 = add nuw nsw i32 %23, 106
  %1508 = sext i32 %1507 to i64
  %1509 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1508
  %1510 = load float, float addrspace(1)* %1509, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1511 = add nuw nsw i32 %24, 106
  %1512 = sext i32 %1511 to i64
  %1513 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1512
  %1514 = load float, float addrspace(1)* %1513, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1515 = fmul contract float %1510, %1514
  %1516 = fadd contract float %1502, %1515
  %1517 = fmul contract float %1514, %1514
  %1518 = fadd contract float %1504, %1517
  %1519 = fmul contract float %1510, %1510
  %1520 = fadd contract float %1506, %1519
  %1521 = add nuw nsw i32 %23, 107
  %1522 = sext i32 %1521 to i64
  %1523 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1522
  %1524 = load float, float addrspace(1)* %1523, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1525 = add nuw nsw i32 %24, 107
  %1526 = sext i32 %1525 to i64
  %1527 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1526
  %1528 = load float, float addrspace(1)* %1527, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1529 = fmul contract float %1524, %1528
  %1530 = fadd contract float %1516, %1529
  %1531 = fmul contract float %1528, %1528
  %1532 = fadd contract float %1518, %1531
  %1533 = fmul contract float %1524, %1524
  %1534 = fadd contract float %1520, %1533
  %1535 = add nuw nsw i32 %23, 108
  %1536 = sext i32 %1535 to i64
  %1537 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1536
  %1538 = load float, float addrspace(1)* %1537, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1539 = add nuw nsw i32 %24, 108
  %1540 = sext i32 %1539 to i64
  %1541 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1540
  %1542 = load float, float addrspace(1)* %1541, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1543 = fmul contract float %1538, %1542
  %1544 = fadd contract float %1530, %1543
  %1545 = fmul contract float %1542, %1542
  %1546 = fadd contract float %1532, %1545
  %1547 = fmul contract float %1538, %1538
  %1548 = fadd contract float %1534, %1547
  %1549 = add nuw nsw i32 %23, 109
  %1550 = sext i32 %1549 to i64
  %1551 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1550
  %1552 = load float, float addrspace(1)* %1551, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1553 = add nuw nsw i32 %24, 109
  %1554 = sext i32 %1553 to i64
  %1555 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1554
  %1556 = load float, float addrspace(1)* %1555, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1557 = fmul contract float %1552, %1556
  %1558 = fadd contract float %1544, %1557
  %1559 = fmul contract float %1556, %1556
  %1560 = fadd contract float %1546, %1559
  %1561 = fmul contract float %1552, %1552
  %1562 = fadd contract float %1548, %1561
  %1563 = add nuw nsw i32 %23, 110
  %1564 = sext i32 %1563 to i64
  %1565 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1564
  %1566 = load float, float addrspace(1)* %1565, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1567 = add nuw nsw i32 %24, 110
  %1568 = sext i32 %1567 to i64
  %1569 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1568
  %1570 = load float, float addrspace(1)* %1569, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1571 = fmul contract float %1566, %1570
  %1572 = fadd contract float %1558, %1571
  %1573 = fmul contract float %1570, %1570
  %1574 = fadd contract float %1560, %1573
  %1575 = fmul contract float %1566, %1566
  %1576 = fadd contract float %1562, %1575
  %1577 = add nuw nsw i32 %23, 111
  %1578 = sext i32 %1577 to i64
  %1579 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1578
  %1580 = load float, float addrspace(1)* %1579, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1581 = add nuw nsw i32 %24, 111
  %1582 = sext i32 %1581 to i64
  %1583 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1582
  %1584 = load float, float addrspace(1)* %1583, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1585 = fmul contract float %1580, %1584
  %1586 = fadd contract float %1572, %1585
  %1587 = fmul contract float %1584, %1584
  %1588 = fadd contract float %1574, %1587
  %1589 = fmul contract float %1580, %1580
  %1590 = fadd contract float %1576, %1589
  %1591 = add nuw nsw i32 %23, 112
  %1592 = sext i32 %1591 to i64
  %1593 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1592
  %1594 = load float, float addrspace(1)* %1593, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1595 = add nuw nsw i32 %24, 112
  %1596 = sext i32 %1595 to i64
  %1597 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1596
  %1598 = load float, float addrspace(1)* %1597, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1599 = fmul contract float %1594, %1598
  %1600 = fadd contract float %1586, %1599
  %1601 = fmul contract float %1598, %1598
  %1602 = fadd contract float %1588, %1601
  %1603 = fmul contract float %1594, %1594
  %1604 = fadd contract float %1590, %1603
  %1605 = add nuw nsw i32 %23, 113
  %1606 = sext i32 %1605 to i64
  %1607 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1606
  %1608 = load float, float addrspace(1)* %1607, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1609 = add nuw nsw i32 %24, 113
  %1610 = sext i32 %1609 to i64
  %1611 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1610
  %1612 = load float, float addrspace(1)* %1611, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1613 = fmul contract float %1608, %1612
  %1614 = fadd contract float %1600, %1613
  %1615 = fmul contract float %1612, %1612
  %1616 = fadd contract float %1602, %1615
  %1617 = fmul contract float %1608, %1608
  %1618 = fadd contract float %1604, %1617
  %1619 = add nuw nsw i32 %23, 114
  %1620 = sext i32 %1619 to i64
  %1621 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1620
  %1622 = load float, float addrspace(1)* %1621, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1623 = add nuw nsw i32 %24, 114
  %1624 = sext i32 %1623 to i64
  %1625 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1624
  %1626 = load float, float addrspace(1)* %1625, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1627 = fmul contract float %1622, %1626
  %1628 = fadd contract float %1614, %1627
  %1629 = fmul contract float %1626, %1626
  %1630 = fadd contract float %1616, %1629
  %1631 = fmul contract float %1622, %1622
  %1632 = fadd contract float %1618, %1631
  %1633 = add nuw nsw i32 %23, 115
  %1634 = sext i32 %1633 to i64
  %1635 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1634
  %1636 = load float, float addrspace(1)* %1635, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1637 = add nuw nsw i32 %24, 115
  %1638 = sext i32 %1637 to i64
  %1639 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1638
  %1640 = load float, float addrspace(1)* %1639, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1641 = fmul contract float %1636, %1640
  %1642 = fadd contract float %1628, %1641
  %1643 = fmul contract float %1640, %1640
  %1644 = fadd contract float %1630, %1643
  %1645 = fmul contract float %1636, %1636
  %1646 = fadd contract float %1632, %1645
  %1647 = add nuw nsw i32 %23, 116
  %1648 = sext i32 %1647 to i64
  %1649 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1648
  %1650 = load float, float addrspace(1)* %1649, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1651 = add nuw nsw i32 %24, 116
  %1652 = sext i32 %1651 to i64
  %1653 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1652
  %1654 = load float, float addrspace(1)* %1653, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1655 = fmul contract float %1650, %1654
  %1656 = fadd contract float %1642, %1655
  %1657 = fmul contract float %1654, %1654
  %1658 = fadd contract float %1644, %1657
  %1659 = fmul contract float %1650, %1650
  %1660 = fadd contract float %1646, %1659
  %1661 = add nuw nsw i32 %23, 117
  %1662 = sext i32 %1661 to i64
  %1663 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1662
  %1664 = load float, float addrspace(1)* %1663, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1665 = add nuw nsw i32 %24, 117
  %1666 = sext i32 %1665 to i64
  %1667 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1666
  %1668 = load float, float addrspace(1)* %1667, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1669 = fmul contract float %1664, %1668
  %1670 = fadd contract float %1656, %1669
  %1671 = fmul contract float %1668, %1668
  %1672 = fadd contract float %1658, %1671
  %1673 = fmul contract float %1664, %1664
  %1674 = fadd contract float %1660, %1673
  %1675 = add nuw nsw i32 %23, 118
  %1676 = sext i32 %1675 to i64
  %1677 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1676
  %1678 = load float, float addrspace(1)* %1677, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1679 = add nuw nsw i32 %24, 118
  %1680 = sext i32 %1679 to i64
  %1681 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1680
  %1682 = load float, float addrspace(1)* %1681, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1683 = fmul contract float %1678, %1682
  %1684 = fadd contract float %1670, %1683
  %1685 = fmul contract float %1682, %1682
  %1686 = fadd contract float %1672, %1685
  %1687 = fmul contract float %1678, %1678
  %1688 = fadd contract float %1674, %1687
  %1689 = add nuw nsw i32 %23, 119
  %1690 = sext i32 %1689 to i64
  %1691 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1690
  %1692 = load float, float addrspace(1)* %1691, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1693 = add nuw nsw i32 %24, 119
  %1694 = sext i32 %1693 to i64
  %1695 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1694
  %1696 = load float, float addrspace(1)* %1695, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1697 = fmul contract float %1692, %1696
  %1698 = fadd contract float %1684, %1697
  %1699 = fmul contract float %1696, %1696
  %1700 = fadd contract float %1686, %1699
  %1701 = fmul contract float %1692, %1692
  %1702 = fadd contract float %1688, %1701
  %1703 = add nuw nsw i32 %23, 120
  %1704 = sext i32 %1703 to i64
  %1705 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1704
  %1706 = load float, float addrspace(1)* %1705, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1707 = add nuw nsw i32 %24, 120
  %1708 = sext i32 %1707 to i64
  %1709 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1708
  %1710 = load float, float addrspace(1)* %1709, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1711 = fmul contract float %1706, %1710
  %1712 = fadd contract float %1698, %1711
  %1713 = fmul contract float %1710, %1710
  %1714 = fadd contract float %1700, %1713
  %1715 = fmul contract float %1706, %1706
  %1716 = fadd contract float %1702, %1715
  %1717 = add nuw nsw i32 %23, 121
  %1718 = sext i32 %1717 to i64
  %1719 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1718
  %1720 = load float, float addrspace(1)* %1719, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1721 = add nuw nsw i32 %24, 121
  %1722 = sext i32 %1721 to i64
  %1723 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1722
  %1724 = load float, float addrspace(1)* %1723, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1725 = fmul contract float %1720, %1724
  %1726 = fadd contract float %1712, %1725
  %1727 = fmul contract float %1724, %1724
  %1728 = fadd contract float %1714, %1727
  %1729 = fmul contract float %1720, %1720
  %1730 = fadd contract float %1716, %1729
  %1731 = add nuw nsw i32 %23, 122
  %1732 = sext i32 %1731 to i64
  %1733 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1732
  %1734 = load float, float addrspace(1)* %1733, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1735 = add nuw nsw i32 %24, 122
  %1736 = sext i32 %1735 to i64
  %1737 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1736
  %1738 = load float, float addrspace(1)* %1737, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1739 = fmul contract float %1734, %1738
  %1740 = fadd contract float %1726, %1739
  %1741 = fmul contract float %1738, %1738
  %1742 = fadd contract float %1728, %1741
  %1743 = fmul contract float %1734, %1734
  %1744 = fadd contract float %1730, %1743
  %1745 = add nuw nsw i32 %23, 123
  %1746 = sext i32 %1745 to i64
  %1747 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1746
  %1748 = load float, float addrspace(1)* %1747, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1749 = add nuw nsw i32 %24, 123
  %1750 = sext i32 %1749 to i64
  %1751 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1750
  %1752 = load float, float addrspace(1)* %1751, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1753 = fmul contract float %1748, %1752
  %1754 = fadd contract float %1740, %1753
  %1755 = fmul contract float %1752, %1752
  %1756 = fadd contract float %1742, %1755
  %1757 = fmul contract float %1748, %1748
  %1758 = fadd contract float %1744, %1757
  %1759 = add nuw nsw i32 %23, 124
  %1760 = sext i32 %1759 to i64
  %1761 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1760
  %1762 = load float, float addrspace(1)* %1761, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1763 = add nuw nsw i32 %24, 124
  %1764 = sext i32 %1763 to i64
  %1765 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1764
  %1766 = load float, float addrspace(1)* %1765, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1767 = fmul contract float %1762, %1766
  %1768 = fadd contract float %1754, %1767
  %1769 = fmul contract float %1766, %1766
  %1770 = fadd contract float %1756, %1769
  %1771 = fmul contract float %1762, %1762
  %1772 = fadd contract float %1758, %1771
  %1773 = add nuw nsw i32 %23, 125
  %1774 = sext i32 %1773 to i64
  %1775 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1774
  %1776 = load float, float addrspace(1)* %1775, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1777 = add nuw nsw i32 %24, 125
  %1778 = sext i32 %1777 to i64
  %1779 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1778
  %1780 = load float, float addrspace(1)* %1779, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1781 = fmul contract float %1776, %1780
  %1782 = fadd contract float %1768, %1781
  %1783 = fmul contract float %1780, %1780
  %1784 = fadd contract float %1770, %1783
  %1785 = fmul contract float %1776, %1776
  %1786 = fadd contract float %1772, %1785
  %1787 = add nuw nsw i32 %23, 126
  %1788 = sext i32 %1787 to i64
  %1789 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1788
  %1790 = load float, float addrspace(1)* %1789, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1791 = add nuw nsw i32 %24, 126
  %1792 = sext i32 %1791 to i64
  %1793 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1792
  %1794 = load float, float addrspace(1)* %1793, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1795 = fmul contract float %1790, %1794
  %1796 = fadd contract float %1782, %1795
  %1797 = fmul contract float %1794, %1794
  %1798 = fadd contract float %1784, %1797
  %1799 = fmul contract float %1790, %1790
  %1800 = fadd contract float %1786, %1799
  %1801 = add nuw nsw i32 %23, 127
  %1802 = sext i32 %1801 to i64
  %1803 = getelementptr inbounds float, float addrspace(1)* %0, i64 %1802
  %1804 = load float, float addrspace(1)* %1803, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1805 = add nuw nsw i32 %24, 127
  %1806 = sext i32 %1805 to i64
  %1807 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1806
  %1808 = load float, float addrspace(1)* %1807, align 4, !tbaa !16, !amdgpu.noclobber !5
  %1809 = fmul contract float %1804, %1808
  %1810 = fadd contract float %1796, %1809
  %1811 = fmul contract float %1808, %1808
  %1812 = fadd contract float %1798, %1811
  %1813 = fmul contract float %1804, %1804
  %1814 = fadd contract float %1800, %1813
  %1815 = fcmp olt float %1812, 0x39F0000000000000
  %1816 = select i1 %1815, float 0x41F0000000000000, float 1.000000e+00
  %1817 = fmul float %1812, %1816
  %1818 = tail call float @llvm.sqrt.f32(float %1817)
  %1819 = bitcast float %1818 to i32
  %1820 = add nsw i32 %1819, -1
  %1821 = bitcast i32 %1820 to float
  %1822 = add nsw i32 %1819, 1
  %1823 = bitcast i32 %1822 to float
  %1824 = tail call i1 @llvm.amdgcn.class.f32(float %1817, i32 608)
  %1825 = select i1 %1815, float 0x3EF0000000000000, float 1.000000e+00
  %1826 = fneg float %1823
  %1827 = tail call float @llvm.fma.f32(float %1826, float %1818, float %1817)
  %1828 = fcmp ogt float %1827, 0.000000e+00
  %1829 = fneg float %1821
  %1830 = tail call float @llvm.fma.f32(float %1829, float %1818, float %1817)
  %1831 = fcmp ole float %1830, 0.000000e+00
  %1832 = select i1 %1831, float %1821, float %1818
  %1833 = select i1 %1828, float %1823, float %1832
  %1834 = fmul float %1825, %1833
  %1835 = select i1 %1824, float %1817, float %1834
  %1836 = fcmp olt float %1814, 0x39F0000000000000
  %1837 = select i1 %1836, float 0x41F0000000000000, float 1.000000e+00
  %1838 = fmul float %1814, %1837
  %1839 = tail call float @llvm.sqrt.f32(float %1838)
  %1840 = bitcast float %1839 to i32
  %1841 = add nsw i32 %1840, -1
  %1842 = bitcast i32 %1841 to float
  %1843 = add nsw i32 %1840, 1
  %1844 = bitcast i32 %1843 to float
  %1845 = tail call i1 @llvm.amdgcn.class.f32(float %1838, i32 608)
  %1846 = select i1 %1836, float 0x3EF0000000000000, float 1.000000e+00
  %1847 = fneg float %1844
  %1848 = tail call float @llvm.fma.f32(float %1847, float %1839, float %1838)
  %1849 = fcmp ogt float %1848, 0.000000e+00
  %1850 = fneg float %1842
  %1851 = tail call float @llvm.fma.f32(float %1850, float %1839, float %1838)
  %1852 = fcmp ole float %1851, 0.000000e+00
  %1853 = select i1 %1852, float %1842, float %1839
  %1854 = select i1 %1849, float %1844, float %1853
  %1855 = fmul float %1846, %1854
  %1856 = select i1 %1845, float %1838, float %1855
  %1857 = fdiv contract float %1835, %1856
  %1858 = fdiv contract float %1810, %1857
  %1859 = getelementptr inbounds [1024 x [2 x float]], [1024 x [2 x float]] addrspace(3)* @_ZZ14createHistCudaPfS_iiS_E7cosines, i32 0, i32 %16, i32 0
  store float %1858, float addrspace(3)* %1859, align 8, !tbaa !16
  %1860 = uitofp i32 %17 to float
  %1861 = getelementptr inbounds [1024 x [2 x float]], [1024 x [2 x float]] addrspace(3)* @_ZZ14createHistCudaPfS_iiS_E7cosines, i32 0, i32 %16, i32 1
  store float %1860, float addrspace(3)* %1861, align 4, !tbaa !16
  fence syncscope("workgroup") release
  tail call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  %1862 = icmp ult i16 %10, 2
  br i1 %1862, label %1863, label %1865

1863:                                             ; preds = %1878, %22
  %1864 = icmp eq i32 %16, 0
  br i1 %1864, label %1880, label %1896

1865:                                             ; preds = %22, %1878
  %1866 = phi i32 [ %1867, %1878 ], [ %11, %22 ]
  %1867 = lshr i32 %1866, 1
  %1868 = icmp ult i32 %16, %1867
  br i1 %1868, label %1869, label %1878

1869:                                             ; preds = %1865
  %1870 = add nuw nsw i32 %1867, %16
  %1871 = getelementptr inbounds [1024 x [2 x float]], [1024 x [2 x float]] addrspace(3)* @_ZZ14createHistCudaPfS_iiS_E7cosines, i32 0, i32 %1870, i32 0
  %1872 = load float, float addrspace(3)* %1871, align 8, !tbaa !16
  %1873 = load float, float addrspace(3)* %1859, align 8, !tbaa !16
  %1874 = fcmp contract ogt float %1872, %1873
  br i1 %1874, label %1875, label %1878

1875:                                             ; preds = %1869
  store float %1872, float addrspace(3)* %1859, align 8, !tbaa !16
  %1876 = getelementptr inbounds [1024 x [2 x float]], [1024 x [2 x float]] addrspace(3)* @_ZZ14createHistCudaPfS_iiS_E7cosines, i32 0, i32 %1870, i32 1
  %1877 = load float, float addrspace(3)* %1876, align 4, !tbaa !16
  store float %1877, float addrspace(3)* %1861, align 4, !tbaa !16
  br label %1878

1878:                                             ; preds = %1869, %1875, %1865
  fence syncscope("workgroup") release
  tail call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  %1879 = icmp ult i32 %1866, 4
  br i1 %1879, label %1863, label %1865, !llvm.loop !20

1880:                                             ; preds = %1863
  %1881 = load float, float addrspace(3)* getelementptr inbounds ([1024 x [2 x float]], [1024 x [2 x float]] addrspace(3)* @_ZZ14createHistCudaPfS_iiS_E7cosines, i32 0, i32 0, i32 0), align 16, !tbaa !16
  %1882 = udiv i32 %14, %11
  %1883 = mul i32 %1882, %11
  %1884 = icmp ugt i32 %14, %1883
  %1885 = zext i1 %1884 to i32
  %1886 = add i32 %1882, %1885
  %1887 = mul i32 %1886, %19
  %1888 = add i32 %1887, %6
  %1889 = shl i32 %1888, 1
  %1890 = zext i32 %1889 to i64
  %1891 = getelementptr inbounds float, float addrspace(1)* %4, i64 %1890
  store float %1881, float addrspace(1)* %1891, align 4, !tbaa !16
  %1892 = load float, float addrspace(3)* getelementptr inbounds ([1024 x [2 x float]], [1024 x [2 x float]] addrspace(3)* @_ZZ14createHistCudaPfS_iiS_E7cosines, i32 0, i32 0, i32 1), align 4, !tbaa !16
  %1893 = add nuw nsw i32 %1889, 1
  %1894 = zext i32 %1893 to i64
  %1895 = getelementptr inbounds float, float addrspace(1)* %4, i64 %1894
  store float %1892, float addrspace(1)* %1895, align 4, !tbaa !16
  br label %1896

1896:                                             ; preds = %1863, %1880, %5
  ret void
}

; Function Attrs: convergent mustprogress nounwind willreturn
declare void @llvm.amdgcn.s.barrier() #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.sqrt.f32(float) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn
declare float @llvm.fma.f32(float, float, float) #2

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i1 @llvm.amdgcn.class.f32(float, i32) #3

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare align 4 i8 addrspace(4)* @llvm.amdgcn.dispatch.ptr() #3

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workitem.id.x() #3

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.x() #3

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.y() #3

attributes #0 = { convergent mustprogress norecurse nounwind "amdgpu-flat-work-group-size"="1,256" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx906" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+s-memrealtime,+s-memtime-inst,+sramecc" "uniform-work-group-size"="true" }
attributes #1 = { convergent mustprogress nounwind willreturn }
attributes #2 = { mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn }
attributes #3 = { mustprogress nofree nosync nounwind readnone speculatable willreturn }

!llvm.module.flags = !{!0, !1}
!opencl.ocl.version = !{!2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 1}
!2 = !{i32 2, i32 0}
!3 = !{!"clang version 15.0.0 (http://10.15.3.7/dcutoolkit/driverruntime/llvm-project.git 340750feeda88c9c2ce8ad481b11d9aa7f033d39)"}
!4 = !{i16 1, i16 1025}
!5 = !{}
!6 = !{!7, !11, i64 12}
!7 = !{!"hsa_kernel_dispatch_packet_s", !8, i64 0, !8, i64 2, !8, i64 4, !8, i64 6, !8, i64 8, !8, i64 10, !11, i64 12, !11, i64 16, !11, i64 20, !11, i64 24, !11, i64 28, !12, i64 32, !13, i64 40, !12, i64 48, !14, i64 56}
!8 = !{!"short", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C/C++ TBAA"}
!11 = !{!"int", !9, i64 0}
!12 = !{!"long", !9, i64 0}
!13 = !{!"any pointer", !9, i64 0}
!14 = !{!"hsa_signal_s", !12, i64 0}
!15 = !{i32 0, i32 1024}
!16 = !{!17, !17, i64 0}
!17 = !{!"float", !18, i64 0}
!18 = !{!"omnipotent char", !19, i64 0}
!19 = !{!"Simple C++ TBAA"}
!20 = distinct !{!20, !21}
!21 = !{!"llvm.loop.mustprogress"}
