digraph "CFG for '_Z6Fprop1PKfS0_Pf' function" {
	label="CFG for '_Z6Fprop1PKfS0_Pf' function";

	Node0x4ab0f50 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#b9d0f970",label="{%3:\l  %4 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !4\l  %5 = tail call i32 @llvm.amdgcn.workgroup.id.x()\l  %6 = mul i32 %5, 784\l  br label %12\l}"];
	Node0x4ab0f50 -> Node0x4ab25b0;
	Node0x4ab26b0 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#b9d0f970",label="{%7:\l7:                                                \l  %8 = shl nsw i32 %5, 8\l  %9 = add nsw i32 %8, %4\l  %10 = sext i32 %9 to i64\l  %11 = getelementptr inbounds float, float addrspace(1)* %2, i64 %10\l  store float %109, float addrspace(1)* %11, align 4, !tbaa !5\l  ret void\l}"];
	Node0x4ab25b0 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%12:\l12:                                               \l  %13 = phi i32 [ 0, %3 ], [ %110, %12 ]\l  %14 = phi float [ 0.000000e+00, %3 ], [ %109, %12 ]\l  %15 = add nsw i32 %13, %6\l  %16 = sext i32 %15 to i64\l  %17 = getelementptr inbounds float, float addrspace(1)* %0, i64 %16\l  %18 = load float, float addrspace(1)* %17, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %19 = shl nuw nsw i32 %13, 8\l  %20 = or i32 %19, %4\l  %21 = zext i32 %20 to i64\l  %22 = getelementptr inbounds float, float addrspace(1)* %1, i64 %21\l  %23 = load float, float addrspace(1)* %22, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %24 = fmul contract float %18, %23\l  %25 = fadd contract float %14, %24\l  %26 = or i32 %13, 1\l  %27 = add nsw i32 %26, %6\l  %28 = sext i32 %27 to i64\l  %29 = getelementptr inbounds float, float addrspace(1)* %0, i64 %28\l  %30 = load float, float addrspace(1)* %29, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %31 = shl nuw nsw i32 %26, 8\l  %32 = add nuw nsw i32 %31, %4\l  %33 = zext i32 %32 to i64\l  %34 = getelementptr inbounds float, float addrspace(1)* %1, i64 %33\l  %35 = load float, float addrspace(1)* %34, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %36 = fmul contract float %30, %35\l  %37 = fadd contract float %25, %36\l  %38 = or i32 %13, 2\l  %39 = add nsw i32 %38, %6\l  %40 = sext i32 %39 to i64\l  %41 = getelementptr inbounds float, float addrspace(1)* %0, i64 %40\l  %42 = load float, float addrspace(1)* %41, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %43 = shl nuw nsw i32 %38, 8\l  %44 = add nuw nsw i32 %43, %4\l  %45 = zext i32 %44 to i64\l  %46 = getelementptr inbounds float, float addrspace(1)* %1, i64 %45\l  %47 = load float, float addrspace(1)* %46, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %48 = fmul contract float %42, %47\l  %49 = fadd contract float %37, %48\l  %50 = or i32 %13, 3\l  %51 = add nsw i32 %50, %6\l  %52 = sext i32 %51 to i64\l  %53 = getelementptr inbounds float, float addrspace(1)* %0, i64 %52\l  %54 = load float, float addrspace(1)* %53, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %55 = shl nuw nsw i32 %50, 8\l  %56 = add nuw nsw i32 %55, %4\l  %57 = zext i32 %56 to i64\l  %58 = getelementptr inbounds float, float addrspace(1)* %1, i64 %57\l  %59 = load float, float addrspace(1)* %58, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %60 = fmul contract float %54, %59\l  %61 = fadd contract float %49, %60\l  %62 = or i32 %13, 4\l  %63 = add nsw i32 %62, %6\l  %64 = sext i32 %63 to i64\l  %65 = getelementptr inbounds float, float addrspace(1)* %0, i64 %64\l  %66 = load float, float addrspace(1)* %65, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %67 = shl nuw nsw i32 %62, 8\l  %68 = or i32 %67, %4\l  %69 = zext i32 %68 to i64\l  %70 = getelementptr inbounds float, float addrspace(1)* %1, i64 %69\l  %71 = load float, float addrspace(1)* %70, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %72 = fmul contract float %66, %71\l  %73 = fadd contract float %61, %72\l  %74 = or i32 %13, 5\l  %75 = add nsw i32 %74, %6\l  %76 = sext i32 %75 to i64\l  %77 = getelementptr inbounds float, float addrspace(1)* %0, i64 %76\l  %78 = load float, float addrspace(1)* %77, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %79 = shl nuw nsw i32 %74, 8\l  %80 = add nuw nsw i32 %79, %4\l  %81 = zext i32 %80 to i64\l  %82 = getelementptr inbounds float, float addrspace(1)* %1, i64 %81\l  %83 = load float, float addrspace(1)* %82, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %84 = fmul contract float %78, %83\l  %85 = fadd contract float %73, %84\l  %86 = or i32 %13, 6\l  %87 = add nsw i32 %86, %6\l  %88 = sext i32 %87 to i64\l  %89 = getelementptr inbounds float, float addrspace(1)* %0, i64 %88\l  %90 = load float, float addrspace(1)* %89, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %91 = shl nuw nsw i32 %86, 8\l  %92 = add nuw nsw i32 %91, %4\l  %93 = zext i32 %92 to i64\l  %94 = getelementptr inbounds float, float addrspace(1)* %1, i64 %93\l  %95 = load float, float addrspace(1)* %94, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %96 = fmul contract float %90, %95\l  %97 = fadd contract float %85, %96\l  %98 = or i32 %13, 7\l  %99 = add nsw i32 %98, %6\l  %100 = sext i32 %99 to i64\l  %101 = getelementptr inbounds float, float addrspace(1)* %0, i64 %100\l  %102 = load float, float addrspace(1)* %101, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %103 = shl nuw nsw i32 %98, 8\l  %104 = add nuw nsw i32 %103, %4\l  %105 = zext i32 %104 to i64\l  %106 = getelementptr inbounds float, float addrspace(1)* %1, i64 %105\l  %107 = load float, float addrspace(1)* %106, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %108 = fmul contract float %102, %107\l  %109 = fadd contract float %97, %108\l  %110 = add nuw nsw i32 %13, 8\l  %111 = icmp eq i32 %110, 784\l  br i1 %111, label %7, label %12, !llvm.loop !10\l|{<s0>T|<s1>F}}"];
	Node0x4ab25b0:s0 -> Node0x4ab26b0;
	Node0x4ab25b0:s1 -> Node0x4ab25b0;
}
