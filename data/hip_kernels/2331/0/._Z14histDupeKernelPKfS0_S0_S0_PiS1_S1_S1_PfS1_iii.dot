digraph "CFG for '_Z14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iii' function" {
	label="CFG for '_Z14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iii' function";

	Node0x4a59a90 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#e3d9d370",label="{%13:\l  %14 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !4\l  %15 = tail call i32 @llvm.amdgcn.workgroup.id.x()\l  %16 = tail call align 4 dereferenceable(64) i8 addrspace(4)*\l... @llvm.amdgcn.dispatch.ptr()\l  %17 = getelementptr i8, i8 addrspace(4)* %16, i64 4\l  %18 = bitcast i8 addrspace(4)* %17 to i16 addrspace(4)*\l  %19 = load i16, i16 addrspace(4)* %18, align 4, !range !5, !invariant.load !6\l  %20 = zext i16 %19 to i32\l  %21 = mul i32 %15, %20\l  %22 = add i32 %21, %14\l  %23 = zext i32 %22 to i64\l  %24 = getelementptr inbounds float, float addrspace(1)* %2, i64 %23\l  %25 = load float, float addrspace(1)* %24, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %26 = getelementptr inbounds i32, i32 addrspace(1)* %4, i64 %23\l  %27 = load i32, i32 addrspace(1)* %26, align 4, !tbaa !11, !amdgpu.noclobber\l... !6\l  %28 = add nuw nsw i32 %14, 64\l  %29 = shl i32 %21, 7\l  %30 = add i32 %29, %14\l  %31 = zext i32 %30 to i64\l  %32 = getelementptr inbounds float, float addrspace(1)* %0, i64 %31\l  %33 = load float, float addrspace(1)* %32, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %34 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %14\l  store float %33, float addrspace(3)* %34, align 4, !tbaa !7\l  %35 = add i32 %28, %29\l  %36 = zext i32 %35 to i64\l  %37 = getelementptr inbounds float, float addrspace(1)* %0, i64 %36\l  %38 = load float, float addrspace(1)* %37, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %39 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %28\l  store float %38, float addrspace(3)* %39, align 4, !tbaa !7\l  %40 = shl i32 %21, 7\l  %41 = add i32 %40, 128\l  %42 = add i32 %41, %14\l  %43 = zext i32 %42 to i64\l  %44 = getelementptr inbounds float, float addrspace(1)* %0, i64 %43\l  %45 = load float, float addrspace(1)* %44, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %46 = add nuw nsw i32 %14, 128\l  %47 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %46\l  store float %45, float addrspace(3)* %47, align 4, !tbaa !7\l  %48 = add i32 %28, %41\l  %49 = zext i32 %48 to i64\l  %50 = getelementptr inbounds float, float addrspace(1)* %0, i64 %49\l  %51 = load float, float addrspace(1)* %50, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %52 = add nuw nsw i32 %14, 192\l  %53 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %52\l  store float %51, float addrspace(3)* %53, align 4, !tbaa !7\l  %54 = shl i32 %21, 7\l  %55 = add i32 %54, 256\l  %56 = add i32 %55, %14\l  %57 = zext i32 %56 to i64\l  %58 = getelementptr inbounds float, float addrspace(1)* %0, i64 %57\l  %59 = load float, float addrspace(1)* %58, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %60 = add nuw nsw i32 %14, 256\l  %61 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %60\l  store float %59, float addrspace(3)* %61, align 4, !tbaa !7\l  %62 = add i32 %28, %55\l  %63 = zext i32 %62 to i64\l  %64 = getelementptr inbounds float, float addrspace(1)* %0, i64 %63\l  %65 = load float, float addrspace(1)* %64, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %66 = add nuw nsw i32 %14, 320\l  %67 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %66\l  store float %65, float addrspace(3)* %67, align 4, !tbaa !7\l  %68 = shl i32 %21, 7\l  %69 = add i32 %68, 384\l  %70 = add i32 %69, %14\l  %71 = zext i32 %70 to i64\l  %72 = getelementptr inbounds float, float addrspace(1)* %0, i64 %71\l  %73 = load float, float addrspace(1)* %72, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %74 = add nuw nsw i32 %14, 384\l  %75 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %74\l  store float %73, float addrspace(3)* %75, align 4, !tbaa !7\l  %76 = add i32 %28, %69\l  %77 = zext i32 %76 to i64\l  %78 = getelementptr inbounds float, float addrspace(1)* %0, i64 %77\l  %79 = load float, float addrspace(1)* %78, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %80 = add nuw nsw i32 %14, 448\l  %81 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %80\l  store float %79, float addrspace(3)* %81, align 4, !tbaa !7\l  %82 = shl i32 %21, 7\l  %83 = add i32 %82, 512\l  %84 = add i32 %83, %14\l  %85 = zext i32 %84 to i64\l  %86 = getelementptr inbounds float, float addrspace(1)* %0, i64 %85\l  %87 = load float, float addrspace(1)* %86, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %88 = add nuw nsw i32 %14, 512\l  %89 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %88\l  store float %87, float addrspace(3)* %89, align 4, !tbaa !7\l  %90 = add i32 %28, %83\l  %91 = zext i32 %90 to i64\l  %92 = getelementptr inbounds float, float addrspace(1)* %0, i64 %91\l  %93 = load float, float addrspace(1)* %92, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %94 = add nuw nsw i32 %14, 576\l  %95 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %94\l  store float %93, float addrspace(3)* %95, align 4, !tbaa !7\l  %96 = shl i32 %21, 7\l  %97 = add i32 %96, 640\l  %98 = add i32 %97, %14\l  %99 = zext i32 %98 to i64\l  %100 = getelementptr inbounds float, float addrspace(1)* %0, i64 %99\l  %101 = load float, float addrspace(1)* %100, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %102 = add nuw nsw i32 %14, 640\l  %103 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %102\l  store float %101, float addrspace(3)* %103, align 4, !tbaa !7\l  %104 = add i32 %28, %97\l  %105 = zext i32 %104 to i64\l  %106 = getelementptr inbounds float, float addrspace(1)* %0, i64 %105\l  %107 = load float, float addrspace(1)* %106, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %108 = add nuw nsw i32 %14, 704\l  %109 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %108\l  store float %107, float addrspace(3)* %109, align 4, !tbaa !7\l  %110 = shl i32 %21, 7\l  %111 = add i32 %110, 768\l  %112 = add i32 %111, %14\l  %113 = zext i32 %112 to i64\l  %114 = getelementptr inbounds float, float addrspace(1)* %0, i64 %113\l  %115 = load float, float addrspace(1)* %114, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %116 = add nuw nsw i32 %14, 768\l  %117 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %116\l  store float %115, float addrspace(3)* %117, align 4, !tbaa !7\l  %118 = add i32 %28, %111\l  %119 = zext i32 %118 to i64\l  %120 = getelementptr inbounds float, float addrspace(1)* %0, i64 %119\l  %121 = load float, float addrspace(1)* %120, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %122 = add nuw nsw i32 %14, 832\l  %123 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %122\l  store float %121, float addrspace(3)* %123, align 4, !tbaa !7\l  %124 = shl i32 %21, 7\l  %125 = add i32 %124, 896\l  %126 = add i32 %125, %14\l  %127 = zext i32 %126 to i64\l  %128 = getelementptr inbounds float, float addrspace(1)* %0, i64 %127\l  %129 = load float, float addrspace(1)* %128, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %130 = add nuw nsw i32 %14, 896\l  %131 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %130\l  store float %129, float addrspace(3)* %131, align 4, !tbaa !7\l  %132 = add i32 %28, %125\l  %133 = zext i32 %132 to i64\l  %134 = getelementptr inbounds float, float addrspace(1)* %0, i64 %133\l  %135 = load float, float addrspace(1)* %134, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %136 = add nuw nsw i32 %14, 960\l  %137 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %136\l  store float %135, float addrspace(3)* %137, align 4, !tbaa !7\l  %138 = shl i32 %21, 7\l  %139 = add i32 %138, 1024\l  %140 = add i32 %139, %14\l  %141 = zext i32 %140 to i64\l  %142 = getelementptr inbounds float, float addrspace(1)* %0, i64 %141\l  %143 = load float, float addrspace(1)* %142, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %144 = or i32 %14, 1024\l  %145 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %144\l  store float %143, float addrspace(3)* %145, align 4, !tbaa !7\l  %146 = add i32 %28, %139\l  %147 = zext i32 %146 to i64\l  %148 = getelementptr inbounds float, float addrspace(1)* %0, i64 %147\l  %149 = load float, float addrspace(1)* %148, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %150 = add nuw nsw i32 %14, 1088\l  %151 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %150\l  store float %149, float addrspace(3)* %151, align 4, !tbaa !7\l  %152 = shl i32 %21, 7\l  %153 = add i32 %152, 1152\l  %154 = add i32 %153, %14\l  %155 = zext i32 %154 to i64\l  %156 = getelementptr inbounds float, float addrspace(1)* %0, i64 %155\l  %157 = load float, float addrspace(1)* %156, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %158 = add nuw nsw i32 %14, 1152\l  %159 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %158\l  store float %157, float addrspace(3)* %159, align 4, !tbaa !7\l  %160 = add i32 %28, %153\l  %161 = zext i32 %160 to i64\l  %162 = getelementptr inbounds float, float addrspace(1)* %0, i64 %161\l  %163 = load float, float addrspace(1)* %162, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %164 = add nuw nsw i32 %14, 1216\l  %165 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %164\l  store float %163, float addrspace(3)* %165, align 4, !tbaa !7\l  %166 = shl i32 %21, 7\l  %167 = add i32 %166, 1280\l  %168 = add i32 %167, %14\l  %169 = zext i32 %168 to i64\l  %170 = getelementptr inbounds float, float addrspace(1)* %0, i64 %169\l  %171 = load float, float addrspace(1)* %170, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %172 = add nuw nsw i32 %14, 1280\l  %173 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %172\l  store float %171, float addrspace(3)* %173, align 4, !tbaa !7\l  %174 = add i32 %28, %167\l  %175 = zext i32 %174 to i64\l  %176 = getelementptr inbounds float, float addrspace(1)* %0, i64 %175\l  %177 = load float, float addrspace(1)* %176, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %178 = add nuw nsw i32 %14, 1344\l  %179 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %178\l  store float %177, float addrspace(3)* %179, align 4, !tbaa !7\l  %180 = shl i32 %21, 7\l  %181 = add i32 %180, 1408\l  %182 = add i32 %181, %14\l  %183 = zext i32 %182 to i64\l  %184 = getelementptr inbounds float, float addrspace(1)* %0, i64 %183\l  %185 = load float, float addrspace(1)* %184, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %186 = add nuw nsw i32 %14, 1408\l  %187 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %186\l  store float %185, float addrspace(3)* %187, align 4, !tbaa !7\l  %188 = add i32 %28, %181\l  %189 = zext i32 %188 to i64\l  %190 = getelementptr inbounds float, float addrspace(1)* %0, i64 %189\l  %191 = load float, float addrspace(1)* %190, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %192 = add nuw nsw i32 %14, 1472\l  %193 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %192\l  store float %191, float addrspace(3)* %193, align 4, !tbaa !7\l  %194 = shl i32 %21, 7\l  %195 = add i32 %194, 1536\l  %196 = add i32 %195, %14\l  %197 = zext i32 %196 to i64\l  %198 = getelementptr inbounds float, float addrspace(1)* %0, i64 %197\l  %199 = load float, float addrspace(1)* %198, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %200 = add nuw nsw i32 %14, 1536\l  %201 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %200\l  store float %199, float addrspace(3)* %201, align 4, !tbaa !7\l  %202 = add i32 %28, %195\l  %203 = zext i32 %202 to i64\l  %204 = getelementptr inbounds float, float addrspace(1)* %0, i64 %203\l  %205 = load float, float addrspace(1)* %204, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %206 = add nuw nsw i32 %14, 1600\l  %207 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %206\l  store float %205, float addrspace(3)* %207, align 4, !tbaa !7\l  %208 = shl i32 %21, 7\l  %209 = add i32 %208, 1664\l  %210 = add i32 %209, %14\l  %211 = zext i32 %210 to i64\l  %212 = getelementptr inbounds float, float addrspace(1)* %0, i64 %211\l  %213 = load float, float addrspace(1)* %212, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %214 = add nuw nsw i32 %14, 1664\l  %215 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %214\l  store float %213, float addrspace(3)* %215, align 4, !tbaa !7\l  %216 = add i32 %28, %209\l  %217 = zext i32 %216 to i64\l  %218 = getelementptr inbounds float, float addrspace(1)* %0, i64 %217\l  %219 = load float, float addrspace(1)* %218, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %220 = add nuw nsw i32 %14, 1728\l  %221 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %220\l  store float %219, float addrspace(3)* %221, align 4, !tbaa !7\l  %222 = shl i32 %21, 7\l  %223 = add i32 %222, 1792\l  %224 = add i32 %223, %14\l  %225 = zext i32 %224 to i64\l  %226 = getelementptr inbounds float, float addrspace(1)* %0, i64 %225\l  %227 = load float, float addrspace(1)* %226, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %228 = add nuw nsw i32 %14, 1792\l  %229 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %228\l  store float %227, float addrspace(3)* %229, align 4, !tbaa !7\l  %230 = add i32 %28, %223\l  %231 = zext i32 %230 to i64\l  %232 = getelementptr inbounds float, float addrspace(1)* %0, i64 %231\l  %233 = load float, float addrspace(1)* %232, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %234 = add nuw nsw i32 %14, 1856\l  %235 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %234\l  store float %233, float addrspace(3)* %235, align 4, !tbaa !7\l  %236 = shl i32 %21, 7\l  %237 = add i32 %236, 1920\l  %238 = add i32 %237, %14\l  %239 = zext i32 %238 to i64\l  %240 = getelementptr inbounds float, float addrspace(1)* %0, i64 %239\l  %241 = load float, float addrspace(1)* %240, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %242 = add nuw nsw i32 %14, 1920\l  %243 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %242\l  store float %241, float addrspace(3)* %243, align 4, !tbaa !7\l  %244 = add i32 %28, %237\l  %245 = zext i32 %244 to i64\l  %246 = getelementptr inbounds float, float addrspace(1)* %0, i64 %245\l  %247 = load float, float addrspace(1)* %246, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %248 = add nuw nsw i32 %14, 1984\l  %249 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %248\l  store float %247, float addrspace(3)* %249, align 4, !tbaa !7\l  %250 = shl i32 %21, 7\l  %251 = add i32 %250, 2048\l  %252 = add i32 %251, %14\l  %253 = zext i32 %252 to i64\l  %254 = getelementptr inbounds float, float addrspace(1)* %0, i64 %253\l  %255 = load float, float addrspace(1)* %254, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %256 = or i32 %14, 2048\l  %257 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %256\l  store float %255, float addrspace(3)* %257, align 4, !tbaa !7\l  %258 = add i32 %28, %251\l  %259 = zext i32 %258 to i64\l  %260 = getelementptr inbounds float, float addrspace(1)* %0, i64 %259\l  %261 = load float, float addrspace(1)* %260, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %262 = add nuw nsw i32 %14, 2112\l  %263 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %262\l  store float %261, float addrspace(3)* %263, align 4, !tbaa !7\l  %264 = shl i32 %21, 7\l  %265 = add i32 %264, 2176\l  %266 = add i32 %265, %14\l  %267 = zext i32 %266 to i64\l  %268 = getelementptr inbounds float, float addrspace(1)* %0, i64 %267\l  %269 = load float, float addrspace(1)* %268, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %270 = add nuw nsw i32 %14, 2176\l  %271 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %270\l  store float %269, float addrspace(3)* %271, align 4, !tbaa !7\l  %272 = add i32 %28, %265\l  %273 = zext i32 %272 to i64\l  %274 = getelementptr inbounds float, float addrspace(1)* %0, i64 %273\l  %275 = load float, float addrspace(1)* %274, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %276 = add nuw nsw i32 %14, 2240\l  %277 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %276\l  store float %275, float addrspace(3)* %277, align 4, !tbaa !7\l  %278 = shl i32 %21, 7\l  %279 = add i32 %278, 2304\l  %280 = add i32 %279, %14\l  %281 = zext i32 %280 to i64\l  %282 = getelementptr inbounds float, float addrspace(1)* %0, i64 %281\l  %283 = load float, float addrspace(1)* %282, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %284 = add nuw nsw i32 %14, 2304\l  %285 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %284\l  store float %283, float addrspace(3)* %285, align 4, !tbaa !7\l  %286 = add i32 %28, %279\l  %287 = zext i32 %286 to i64\l  %288 = getelementptr inbounds float, float addrspace(1)* %0, i64 %287\l  %289 = load float, float addrspace(1)* %288, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %290 = add nuw nsw i32 %14, 2368\l  %291 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %290\l  store float %289, float addrspace(3)* %291, align 4, !tbaa !7\l  %292 = shl i32 %21, 7\l  %293 = add i32 %292, 2432\l  %294 = add i32 %293, %14\l  %295 = zext i32 %294 to i64\l  %296 = getelementptr inbounds float, float addrspace(1)* %0, i64 %295\l  %297 = load float, float addrspace(1)* %296, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %298 = add nuw nsw i32 %14, 2432\l  %299 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %298\l  store float %297, float addrspace(3)* %299, align 4, !tbaa !7\l  %300 = add i32 %28, %293\l  %301 = zext i32 %300 to i64\l  %302 = getelementptr inbounds float, float addrspace(1)* %0, i64 %301\l  %303 = load float, float addrspace(1)* %302, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %304 = add nuw nsw i32 %14, 2496\l  %305 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %304\l  store float %303, float addrspace(3)* %305, align 4, !tbaa !7\l  %306 = shl i32 %21, 7\l  %307 = add i32 %306, 2560\l  %308 = add i32 %307, %14\l  %309 = zext i32 %308 to i64\l  %310 = getelementptr inbounds float, float addrspace(1)* %0, i64 %309\l  %311 = load float, float addrspace(1)* %310, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %312 = add nuw nsw i32 %14, 2560\l  %313 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %312\l  store float %311, float addrspace(3)* %313, align 4, !tbaa !7\l  %314 = add i32 %28, %307\l  %315 = zext i32 %314 to i64\l  %316 = getelementptr inbounds float, float addrspace(1)* %0, i64 %315\l  %317 = load float, float addrspace(1)* %316, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %318 = add nuw nsw i32 %14, 2624\l  %319 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %318\l  store float %317, float addrspace(3)* %319, align 4, !tbaa !7\l  %320 = shl i32 %21, 7\l  %321 = add i32 %320, 2688\l  %322 = add i32 %321, %14\l  %323 = zext i32 %322 to i64\l  %324 = getelementptr inbounds float, float addrspace(1)* %0, i64 %323\l  %325 = load float, float addrspace(1)* %324, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %326 = add nuw nsw i32 %14, 2688\l  %327 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %326\l  store float %325, float addrspace(3)* %327, align 4, !tbaa !7\l  %328 = add i32 %28, %321\l  %329 = zext i32 %328 to i64\l  %330 = getelementptr inbounds float, float addrspace(1)* %0, i64 %329\l  %331 = load float, float addrspace(1)* %330, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %332 = add nuw nsw i32 %14, 2752\l  %333 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %332\l  store float %331, float addrspace(3)* %333, align 4, !tbaa !7\l  %334 = shl i32 %21, 7\l  %335 = add i32 %334, 2816\l  %336 = add i32 %335, %14\l  %337 = zext i32 %336 to i64\l  %338 = getelementptr inbounds float, float addrspace(1)* %0, i64 %337\l  %339 = load float, float addrspace(1)* %338, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %340 = add nuw nsw i32 %14, 2816\l  %341 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %340\l  store float %339, float addrspace(3)* %341, align 4, !tbaa !7\l  %342 = add i32 %28, %335\l  %343 = zext i32 %342 to i64\l  %344 = getelementptr inbounds float, float addrspace(1)* %0, i64 %343\l  %345 = load float, float addrspace(1)* %344, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %346 = add nuw nsw i32 %14, 2880\l  %347 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %346\l  store float %345, float addrspace(3)* %347, align 4, !tbaa !7\l  %348 = shl i32 %21, 7\l  %349 = add i32 %348, 2944\l  %350 = add i32 %349, %14\l  %351 = zext i32 %350 to i64\l  %352 = getelementptr inbounds float, float addrspace(1)* %0, i64 %351\l  %353 = load float, float addrspace(1)* %352, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %354 = add nuw nsw i32 %14, 2944\l  %355 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %354\l  store float %353, float addrspace(3)* %355, align 4, !tbaa !7\l  %356 = add i32 %28, %349\l  %357 = zext i32 %356 to i64\l  %358 = getelementptr inbounds float, float addrspace(1)* %0, i64 %357\l  %359 = load float, float addrspace(1)* %358, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %360 = add nuw nsw i32 %14, 3008\l  %361 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %360\l  store float %359, float addrspace(3)* %361, align 4, !tbaa !7\l  %362 = shl i32 %21, 7\l  %363 = add i32 %362, 3072\l  %364 = add i32 %363, %14\l  %365 = zext i32 %364 to i64\l  %366 = getelementptr inbounds float, float addrspace(1)* %0, i64 %365\l  %367 = load float, float addrspace(1)* %366, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %368 = or i32 %14, 3072\l  %369 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %368\l  store float %367, float addrspace(3)* %369, align 4, !tbaa !7\l  %370 = add i32 %28, %363\l  %371 = zext i32 %370 to i64\l  %372 = getelementptr inbounds float, float addrspace(1)* %0, i64 %371\l  %373 = load float, float addrspace(1)* %372, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %374 = add nuw nsw i32 %14, 3136\l  %375 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %374\l  store float %373, float addrspace(3)* %375, align 4, !tbaa !7\l  %376 = shl i32 %21, 7\l  %377 = add i32 %376, 3200\l  %378 = add i32 %377, %14\l  %379 = zext i32 %378 to i64\l  %380 = getelementptr inbounds float, float addrspace(1)* %0, i64 %379\l  %381 = load float, float addrspace(1)* %380, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %382 = add nuw nsw i32 %14, 3200\l  %383 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %382\l  store float %381, float addrspace(3)* %383, align 4, !tbaa !7\l  %384 = add i32 %28, %377\l  %385 = zext i32 %384 to i64\l  %386 = getelementptr inbounds float, float addrspace(1)* %0, i64 %385\l  %387 = load float, float addrspace(1)* %386, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %388 = add nuw nsw i32 %14, 3264\l  %389 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %388\l  store float %387, float addrspace(3)* %389, align 4, !tbaa !7\l  %390 = shl i32 %21, 7\l  %391 = add i32 %390, 3328\l  %392 = add i32 %391, %14\l  %393 = zext i32 %392 to i64\l  %394 = getelementptr inbounds float, float addrspace(1)* %0, i64 %393\l  %395 = load float, float addrspace(1)* %394, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %396 = add nuw nsw i32 %14, 3328\l  %397 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %396\l  store float %395, float addrspace(3)* %397, align 4, !tbaa !7\l  %398 = add i32 %28, %391\l  %399 = zext i32 %398 to i64\l  %400 = getelementptr inbounds float, float addrspace(1)* %0, i64 %399\l  %401 = load float, float addrspace(1)* %400, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %402 = add nuw nsw i32 %14, 3392\l  %403 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %402\l  store float %401, float addrspace(3)* %403, align 4, !tbaa !7\l  %404 = shl i32 %21, 7\l  %405 = add i32 %404, 3456\l  %406 = add i32 %405, %14\l  %407 = zext i32 %406 to i64\l  %408 = getelementptr inbounds float, float addrspace(1)* %0, i64 %407\l  %409 = load float, float addrspace(1)* %408, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %410 = add nuw nsw i32 %14, 3456\l  %411 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %410\l  store float %409, float addrspace(3)* %411, align 4, !tbaa !7\l  %412 = add i32 %28, %405\l  %413 = zext i32 %412 to i64\l  %414 = getelementptr inbounds float, float addrspace(1)* %0, i64 %413\l  %415 = load float, float addrspace(1)* %414, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %416 = add nuw nsw i32 %14, 3520\l  %417 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %416\l  store float %415, float addrspace(3)* %417, align 4, !tbaa !7\l  %418 = shl i32 %21, 7\l  %419 = add i32 %418, 3584\l  %420 = add i32 %419, %14\l  %421 = zext i32 %420 to i64\l  %422 = getelementptr inbounds float, float addrspace(1)* %0, i64 %421\l  %423 = load float, float addrspace(1)* %422, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %424 = add nuw nsw i32 %14, 3584\l  %425 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %424\l  store float %423, float addrspace(3)* %425, align 4, !tbaa !7\l  %426 = add i32 %28, %419\l  %427 = zext i32 %426 to i64\l  %428 = getelementptr inbounds float, float addrspace(1)* %0, i64 %427\l  %429 = load float, float addrspace(1)* %428, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %430 = add nuw nsw i32 %14, 3648\l  %431 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %430\l  store float %429, float addrspace(3)* %431, align 4, !tbaa !7\l  %432 = shl i32 %21, 7\l  %433 = add i32 %432, 3712\l  %434 = add i32 %433, %14\l  %435 = zext i32 %434 to i64\l  %436 = getelementptr inbounds float, float addrspace(1)* %0, i64 %435\l  %437 = load float, float addrspace(1)* %436, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %438 = add nuw nsw i32 %14, 3712\l  %439 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %438\l  store float %437, float addrspace(3)* %439, align 4, !tbaa !7\l  %440 = add i32 %28, %433\l  %441 = zext i32 %440 to i64\l  %442 = getelementptr inbounds float, float addrspace(1)* %0, i64 %441\l  %443 = load float, float addrspace(1)* %442, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %444 = add nuw nsw i32 %14, 3776\l  %445 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %444\l  store float %443, float addrspace(3)* %445, align 4, !tbaa !7\l  %446 = shl i32 %21, 7\l  %447 = add i32 %446, 3840\l  %448 = add i32 %447, %14\l  %449 = zext i32 %448 to i64\l  %450 = getelementptr inbounds float, float addrspace(1)* %0, i64 %449\l  %451 = load float, float addrspace(1)* %450, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %452 = add nuw nsw i32 %14, 3840\l  %453 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %452\l  store float %451, float addrspace(3)* %453, align 4, !tbaa !7\l  %454 = add i32 %28, %447\l  %455 = zext i32 %454 to i64\l  %456 = getelementptr inbounds float, float addrspace(1)* %0, i64 %455\l  %457 = load float, float addrspace(1)* %456, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %458 = add nuw nsw i32 %14, 3904\l  %459 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %458\l  store float %457, float addrspace(3)* %459, align 4, !tbaa !7\l  %460 = shl i32 %21, 7\l  %461 = add i32 %460, 3968\l  %462 = add i32 %461, %14\l  %463 = zext i32 %462 to i64\l  %464 = getelementptr inbounds float, float addrspace(1)* %0, i64 %463\l  %465 = load float, float addrspace(1)* %464, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %466 = add nuw nsw i32 %14, 3968\l  %467 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %466\l  store float %465, float addrspace(3)* %467, align 4, !tbaa !7\l  %468 = add i32 %28, %461\l  %469 = zext i32 %468 to i64\l  %470 = getelementptr inbounds float, float addrspace(1)* %0, i64 %469\l  %471 = load float, float addrspace(1)* %470, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %472 = add nuw nsw i32 %14, 4032\l  %473 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %472\l  store float %471, float addrspace(3)* %473, align 4, !tbaa !7\l  %474 = shl i32 %21, 7\l  %475 = add i32 %474, 4096\l  %476 = add i32 %475, %14\l  %477 = zext i32 %476 to i64\l  %478 = getelementptr inbounds float, float addrspace(1)* %0, i64 %477\l  %479 = load float, float addrspace(1)* %478, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %480 = or i32 %14, 4096\l  %481 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %480\l  store float %479, float addrspace(3)* %481, align 4, !tbaa !7\l  %482 = add i32 %28, %475\l  %483 = zext i32 %482 to i64\l  %484 = getelementptr inbounds float, float addrspace(1)* %0, i64 %483\l  %485 = load float, float addrspace(1)* %484, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %486 = add nuw nsw i32 %14, 4160\l  %487 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %486\l  store float %485, float addrspace(3)* %487, align 4, !tbaa !7\l  %488 = shl i32 %21, 7\l  %489 = add i32 %488, 4224\l  %490 = add i32 %489, %14\l  %491 = zext i32 %490 to i64\l  %492 = getelementptr inbounds float, float addrspace(1)* %0, i64 %491\l  %493 = load float, float addrspace(1)* %492, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %494 = add nuw nsw i32 %14, 4224\l  %495 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %494\l  store float %493, float addrspace(3)* %495, align 4, !tbaa !7\l  %496 = add i32 %28, %489\l  %497 = zext i32 %496 to i64\l  %498 = getelementptr inbounds float, float addrspace(1)* %0, i64 %497\l  %499 = load float, float addrspace(1)* %498, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %500 = add nuw nsw i32 %14, 4288\l  %501 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %500\l  store float %499, float addrspace(3)* %501, align 4, !tbaa !7\l  %502 = shl i32 %21, 7\l  %503 = add i32 %502, 4352\l  %504 = add i32 %503, %14\l  %505 = zext i32 %504 to i64\l  %506 = getelementptr inbounds float, float addrspace(1)* %0, i64 %505\l  %507 = load float, float addrspace(1)* %506, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %508 = add nuw nsw i32 %14, 4352\l  %509 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %508\l  store float %507, float addrspace(3)* %509, align 4, !tbaa !7\l  %510 = add i32 %28, %503\l  %511 = zext i32 %510 to i64\l  %512 = getelementptr inbounds float, float addrspace(1)* %0, i64 %511\l  %513 = load float, float addrspace(1)* %512, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %514 = add nuw nsw i32 %14, 4416\l  %515 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %514\l  store float %513, float addrspace(3)* %515, align 4, !tbaa !7\l  %516 = shl i32 %21, 7\l  %517 = add i32 %516, 4480\l  %518 = add i32 %517, %14\l  %519 = zext i32 %518 to i64\l  %520 = getelementptr inbounds float, float addrspace(1)* %0, i64 %519\l  %521 = load float, float addrspace(1)* %520, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %522 = add nuw nsw i32 %14, 4480\l  %523 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %522\l  store float %521, float addrspace(3)* %523, align 4, !tbaa !7\l  %524 = add i32 %28, %517\l  %525 = zext i32 %524 to i64\l  %526 = getelementptr inbounds float, float addrspace(1)* %0, i64 %525\l  %527 = load float, float addrspace(1)* %526, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %528 = add nuw nsw i32 %14, 4544\l  %529 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %528\l  store float %527, float addrspace(3)* %529, align 4, !tbaa !7\l  %530 = shl i32 %21, 7\l  %531 = add i32 %530, 4608\l  %532 = add i32 %531, %14\l  %533 = zext i32 %532 to i64\l  %534 = getelementptr inbounds float, float addrspace(1)* %0, i64 %533\l  %535 = load float, float addrspace(1)* %534, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %536 = add nuw nsw i32 %14, 4608\l  %537 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %536\l  store float %535, float addrspace(3)* %537, align 4, !tbaa !7\l  %538 = add i32 %28, %531\l  %539 = zext i32 %538 to i64\l  %540 = getelementptr inbounds float, float addrspace(1)* %0, i64 %539\l  %541 = load float, float addrspace(1)* %540, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %542 = add nuw nsw i32 %14, 4672\l  %543 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %542\l  store float %541, float addrspace(3)* %543, align 4, !tbaa !7\l  %544 = shl i32 %21, 7\l  %545 = add i32 %544, 4736\l  %546 = add i32 %545, %14\l  %547 = zext i32 %546 to i64\l  %548 = getelementptr inbounds float, float addrspace(1)* %0, i64 %547\l  %549 = load float, float addrspace(1)* %548, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %550 = add nuw nsw i32 %14, 4736\l  %551 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %550\l  store float %549, float addrspace(3)* %551, align 4, !tbaa !7\l  %552 = add i32 %28, %545\l  %553 = zext i32 %552 to i64\l  %554 = getelementptr inbounds float, float addrspace(1)* %0, i64 %553\l  %555 = load float, float addrspace(1)* %554, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %556 = add nuw nsw i32 %14, 4800\l  %557 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %556\l  store float %555, float addrspace(3)* %557, align 4, !tbaa !7\l  %558 = shl i32 %21, 7\l  %559 = add i32 %558, 4864\l  %560 = add i32 %559, %14\l  %561 = zext i32 %560 to i64\l  %562 = getelementptr inbounds float, float addrspace(1)* %0, i64 %561\l  %563 = load float, float addrspace(1)* %562, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %564 = add nuw nsw i32 %14, 4864\l  %565 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %564\l  store float %563, float addrspace(3)* %565, align 4, !tbaa !7\l  %566 = add i32 %28, %559\l  %567 = zext i32 %566 to i64\l  %568 = getelementptr inbounds float, float addrspace(1)* %0, i64 %567\l  %569 = load float, float addrspace(1)* %568, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %570 = add nuw nsw i32 %14, 4928\l  %571 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %570\l  store float %569, float addrspace(3)* %571, align 4, !tbaa !7\l  %572 = shl i32 %21, 7\l  %573 = add i32 %572, 4992\l  %574 = add i32 %573, %14\l  %575 = zext i32 %574 to i64\l  %576 = getelementptr inbounds float, float addrspace(1)* %0, i64 %575\l  %577 = load float, float addrspace(1)* %576, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %578 = add nuw nsw i32 %14, 4992\l  %579 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %578\l  store float %577, float addrspace(3)* %579, align 4, !tbaa !7\l  %580 = add i32 %28, %573\l  %581 = zext i32 %580 to i64\l  %582 = getelementptr inbounds float, float addrspace(1)* %0, i64 %581\l  %583 = load float, float addrspace(1)* %582, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %584 = add nuw nsw i32 %14, 5056\l  %585 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %584\l  store float %583, float addrspace(3)* %585, align 4, !tbaa !7\l  %586 = shl i32 %21, 7\l  %587 = add i32 %586, 5120\l  %588 = add i32 %587, %14\l  %589 = zext i32 %588 to i64\l  %590 = getelementptr inbounds float, float addrspace(1)* %0, i64 %589\l  %591 = load float, float addrspace(1)* %590, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %592 = or i32 %14, 5120\l  %593 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %592\l  store float %591, float addrspace(3)* %593, align 4, !tbaa !7\l  %594 = add i32 %28, %587\l  %595 = zext i32 %594 to i64\l  %596 = getelementptr inbounds float, float addrspace(1)* %0, i64 %595\l  %597 = load float, float addrspace(1)* %596, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %598 = add nuw nsw i32 %14, 5184\l  %599 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %598\l  store float %597, float addrspace(3)* %599, align 4, !tbaa !7\l  %600 = shl i32 %21, 7\l  %601 = add i32 %600, 5248\l  %602 = add i32 %601, %14\l  %603 = zext i32 %602 to i64\l  %604 = getelementptr inbounds float, float addrspace(1)* %0, i64 %603\l  %605 = load float, float addrspace(1)* %604, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %606 = add nuw nsw i32 %14, 5248\l  %607 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %606\l  store float %605, float addrspace(3)* %607, align 4, !tbaa !7\l  %608 = add i32 %28, %601\l  %609 = zext i32 %608 to i64\l  %610 = getelementptr inbounds float, float addrspace(1)* %0, i64 %609\l  %611 = load float, float addrspace(1)* %610, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %612 = add nuw nsw i32 %14, 5312\l  %613 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %612\l  store float %611, float addrspace(3)* %613, align 4, !tbaa !7\l  %614 = shl i32 %21, 7\l  %615 = add i32 %614, 5376\l  %616 = add i32 %615, %14\l  %617 = zext i32 %616 to i64\l  %618 = getelementptr inbounds float, float addrspace(1)* %0, i64 %617\l  %619 = load float, float addrspace(1)* %618, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %620 = add nuw nsw i32 %14, 5376\l  %621 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %620\l  store float %619, float addrspace(3)* %621, align 4, !tbaa !7\l  %622 = add i32 %28, %615\l  %623 = zext i32 %622 to i64\l  %624 = getelementptr inbounds float, float addrspace(1)* %0, i64 %623\l  %625 = load float, float addrspace(1)* %624, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %626 = add nuw nsw i32 %14, 5440\l  %627 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %626\l  store float %625, float addrspace(3)* %627, align 4, !tbaa !7\l  %628 = shl i32 %21, 7\l  %629 = add i32 %628, 5504\l  %630 = add i32 %629, %14\l  %631 = zext i32 %630 to i64\l  %632 = getelementptr inbounds float, float addrspace(1)* %0, i64 %631\l  %633 = load float, float addrspace(1)* %632, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %634 = add nuw nsw i32 %14, 5504\l  %635 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %634\l  store float %633, float addrspace(3)* %635, align 4, !tbaa !7\l  %636 = add i32 %28, %629\l  %637 = zext i32 %636 to i64\l  %638 = getelementptr inbounds float, float addrspace(1)* %0, i64 %637\l  %639 = load float, float addrspace(1)* %638, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %640 = add nuw nsw i32 %14, 5568\l  %641 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %640\l  store float %639, float addrspace(3)* %641, align 4, !tbaa !7\l  %642 = shl i32 %21, 7\l  %643 = add i32 %642, 5632\l  %644 = add i32 %643, %14\l  %645 = zext i32 %644 to i64\l  %646 = getelementptr inbounds float, float addrspace(1)* %0, i64 %645\l  %647 = load float, float addrspace(1)* %646, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %648 = add nuw nsw i32 %14, 5632\l  %649 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %648\l  store float %647, float addrspace(3)* %649, align 4, !tbaa !7\l  %650 = add i32 %28, %643\l  %651 = zext i32 %650 to i64\l  %652 = getelementptr inbounds float, float addrspace(1)* %0, i64 %651\l  %653 = load float, float addrspace(1)* %652, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %654 = add nuw nsw i32 %14, 5696\l  %655 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %654\l  store float %653, float addrspace(3)* %655, align 4, !tbaa !7\l  %656 = shl i32 %21, 7\l  %657 = add i32 %656, 5760\l  %658 = add i32 %657, %14\l  %659 = zext i32 %658 to i64\l  %660 = getelementptr inbounds float, float addrspace(1)* %0, i64 %659\l  %661 = load float, float addrspace(1)* %660, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %662 = add nuw nsw i32 %14, 5760\l  %663 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %662\l  store float %661, float addrspace(3)* %663, align 4, !tbaa !7\l  %664 = add i32 %28, %657\l  %665 = zext i32 %664 to i64\l  %666 = getelementptr inbounds float, float addrspace(1)* %0, i64 %665\l  %667 = load float, float addrspace(1)* %666, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %668 = add nuw nsw i32 %14, 5824\l  %669 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %668\l  store float %667, float addrspace(3)* %669, align 4, !tbaa !7\l  %670 = shl i32 %21, 7\l  %671 = add i32 %670, 5888\l  %672 = add i32 %671, %14\l  %673 = zext i32 %672 to i64\l  %674 = getelementptr inbounds float, float addrspace(1)* %0, i64 %673\l  %675 = load float, float addrspace(1)* %674, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %676 = add nuw nsw i32 %14, 5888\l  %677 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %676\l  store float %675, float addrspace(3)* %677, align 4, !tbaa !7\l  %678 = add i32 %28, %671\l  %679 = zext i32 %678 to i64\l  %680 = getelementptr inbounds float, float addrspace(1)* %0, i64 %679\l  %681 = load float, float addrspace(1)* %680, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %682 = add nuw nsw i32 %14, 5952\l  %683 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %682\l  store float %681, float addrspace(3)* %683, align 4, !tbaa !7\l  %684 = shl i32 %21, 7\l  %685 = add i32 %684, 6016\l  %686 = add i32 %685, %14\l  %687 = zext i32 %686 to i64\l  %688 = getelementptr inbounds float, float addrspace(1)* %0, i64 %687\l  %689 = load float, float addrspace(1)* %688, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %690 = add nuw nsw i32 %14, 6016\l  %691 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %690\l  store float %689, float addrspace(3)* %691, align 4, !tbaa !7\l  %692 = add i32 %28, %685\l  %693 = zext i32 %692 to i64\l  %694 = getelementptr inbounds float, float addrspace(1)* %0, i64 %693\l  %695 = load float, float addrspace(1)* %694, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %696 = add nuw nsw i32 %14, 6080\l  %697 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %696\l  store float %695, float addrspace(3)* %697, align 4, !tbaa !7\l  %698 = shl i32 %21, 7\l  %699 = add i32 %698, 6144\l  %700 = add i32 %699, %14\l  %701 = zext i32 %700 to i64\l  %702 = getelementptr inbounds float, float addrspace(1)* %0, i64 %701\l  %703 = load float, float addrspace(1)* %702, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %704 = or i32 %14, 6144\l  %705 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %704\l  store float %703, float addrspace(3)* %705, align 4, !tbaa !7\l  %706 = add i32 %28, %699\l  %707 = zext i32 %706 to i64\l  %708 = getelementptr inbounds float, float addrspace(1)* %0, i64 %707\l  %709 = load float, float addrspace(1)* %708, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %710 = add nuw nsw i32 %14, 6208\l  %711 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %710\l  store float %709, float addrspace(3)* %711, align 4, !tbaa !7\l  %712 = shl i32 %21, 7\l  %713 = add i32 %712, 6272\l  %714 = add i32 %713, %14\l  %715 = zext i32 %714 to i64\l  %716 = getelementptr inbounds float, float addrspace(1)* %0, i64 %715\l  %717 = load float, float addrspace(1)* %716, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %718 = add nuw nsw i32 %14, 6272\l  %719 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %718\l  store float %717, float addrspace(3)* %719, align 4, !tbaa !7\l  %720 = add i32 %28, %713\l  %721 = zext i32 %720 to i64\l  %722 = getelementptr inbounds float, float addrspace(1)* %0, i64 %721\l  %723 = load float, float addrspace(1)* %722, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %724 = add nuw nsw i32 %14, 6336\l  %725 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %724\l  store float %723, float addrspace(3)* %725, align 4, !tbaa !7\l  %726 = shl i32 %21, 7\l  %727 = add i32 %726, 6400\l  %728 = add i32 %727, %14\l  %729 = zext i32 %728 to i64\l  %730 = getelementptr inbounds float, float addrspace(1)* %0, i64 %729\l  %731 = load float, float addrspace(1)* %730, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %732 = add nuw nsw i32 %14, 6400\l  %733 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %732\l  store float %731, float addrspace(3)* %733, align 4, !tbaa !7\l  %734 = add i32 %28, %727\l  %735 = zext i32 %734 to i64\l  %736 = getelementptr inbounds float, float addrspace(1)* %0, i64 %735\l  %737 = load float, float addrspace(1)* %736, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %738 = add nuw nsw i32 %14, 6464\l  %739 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %738\l  store float %737, float addrspace(3)* %739, align 4, !tbaa !7\l  %740 = shl i32 %21, 7\l  %741 = add i32 %740, 6528\l  %742 = add i32 %741, %14\l  %743 = zext i32 %742 to i64\l  %744 = getelementptr inbounds float, float addrspace(1)* %0, i64 %743\l  %745 = load float, float addrspace(1)* %744, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %746 = add nuw nsw i32 %14, 6528\l  %747 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %746\l  store float %745, float addrspace(3)* %747, align 4, !tbaa !7\l  %748 = add i32 %28, %741\l  %749 = zext i32 %748 to i64\l  %750 = getelementptr inbounds float, float addrspace(1)* %0, i64 %749\l  %751 = load float, float addrspace(1)* %750, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %752 = add nuw nsw i32 %14, 6592\l  %753 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %752\l  store float %751, float addrspace(3)* %753, align 4, !tbaa !7\l  %754 = shl i32 %21, 7\l  %755 = add i32 %754, 6656\l  %756 = add i32 %755, %14\l  %757 = zext i32 %756 to i64\l  %758 = getelementptr inbounds float, float addrspace(1)* %0, i64 %757\l  %759 = load float, float addrspace(1)* %758, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %760 = add nuw nsw i32 %14, 6656\l  %761 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %760\l  store float %759, float addrspace(3)* %761, align 4, !tbaa !7\l  %762 = add i32 %28, %755\l  %763 = zext i32 %762 to i64\l  %764 = getelementptr inbounds float, float addrspace(1)* %0, i64 %763\l  %765 = load float, float addrspace(1)* %764, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %766 = add nuw nsw i32 %14, 6720\l  %767 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %766\l  store float %765, float addrspace(3)* %767, align 4, !tbaa !7\l  %768 = shl i32 %21, 7\l  %769 = add i32 %768, 6784\l  %770 = add i32 %769, %14\l  %771 = zext i32 %770 to i64\l  %772 = getelementptr inbounds float, float addrspace(1)* %0, i64 %771\l  %773 = load float, float addrspace(1)* %772, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %774 = add nuw nsw i32 %14, 6784\l  %775 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %774\l  store float %773, float addrspace(3)* %775, align 4, !tbaa !7\l  %776 = add i32 %28, %769\l  %777 = zext i32 %776 to i64\l  %778 = getelementptr inbounds float, float addrspace(1)* %0, i64 %777\l  %779 = load float, float addrspace(1)* %778, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %780 = add nuw nsw i32 %14, 6848\l  %781 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %780\l  store float %779, float addrspace(3)* %781, align 4, !tbaa !7\l  %782 = shl i32 %21, 7\l  %783 = add i32 %782, 6912\l  %784 = add i32 %783, %14\l  %785 = zext i32 %784 to i64\l  %786 = getelementptr inbounds float, float addrspace(1)* %0, i64 %785\l  %787 = load float, float addrspace(1)* %786, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %788 = add nuw nsw i32 %14, 6912\l  %789 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %788\l  store float %787, float addrspace(3)* %789, align 4, !tbaa !7\l  %790 = add i32 %28, %783\l  %791 = zext i32 %790 to i64\l  %792 = getelementptr inbounds float, float addrspace(1)* %0, i64 %791\l  %793 = load float, float addrspace(1)* %792, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %794 = add nuw nsw i32 %14, 6976\l  %795 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %794\l  store float %793, float addrspace(3)* %795, align 4, !tbaa !7\l  %796 = shl i32 %21, 7\l  %797 = add i32 %796, 7040\l  %798 = add i32 %797, %14\l  %799 = zext i32 %798 to i64\l  %800 = getelementptr inbounds float, float addrspace(1)* %0, i64 %799\l  %801 = load float, float addrspace(1)* %800, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %802 = add nuw nsw i32 %14, 7040\l  %803 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %802\l  store float %801, float addrspace(3)* %803, align 4, !tbaa !7\l  %804 = add i32 %28, %797\l  %805 = zext i32 %804 to i64\l  %806 = getelementptr inbounds float, float addrspace(1)* %0, i64 %805\l  %807 = load float, float addrspace(1)* %806, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %808 = add nuw nsw i32 %14, 7104\l  %809 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %808\l  store float %807, float addrspace(3)* %809, align 4, !tbaa !7\l  %810 = shl i32 %21, 7\l  %811 = add i32 %810, 7168\l  %812 = add i32 %811, %14\l  %813 = zext i32 %812 to i64\l  %814 = getelementptr inbounds float, float addrspace(1)* %0, i64 %813\l  %815 = load float, float addrspace(1)* %814, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %816 = or i32 %14, 7168\l  %817 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %816\l  store float %815, float addrspace(3)* %817, align 4, !tbaa !7\l  %818 = add i32 %28, %811\l  %819 = zext i32 %818 to i64\l  %820 = getelementptr inbounds float, float addrspace(1)* %0, i64 %819\l  %821 = load float, float addrspace(1)* %820, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %822 = add nuw nsw i32 %14, 7232\l  %823 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %822\l  store float %821, float addrspace(3)* %823, align 4, !tbaa !7\l  %824 = shl i32 %21, 7\l  %825 = add i32 %824, 7296\l  %826 = add i32 %825, %14\l  %827 = zext i32 %826 to i64\l  %828 = getelementptr inbounds float, float addrspace(1)* %0, i64 %827\l  %829 = load float, float addrspace(1)* %828, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %830 = add nuw nsw i32 %14, 7296\l  %831 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %830\l  store float %829, float addrspace(3)* %831, align 4, !tbaa !7\l  %832 = add i32 %28, %825\l  %833 = zext i32 %832 to i64\l  %834 = getelementptr inbounds float, float addrspace(1)* %0, i64 %833\l  %835 = load float, float addrspace(1)* %834, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %836 = add nuw nsw i32 %14, 7360\l  %837 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %836\l  store float %835, float addrspace(3)* %837, align 4, !tbaa !7\l  %838 = shl i32 %21, 7\l  %839 = add i32 %838, 7424\l  %840 = add i32 %839, %14\l  %841 = zext i32 %840 to i64\l  %842 = getelementptr inbounds float, float addrspace(1)* %0, i64 %841\l  %843 = load float, float addrspace(1)* %842, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %844 = add nuw nsw i32 %14, 7424\l  %845 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %844\l  store float %843, float addrspace(3)* %845, align 4, !tbaa !7\l  %846 = add i32 %28, %839\l  %847 = zext i32 %846 to i64\l  %848 = getelementptr inbounds float, float addrspace(1)* %0, i64 %847\l  %849 = load float, float addrspace(1)* %848, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %850 = add nuw nsw i32 %14, 7488\l  %851 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %850\l  store float %849, float addrspace(3)* %851, align 4, !tbaa !7\l  %852 = shl i32 %21, 7\l  %853 = add i32 %852, 7552\l  %854 = add i32 %853, %14\l  %855 = zext i32 %854 to i64\l  %856 = getelementptr inbounds float, float addrspace(1)* %0, i64 %855\l  %857 = load float, float addrspace(1)* %856, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %858 = add nuw nsw i32 %14, 7552\l  %859 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %858\l  store float %857, float addrspace(3)* %859, align 4, !tbaa !7\l  %860 = add i32 %28, %853\l  %861 = zext i32 %860 to i64\l  %862 = getelementptr inbounds float, float addrspace(1)* %0, i64 %861\l  %863 = load float, float addrspace(1)* %862, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %864 = add nuw nsw i32 %14, 7616\l  %865 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %864\l  store float %863, float addrspace(3)* %865, align 4, !tbaa !7\l  %866 = shl i32 %21, 7\l  %867 = add i32 %866, 7680\l  %868 = add i32 %867, %14\l  %869 = zext i32 %868 to i64\l  %870 = getelementptr inbounds float, float addrspace(1)* %0, i64 %869\l  %871 = load float, float addrspace(1)* %870, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %872 = add nuw nsw i32 %14, 7680\l  %873 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %872\l  store float %871, float addrspace(3)* %873, align 4, !tbaa !7\l  %874 = add i32 %28, %867\l  %875 = zext i32 %874 to i64\l  %876 = getelementptr inbounds float, float addrspace(1)* %0, i64 %875\l  %877 = load float, float addrspace(1)* %876, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %878 = add nuw nsw i32 %14, 7744\l  %879 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %878\l  store float %877, float addrspace(3)* %879, align 4, !tbaa !7\l  %880 = shl i32 %21, 7\l  %881 = add i32 %880, 7808\l  %882 = add i32 %881, %14\l  %883 = zext i32 %882 to i64\l  %884 = getelementptr inbounds float, float addrspace(1)* %0, i64 %883\l  %885 = load float, float addrspace(1)* %884, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %886 = add nuw nsw i32 %14, 7808\l  %887 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %886\l  store float %885, float addrspace(3)* %887, align 4, !tbaa !7\l  %888 = add i32 %28, %881\l  %889 = zext i32 %888 to i64\l  %890 = getelementptr inbounds float, float addrspace(1)* %0, i64 %889\l  %891 = load float, float addrspace(1)* %890, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %892 = add nuw nsw i32 %14, 7872\l  %893 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %892\l  store float %891, float addrspace(3)* %893, align 4, !tbaa !7\l  %894 = shl i32 %21, 7\l  %895 = add i32 %894, 7936\l  %896 = add i32 %895, %14\l  %897 = zext i32 %896 to i64\l  %898 = getelementptr inbounds float, float addrspace(1)* %0, i64 %897\l  %899 = load float, float addrspace(1)* %898, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %900 = add nuw nsw i32 %14, 7936\l  %901 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %900\l  store float %899, float addrspace(3)* %901, align 4, !tbaa !7\l  %902 = add i32 %28, %895\l  %903 = zext i32 %902 to i64\l  %904 = getelementptr inbounds float, float addrspace(1)* %0, i64 %903\l  %905 = load float, float addrspace(1)* %904, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %906 = add nuw nsw i32 %14, 8000\l  %907 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %906\l  store float %905, float addrspace(3)* %907, align 4, !tbaa !7\l  %908 = shl i32 %21, 7\l  %909 = add i32 %908, 8064\l  %910 = add i32 %909, %14\l  %911 = zext i32 %910 to i64\l  %912 = getelementptr inbounds float, float addrspace(1)* %0, i64 %911\l  %913 = load float, float addrspace(1)* %912, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %914 = add nuw nsw i32 %14, 8064\l  %915 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %914\l  store float %913, float addrspace(3)* %915, align 4, !tbaa !7\l  %916 = add i32 %28, %909\l  %917 = zext i32 %916 to i64\l  %918 = getelementptr inbounds float, float addrspace(1)* %0, i64 %917\l  %919 = load float, float addrspace(1)* %918, align 4, !tbaa !7,\l... !amdgpu.noclobber !6\l  %920 = add nuw nsw i32 %14, 8128\l  %921 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %920\l  store float %919, float addrspace(3)* %921, align 4, !tbaa !7\l  %922 = icmp eq i32 %11, 0\l  br i1 %922, label %1187, label %923\l|{<s0>T|<s1>F}}"];
	Node0x4a59a90:s0 -> Node0x4a90680;
	Node0x4a59a90:s1 -> Node0x4a90710;
	Node0x4a90710 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#c7d7f070",label="{%923:\l923:                                              \l  %924 = getelementptr inbounds [128 x float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 %14\l  %925 = getelementptr inbounds [128 x float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 %28\l  %926 = icmp ult i32 %22, %10\l  %927 = shl nuw nsw i32 %14, 7\l  %928 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %927\l  %929 = add nuw nsw i32 %927, 1\l  %930 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %929\l  %931 = add nuw nsw i32 %927, 2\l  %932 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %931\l  %933 = add nuw nsw i32 %927, 3\l  %934 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %933\l  %935 = add nuw nsw i32 %927, 4\l  %936 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %935\l  %937 = add nuw nsw i32 %927, 5\l  %938 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %937\l  %939 = add nuw nsw i32 %927, 6\l  %940 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %939\l  %941 = add nuw nsw i32 %927, 7\l  %942 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %941\l  %943 = add nuw nsw i32 %927, 8\l  %944 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %943\l  %945 = add nuw nsw i32 %927, 9\l  %946 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %945\l  %947 = add nuw nsw i32 %927, 10\l  %948 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %947\l  %949 = add nuw nsw i32 %927, 11\l  %950 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %949\l  %951 = add nuw nsw i32 %927, 12\l  %952 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %951\l  %953 = add nuw nsw i32 %927, 13\l  %954 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %953\l  %955 = add nuw nsw i32 %927, 14\l  %956 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %955\l  %957 = add nuw nsw i32 %927, 15\l  %958 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %957\l  %959 = add nuw nsw i32 %927, 16\l  %960 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %959\l  %961 = add nuw nsw i32 %927, 17\l  %962 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %961\l  %963 = add nuw nsw i32 %927, 18\l  %964 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %963\l  %965 = add nuw nsw i32 %927, 19\l  %966 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %965\l  %967 = add nuw nsw i32 %927, 20\l  %968 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %967\l  %969 = add nuw nsw i32 %927, 21\l  %970 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %969\l  %971 = add nuw nsw i32 %927, 22\l  %972 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %971\l  %973 = add nuw nsw i32 %927, 23\l  %974 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %973\l  %975 = add nuw nsw i32 %927, 24\l  %976 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %975\l  %977 = add nuw nsw i32 %927, 25\l  %978 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %977\l  %979 = add nuw nsw i32 %927, 26\l  %980 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %979\l  %981 = add nuw nsw i32 %927, 27\l  %982 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %981\l  %983 = add nuw nsw i32 %927, 28\l  %984 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %983\l  %985 = add nuw nsw i32 %927, 29\l  %986 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %985\l  %987 = add nuw nsw i32 %927, 30\l  %988 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %987\l  %989 = add nuw nsw i32 %927, 31\l  %990 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %989\l  %991 = add nuw nsw i32 %927, 32\l  %992 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %991\l  %993 = add nuw nsw i32 %927, 33\l  %994 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %993\l  %995 = add nuw nsw i32 %927, 34\l  %996 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %995\l  %997 = add nuw nsw i32 %927, 35\l  %998 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %997\l  %999 = add nuw nsw i32 %927, 36\l  %1000 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %999\l  %1001 = add nuw nsw i32 %927, 37\l  %1002 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1001\l  %1003 = add nuw nsw i32 %927, 38\l  %1004 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1003\l  %1005 = add nuw nsw i32 %927, 39\l  %1006 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1005\l  %1007 = add nuw nsw i32 %927, 40\l  %1008 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1007\l  %1009 = add nuw nsw i32 %927, 41\l  %1010 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1009\l  %1011 = add nuw nsw i32 %927, 42\l  %1012 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1011\l  %1013 = add nuw nsw i32 %927, 43\l  %1014 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1013\l  %1015 = add nuw nsw i32 %927, 44\l  %1016 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1015\l  %1017 = add nuw nsw i32 %927, 45\l  %1018 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1017\l  %1019 = add nuw nsw i32 %927, 46\l  %1020 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1019\l  %1021 = add nuw nsw i32 %927, 47\l  %1022 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1021\l  %1023 = add nuw nsw i32 %927, 48\l  %1024 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1023\l  %1025 = add nuw nsw i32 %927, 49\l  %1026 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1025\l  %1027 = add nuw nsw i32 %927, 50\l  %1028 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1027\l  %1029 = add nuw nsw i32 %927, 51\l  %1030 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1029\l  %1031 = add nuw nsw i32 %927, 52\l  %1032 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1031\l  %1033 = add nuw nsw i32 %927, 53\l  %1034 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1033\l  %1035 = add nuw nsw i32 %927, 54\l  %1036 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1035\l  %1037 = add nuw nsw i32 %927, 55\l  %1038 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1037\l  %1039 = add nuw nsw i32 %927, 56\l  %1040 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1039\l  %1041 = add nuw nsw i32 %927, 57\l  %1042 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1041\l  %1043 = add nuw nsw i32 %927, 58\l  %1044 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1043\l  %1045 = add nuw nsw i32 %927, 59\l  %1046 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1045\l  %1047 = add nuw nsw i32 %927, 60\l  %1048 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1047\l  %1049 = add nuw nsw i32 %927, 61\l  %1050 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1049\l  %1051 = add nuw nsw i32 %927, 62\l  %1052 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1051\l  %1053 = add nuw nsw i32 %927, 63\l  %1054 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1053\l  %1055 = add nuw nsw i32 %927, 64\l  %1056 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1055\l  %1057 = add nuw nsw i32 %927, 65\l  %1058 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1057\l  %1059 = add nuw nsw i32 %927, 66\l  %1060 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1059\l  %1061 = add nuw nsw i32 %927, 67\l  %1062 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1061\l  %1063 = add nuw nsw i32 %927, 68\l  %1064 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1063\l  %1065 = add nuw nsw i32 %927, 69\l  %1066 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1065\l  %1067 = add nuw nsw i32 %927, 70\l  %1068 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1067\l  %1069 = add nuw nsw i32 %927, 71\l  %1070 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1069\l  %1071 = add nuw nsw i32 %927, 72\l  %1072 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1071\l  %1073 = add nuw nsw i32 %927, 73\l  %1074 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1073\l  %1075 = add nuw nsw i32 %927, 74\l  %1076 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1075\l  %1077 = add nuw nsw i32 %927, 75\l  %1078 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1077\l  %1079 = add nuw nsw i32 %927, 76\l  %1080 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1079\l  %1081 = add nuw nsw i32 %927, 77\l  %1082 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1081\l  %1083 = add nuw nsw i32 %927, 78\l  %1084 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1083\l  %1085 = add nuw nsw i32 %927, 79\l  %1086 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1085\l  %1087 = add nuw nsw i32 %927, 80\l  %1088 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1087\l  %1089 = add nuw nsw i32 %927, 81\l  %1090 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1089\l  %1091 = add nuw nsw i32 %927, 82\l  %1092 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1091\l  %1093 = add nuw nsw i32 %927, 83\l  %1094 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1093\l  %1095 = add nuw nsw i32 %927, 84\l  %1096 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1095\l  %1097 = add nuw nsw i32 %927, 85\l  %1098 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1097\l  %1099 = add nuw nsw i32 %927, 86\l  %1100 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1099\l  %1101 = add nuw nsw i32 %927, 87\l  %1102 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1101\l  %1103 = add nuw nsw i32 %927, 88\l  %1104 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1103\l  %1105 = add nuw nsw i32 %927, 89\l  %1106 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1105\l  %1107 = add nuw nsw i32 %927, 90\l  %1108 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1107\l  %1109 = add nuw nsw i32 %927, 91\l  %1110 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1109\l  %1111 = add nuw nsw i32 %927, 92\l  %1112 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1111\l  %1113 = add nuw nsw i32 %927, 93\l  %1114 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1113\l  %1115 = add nuw nsw i32 %927, 94\l  %1116 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1115\l  %1117 = add nuw nsw i32 %927, 95\l  %1118 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1117\l  %1119 = add nuw nsw i32 %927, 96\l  %1120 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1119\l  %1121 = add nuw nsw i32 %927, 97\l  %1122 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1121\l  %1123 = add nuw nsw i32 %927, 98\l  %1124 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1123\l  %1125 = add nuw nsw i32 %927, 99\l  %1126 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1125\l  %1127 = add nuw nsw i32 %927, 100\l  %1128 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1127\l  %1129 = add nuw nsw i32 %927, 101\l  %1130 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1129\l  %1131 = add nuw nsw i32 %927, 102\l  %1132 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1131\l  %1133 = add nuw nsw i32 %927, 103\l  %1134 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1133\l  %1135 = add nuw nsw i32 %927, 104\l  %1136 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1135\l  %1137 = add nuw nsw i32 %927, 105\l  %1138 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1137\l  %1139 = add nuw nsw i32 %927, 106\l  %1140 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1139\l  %1141 = add nuw nsw i32 %927, 107\l  %1142 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1141\l  %1143 = add nuw nsw i32 %927, 108\l  %1144 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1143\l  %1145 = add nuw nsw i32 %927, 109\l  %1146 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1145\l  %1147 = add nuw nsw i32 %927, 110\l  %1148 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1147\l  %1149 = add nuw nsw i32 %927, 111\l  %1150 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1149\l  %1151 = add nuw nsw i32 %927, 112\l  %1152 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1151\l  %1153 = add nuw nsw i32 %927, 113\l  %1154 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1153\l  %1155 = add nuw nsw i32 %927, 114\l  %1156 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1155\l  %1157 = add nuw nsw i32 %927, 115\l  %1158 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1157\l  %1159 = add nuw nsw i32 %927, 116\l  %1160 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1159\l  %1161 = add nuw nsw i32 %927, 117\l  %1162 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1161\l  %1163 = add nuw nsw i32 %927, 118\l  %1164 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1163\l  %1165 = add nuw nsw i32 %927, 119\l  %1166 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1165\l  %1167 = add nuw nsw i32 %927, 120\l  %1168 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1167\l  %1169 = add nuw nsw i32 %927, 121\l  %1170 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1169\l  %1171 = add nuw nsw i32 %927, 122\l  %1172 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1171\l  %1173 = add nuw nsw i32 %927, 123\l  %1174 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1173\l  %1175 = add nuw nsw i32 %927, 124\l  %1176 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1175\l  %1177 = add nuw nsw i32 %927, 125\l  %1178 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1177\l  %1179 = add nuw nsw i32 %927, 126\l  %1180 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1179\l  %1181 = add nuw nsw i32 %927, 127\l  %1182 = getelementptr inbounds [8192 x float], [8192 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5hists, i32 0, i32 %1181\l  br label %1183\l}"];
	Node0x4a90710 -> Node0x4aa0180;
	Node0x4aa0180 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%1183:\l1183:                                             \l  %1184 = phi i32 [ 0, %923 ], [ %1858, %1857 ]\l  %1185 = load i32, i32 addrspace(1)* %9, align 4, !tbaa !11\l  %1186 = icmp slt i32 %1185, %12\l  br i1 %1186, label %1188, label %1187\l|{<s0>T|<s1>F}}"];
	Node0x4aa0180:s0 -> Node0x4aa0aa0;
	Node0x4aa0180:s1 -> Node0x4a90680;
	Node0x4a90680 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#e3d9d370",label="{%1187:\l1187:                                             \l  ret void\l}"];
	Node0x4aa0aa0 [shape=record,color="#b70d28ff", style=filled, fillcolor="#bb1b2c70",label="{%1188:\l1188:                                             \l  %1189 = shl i32 %1184, 7\l  %1190 = add i32 %1189, %14\l  %1191 = zext i32 %1190 to i64\l  %1192 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1191\l  %1193 = load float, float addrspace(1)* %1192, align 4, !tbaa !7\l  store float %1193, float addrspace(3)* %924, align 4, !tbaa !7\l  %1194 = add i32 %1190, 64\l  %1195 = zext i32 %1194 to i64\l  %1196 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1195\l  %1197 = load float, float addrspace(1)* %1196, align 4, !tbaa !7\l  store float %1197, float addrspace(3)* %925, align 4, !tbaa !7\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  br i1 %926, label %1198, label %1857\l|{<s0>T|<s1>F}}"];
	Node0x4aa0aa0:s0 -> Node0x4a76370;
	Node0x4aa0aa0:s1 -> Node0x4aa02b0;
	Node0x4a76370 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#e5705870",label="{%1198:\l1198:                                             \l  %1199 = load float, float addrspace(3)* %928, align 16, !tbaa !7\l  %1200 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 0),\l... align 16, !tbaa !7\l  %1201 = fsub contract float %1199, %1200\l  %1202 = tail call float @llvm.fabs.f32(float %1201)\l  %1203 = load float, float addrspace(3)* %930, align 4, !tbaa !7\l  %1204 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 1),\l... align 4, !tbaa !7\l  %1205 = fsub contract float %1203, %1204\l  %1206 = tail call float @llvm.fabs.f32(float %1205)\l  %1207 = fadd contract float %1202, %1206\l  %1208 = load float, float addrspace(3)* %932, align 8, !tbaa !7\l  %1209 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 2),\l... align 8, !tbaa !7\l  %1210 = fsub contract float %1208, %1209\l  %1211 = tail call float @llvm.fabs.f32(float %1210)\l  %1212 = fadd contract float %1207, %1211\l  %1213 = load float, float addrspace(3)* %934, align 4, !tbaa !7\l  %1214 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 3),\l... align 4, !tbaa !7\l  %1215 = fsub contract float %1213, %1214\l  %1216 = tail call float @llvm.fabs.f32(float %1215)\l  %1217 = fadd contract float %1212, %1216\l  %1218 = load float, float addrspace(3)* %936, align 16, !tbaa !7\l  %1219 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 4),\l... align 16, !tbaa !7\l  %1220 = fsub contract float %1218, %1219\l  %1221 = tail call float @llvm.fabs.f32(float %1220)\l  %1222 = fadd contract float %1217, %1221\l  %1223 = load float, float addrspace(3)* %938, align 4, !tbaa !7\l  %1224 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 5),\l... align 4, !tbaa !7\l  %1225 = fsub contract float %1223, %1224\l  %1226 = tail call float @llvm.fabs.f32(float %1225)\l  %1227 = fadd contract float %1222, %1226\l  %1228 = load float, float addrspace(3)* %940, align 8, !tbaa !7\l  %1229 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 6),\l... align 8, !tbaa !7\l  %1230 = fsub contract float %1228, %1229\l  %1231 = tail call float @llvm.fabs.f32(float %1230)\l  %1232 = fadd contract float %1227, %1231\l  %1233 = load float, float addrspace(3)* %942, align 4, !tbaa !7\l  %1234 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 7),\l... align 4, !tbaa !7\l  %1235 = fsub contract float %1233, %1234\l  %1236 = tail call float @llvm.fabs.f32(float %1235)\l  %1237 = fadd contract float %1232, %1236\l  %1238 = load float, float addrspace(3)* %944, align 16, !tbaa !7\l  %1239 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 8),\l... align 16, !tbaa !7\l  %1240 = fsub contract float %1238, %1239\l  %1241 = tail call float @llvm.fabs.f32(float %1240)\l  %1242 = fadd contract float %1237, %1241\l  %1243 = load float, float addrspace(3)* %946, align 4, !tbaa !7\l  %1244 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 9),\l... align 4, !tbaa !7\l  %1245 = fsub contract float %1243, %1244\l  %1246 = tail call float @llvm.fabs.f32(float %1245)\l  %1247 = fadd contract float %1242, %1246\l  %1248 = load float, float addrspace(3)* %948, align 8, !tbaa !7\l  %1249 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 10),\l... align 8, !tbaa !7\l  %1250 = fsub contract float %1248, %1249\l  %1251 = tail call float @llvm.fabs.f32(float %1250)\l  %1252 = fadd contract float %1247, %1251\l  %1253 = load float, float addrspace(3)* %950, align 4, !tbaa !7\l  %1254 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 11),\l... align 4, !tbaa !7\l  %1255 = fsub contract float %1253, %1254\l  %1256 = tail call float @llvm.fabs.f32(float %1255)\l  %1257 = fadd contract float %1252, %1256\l  %1258 = load float, float addrspace(3)* %952, align 16, !tbaa !7\l  %1259 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 12),\l... align 16, !tbaa !7\l  %1260 = fsub contract float %1258, %1259\l  %1261 = tail call float @llvm.fabs.f32(float %1260)\l  %1262 = fadd contract float %1257, %1261\l  %1263 = load float, float addrspace(3)* %954, align 4, !tbaa !7\l  %1264 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 13),\l... align 4, !tbaa !7\l  %1265 = fsub contract float %1263, %1264\l  %1266 = tail call float @llvm.fabs.f32(float %1265)\l  %1267 = fadd contract float %1262, %1266\l  %1268 = load float, float addrspace(3)* %956, align 8, !tbaa !7\l  %1269 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 14),\l... align 8, !tbaa !7\l  %1270 = fsub contract float %1268, %1269\l  %1271 = tail call float @llvm.fabs.f32(float %1270)\l  %1272 = fadd contract float %1267, %1271\l  %1273 = load float, float addrspace(3)* %958, align 4, !tbaa !7\l  %1274 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 15),\l... align 4, !tbaa !7\l  %1275 = fsub contract float %1273, %1274\l  %1276 = tail call float @llvm.fabs.f32(float %1275)\l  %1277 = fadd contract float %1272, %1276\l  %1278 = load float, float addrspace(3)* %960, align 16, !tbaa !7\l  %1279 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 16),\l... align 16, !tbaa !7\l  %1280 = fsub contract float %1278, %1279\l  %1281 = tail call float @llvm.fabs.f32(float %1280)\l  %1282 = fadd contract float %1277, %1281\l  %1283 = load float, float addrspace(3)* %962, align 4, !tbaa !7\l  %1284 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 17),\l... align 4, !tbaa !7\l  %1285 = fsub contract float %1283, %1284\l  %1286 = tail call float @llvm.fabs.f32(float %1285)\l  %1287 = fadd contract float %1282, %1286\l  %1288 = load float, float addrspace(3)* %964, align 8, !tbaa !7\l  %1289 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 18),\l... align 8, !tbaa !7\l  %1290 = fsub contract float %1288, %1289\l  %1291 = tail call float @llvm.fabs.f32(float %1290)\l  %1292 = fadd contract float %1287, %1291\l  %1293 = load float, float addrspace(3)* %966, align 4, !tbaa !7\l  %1294 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 19),\l... align 4, !tbaa !7\l  %1295 = fsub contract float %1293, %1294\l  %1296 = tail call float @llvm.fabs.f32(float %1295)\l  %1297 = fadd contract float %1292, %1296\l  %1298 = load float, float addrspace(3)* %968, align 16, !tbaa !7\l  %1299 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 20),\l... align 16, !tbaa !7\l  %1300 = fsub contract float %1298, %1299\l  %1301 = tail call float @llvm.fabs.f32(float %1300)\l  %1302 = fadd contract float %1297, %1301\l  %1303 = load float, float addrspace(3)* %970, align 4, !tbaa !7\l  %1304 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 21),\l... align 4, !tbaa !7\l  %1305 = fsub contract float %1303, %1304\l  %1306 = tail call float @llvm.fabs.f32(float %1305)\l  %1307 = fadd contract float %1302, %1306\l  %1308 = load float, float addrspace(3)* %972, align 8, !tbaa !7\l  %1309 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 22),\l... align 8, !tbaa !7\l  %1310 = fsub contract float %1308, %1309\l  %1311 = tail call float @llvm.fabs.f32(float %1310)\l  %1312 = fadd contract float %1307, %1311\l  %1313 = load float, float addrspace(3)* %974, align 4, !tbaa !7\l  %1314 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 23),\l... align 4, !tbaa !7\l  %1315 = fsub contract float %1313, %1314\l  %1316 = tail call float @llvm.fabs.f32(float %1315)\l  %1317 = fadd contract float %1312, %1316\l  %1318 = load float, float addrspace(3)* %976, align 16, !tbaa !7\l  %1319 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 24),\l... align 16, !tbaa !7\l  %1320 = fsub contract float %1318, %1319\l  %1321 = tail call float @llvm.fabs.f32(float %1320)\l  %1322 = fadd contract float %1317, %1321\l  %1323 = load float, float addrspace(3)* %978, align 4, !tbaa !7\l  %1324 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 25),\l... align 4, !tbaa !7\l  %1325 = fsub contract float %1323, %1324\l  %1326 = tail call float @llvm.fabs.f32(float %1325)\l  %1327 = fadd contract float %1322, %1326\l  %1328 = load float, float addrspace(3)* %980, align 8, !tbaa !7\l  %1329 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 26),\l... align 8, !tbaa !7\l  %1330 = fsub contract float %1328, %1329\l  %1331 = tail call float @llvm.fabs.f32(float %1330)\l  %1332 = fadd contract float %1327, %1331\l  %1333 = load float, float addrspace(3)* %982, align 4, !tbaa !7\l  %1334 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 27),\l... align 4, !tbaa !7\l  %1335 = fsub contract float %1333, %1334\l  %1336 = tail call float @llvm.fabs.f32(float %1335)\l  %1337 = fadd contract float %1332, %1336\l  %1338 = load float, float addrspace(3)* %984, align 16, !tbaa !7\l  %1339 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 28),\l... align 16, !tbaa !7\l  %1340 = fsub contract float %1338, %1339\l  %1341 = tail call float @llvm.fabs.f32(float %1340)\l  %1342 = fadd contract float %1337, %1341\l  %1343 = load float, float addrspace(3)* %986, align 4, !tbaa !7\l  %1344 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 29),\l... align 4, !tbaa !7\l  %1345 = fsub contract float %1343, %1344\l  %1346 = tail call float @llvm.fabs.f32(float %1345)\l  %1347 = fadd contract float %1342, %1346\l  %1348 = load float, float addrspace(3)* %988, align 8, !tbaa !7\l  %1349 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 30),\l... align 8, !tbaa !7\l  %1350 = fsub contract float %1348, %1349\l  %1351 = tail call float @llvm.fabs.f32(float %1350)\l  %1352 = fadd contract float %1347, %1351\l  %1353 = load float, float addrspace(3)* %990, align 4, !tbaa !7\l  %1354 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 31),\l... align 4, !tbaa !7\l  %1355 = fsub contract float %1353, %1354\l  %1356 = tail call float @llvm.fabs.f32(float %1355)\l  %1357 = fadd contract float %1352, %1356\l  %1358 = load float, float addrspace(3)* %992, align 16, !tbaa !7\l  %1359 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 32),\l... align 16, !tbaa !7\l  %1360 = fsub contract float %1358, %1359\l  %1361 = tail call float @llvm.fabs.f32(float %1360)\l  %1362 = fadd contract float %1357, %1361\l  %1363 = load float, float addrspace(3)* %994, align 4, !tbaa !7\l  %1364 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 33),\l... align 4, !tbaa !7\l  %1365 = fsub contract float %1363, %1364\l  %1366 = tail call float @llvm.fabs.f32(float %1365)\l  %1367 = fadd contract float %1362, %1366\l  %1368 = load float, float addrspace(3)* %996, align 8, !tbaa !7\l  %1369 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 34),\l... align 8, !tbaa !7\l  %1370 = fsub contract float %1368, %1369\l  %1371 = tail call float @llvm.fabs.f32(float %1370)\l  %1372 = fadd contract float %1367, %1371\l  %1373 = load float, float addrspace(3)* %998, align 4, !tbaa !7\l  %1374 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 35),\l... align 4, !tbaa !7\l  %1375 = fsub contract float %1373, %1374\l  %1376 = tail call float @llvm.fabs.f32(float %1375)\l  %1377 = fadd contract float %1372, %1376\l  %1378 = load float, float addrspace(3)* %1000, align 16, !tbaa !7\l  %1379 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 36),\l... align 16, !tbaa !7\l  %1380 = fsub contract float %1378, %1379\l  %1381 = tail call float @llvm.fabs.f32(float %1380)\l  %1382 = fadd contract float %1377, %1381\l  %1383 = load float, float addrspace(3)* %1002, align 4, !tbaa !7\l  %1384 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 37),\l... align 4, !tbaa !7\l  %1385 = fsub contract float %1383, %1384\l  %1386 = tail call float @llvm.fabs.f32(float %1385)\l  %1387 = fadd contract float %1382, %1386\l  %1388 = load float, float addrspace(3)* %1004, align 8, !tbaa !7\l  %1389 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 38),\l... align 8, !tbaa !7\l  %1390 = fsub contract float %1388, %1389\l  %1391 = tail call float @llvm.fabs.f32(float %1390)\l  %1392 = fadd contract float %1387, %1391\l  %1393 = load float, float addrspace(3)* %1006, align 4, !tbaa !7\l  %1394 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 39),\l... align 4, !tbaa !7\l  %1395 = fsub contract float %1393, %1394\l  %1396 = tail call float @llvm.fabs.f32(float %1395)\l  %1397 = fadd contract float %1392, %1396\l  %1398 = load float, float addrspace(3)* %1008, align 16, !tbaa !7\l  %1399 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 40),\l... align 16, !tbaa !7\l  %1400 = fsub contract float %1398, %1399\l  %1401 = tail call float @llvm.fabs.f32(float %1400)\l  %1402 = fadd contract float %1397, %1401\l  %1403 = load float, float addrspace(3)* %1010, align 4, !tbaa !7\l  %1404 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 41),\l... align 4, !tbaa !7\l  %1405 = fsub contract float %1403, %1404\l  %1406 = tail call float @llvm.fabs.f32(float %1405)\l  %1407 = fadd contract float %1402, %1406\l  %1408 = load float, float addrspace(3)* %1012, align 8, !tbaa !7\l  %1409 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 42),\l... align 8, !tbaa !7\l  %1410 = fsub contract float %1408, %1409\l  %1411 = tail call float @llvm.fabs.f32(float %1410)\l  %1412 = fadd contract float %1407, %1411\l  %1413 = load float, float addrspace(3)* %1014, align 4, !tbaa !7\l  %1414 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 43),\l... align 4, !tbaa !7\l  %1415 = fsub contract float %1413, %1414\l  %1416 = tail call float @llvm.fabs.f32(float %1415)\l  %1417 = fadd contract float %1412, %1416\l  %1418 = load float, float addrspace(3)* %1016, align 16, !tbaa !7\l  %1419 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 44),\l... align 16, !tbaa !7\l  %1420 = fsub contract float %1418, %1419\l  %1421 = tail call float @llvm.fabs.f32(float %1420)\l  %1422 = fadd contract float %1417, %1421\l  %1423 = load float, float addrspace(3)* %1018, align 4, !tbaa !7\l  %1424 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 45),\l... align 4, !tbaa !7\l  %1425 = fsub contract float %1423, %1424\l  %1426 = tail call float @llvm.fabs.f32(float %1425)\l  %1427 = fadd contract float %1422, %1426\l  %1428 = load float, float addrspace(3)* %1020, align 8, !tbaa !7\l  %1429 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 46),\l... align 8, !tbaa !7\l  %1430 = fsub contract float %1428, %1429\l  %1431 = tail call float @llvm.fabs.f32(float %1430)\l  %1432 = fadd contract float %1427, %1431\l  %1433 = load float, float addrspace(3)* %1022, align 4, !tbaa !7\l  %1434 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 47),\l... align 4, !tbaa !7\l  %1435 = fsub contract float %1433, %1434\l  %1436 = tail call float @llvm.fabs.f32(float %1435)\l  %1437 = fadd contract float %1432, %1436\l  %1438 = load float, float addrspace(3)* %1024, align 16, !tbaa !7\l  %1439 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 48),\l... align 16, !tbaa !7\l  %1440 = fsub contract float %1438, %1439\l  %1441 = tail call float @llvm.fabs.f32(float %1440)\l  %1442 = fadd contract float %1437, %1441\l  %1443 = load float, float addrspace(3)* %1026, align 4, !tbaa !7\l  %1444 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 49),\l... align 4, !tbaa !7\l  %1445 = fsub contract float %1443, %1444\l  %1446 = tail call float @llvm.fabs.f32(float %1445)\l  %1447 = fadd contract float %1442, %1446\l  %1448 = load float, float addrspace(3)* %1028, align 8, !tbaa !7\l  %1449 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 50),\l... align 8, !tbaa !7\l  %1450 = fsub contract float %1448, %1449\l  %1451 = tail call float @llvm.fabs.f32(float %1450)\l  %1452 = fadd contract float %1447, %1451\l  %1453 = load float, float addrspace(3)* %1030, align 4, !tbaa !7\l  %1454 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 51),\l... align 4, !tbaa !7\l  %1455 = fsub contract float %1453, %1454\l  %1456 = tail call float @llvm.fabs.f32(float %1455)\l  %1457 = fadd contract float %1452, %1456\l  %1458 = load float, float addrspace(3)* %1032, align 16, !tbaa !7\l  %1459 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 52),\l... align 16, !tbaa !7\l  %1460 = fsub contract float %1458, %1459\l  %1461 = tail call float @llvm.fabs.f32(float %1460)\l  %1462 = fadd contract float %1457, %1461\l  %1463 = load float, float addrspace(3)* %1034, align 4, !tbaa !7\l  %1464 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 53),\l... align 4, !tbaa !7\l  %1465 = fsub contract float %1463, %1464\l  %1466 = tail call float @llvm.fabs.f32(float %1465)\l  %1467 = fadd contract float %1462, %1466\l  %1468 = load float, float addrspace(3)* %1036, align 8, !tbaa !7\l  %1469 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 54),\l... align 8, !tbaa !7\l  %1470 = fsub contract float %1468, %1469\l  %1471 = tail call float @llvm.fabs.f32(float %1470)\l  %1472 = fadd contract float %1467, %1471\l  %1473 = load float, float addrspace(3)* %1038, align 4, !tbaa !7\l  %1474 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 55),\l... align 4, !tbaa !7\l  %1475 = fsub contract float %1473, %1474\l  %1476 = tail call float @llvm.fabs.f32(float %1475)\l  %1477 = fadd contract float %1472, %1476\l  %1478 = load float, float addrspace(3)* %1040, align 16, !tbaa !7\l  %1479 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 56),\l... align 16, !tbaa !7\l  %1480 = fsub contract float %1478, %1479\l  %1481 = tail call float @llvm.fabs.f32(float %1480)\l  %1482 = fadd contract float %1477, %1481\l  %1483 = load float, float addrspace(3)* %1042, align 4, !tbaa !7\l  %1484 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 57),\l... align 4, !tbaa !7\l  %1485 = fsub contract float %1483, %1484\l  %1486 = tail call float @llvm.fabs.f32(float %1485)\l  %1487 = fadd contract float %1482, %1486\l  %1488 = load float, float addrspace(3)* %1044, align 8, !tbaa !7\l  %1489 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 58),\l... align 8, !tbaa !7\l  %1490 = fsub contract float %1488, %1489\l  %1491 = tail call float @llvm.fabs.f32(float %1490)\l  %1492 = fadd contract float %1487, %1491\l  %1493 = load float, float addrspace(3)* %1046, align 4, !tbaa !7\l  %1494 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 59),\l... align 4, !tbaa !7\l  %1495 = fsub contract float %1493, %1494\l  %1496 = tail call float @llvm.fabs.f32(float %1495)\l  %1497 = fadd contract float %1492, %1496\l  %1498 = load float, float addrspace(3)* %1048, align 16, !tbaa !7\l  %1499 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 60),\l... align 16, !tbaa !7\l  %1500 = fsub contract float %1498, %1499\l  %1501 = tail call float @llvm.fabs.f32(float %1500)\l  %1502 = fadd contract float %1497, %1501\l  %1503 = load float, float addrspace(3)* %1050, align 4, !tbaa !7\l  %1504 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 61),\l... align 4, !tbaa !7\l  %1505 = fsub contract float %1503, %1504\l  %1506 = tail call float @llvm.fabs.f32(float %1505)\l  %1507 = fadd contract float %1502, %1506\l  %1508 = load float, float addrspace(3)* %1052, align 8, !tbaa !7\l  %1509 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 62),\l... align 8, !tbaa !7\l  %1510 = fsub contract float %1508, %1509\l  %1511 = tail call float @llvm.fabs.f32(float %1510)\l  %1512 = fadd contract float %1507, %1511\l  %1513 = load float, float addrspace(3)* %1054, align 4, !tbaa !7\l  %1514 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 63),\l... align 4, !tbaa !7\l  %1515 = fsub contract float %1513, %1514\l  %1516 = tail call float @llvm.fabs.f32(float %1515)\l  %1517 = fadd contract float %1512, %1516\l  %1518 = load float, float addrspace(3)* %1056, align 16, !tbaa !7\l  %1519 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 64),\l... align 16, !tbaa !7\l  %1520 = fsub contract float %1518, %1519\l  %1521 = tail call float @llvm.fabs.f32(float %1520)\l  %1522 = fadd contract float %1517, %1521\l  %1523 = load float, float addrspace(3)* %1058, align 4, !tbaa !7\l  %1524 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 65),\l... align 4, !tbaa !7\l  %1525 = fsub contract float %1523, %1524\l  %1526 = tail call float @llvm.fabs.f32(float %1525)\l  %1527 = fadd contract float %1522, %1526\l  %1528 = load float, float addrspace(3)* %1060, align 8, !tbaa !7\l  %1529 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 66),\l... align 8, !tbaa !7\l  %1530 = fsub contract float %1528, %1529\l  %1531 = tail call float @llvm.fabs.f32(float %1530)\l  %1532 = fadd contract float %1527, %1531\l  %1533 = load float, float addrspace(3)* %1062, align 4, !tbaa !7\l  %1534 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 67),\l... align 4, !tbaa !7\l  %1535 = fsub contract float %1533, %1534\l  %1536 = tail call float @llvm.fabs.f32(float %1535)\l  %1537 = fadd contract float %1532, %1536\l  %1538 = load float, float addrspace(3)* %1064, align 16, !tbaa !7\l  %1539 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 68),\l... align 16, !tbaa !7\l  %1540 = fsub contract float %1538, %1539\l  %1541 = tail call float @llvm.fabs.f32(float %1540)\l  %1542 = fadd contract float %1537, %1541\l  %1543 = load float, float addrspace(3)* %1066, align 4, !tbaa !7\l  %1544 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 69),\l... align 4, !tbaa !7\l  %1545 = fsub contract float %1543, %1544\l  %1546 = tail call float @llvm.fabs.f32(float %1545)\l  %1547 = fadd contract float %1542, %1546\l  %1548 = load float, float addrspace(3)* %1068, align 8, !tbaa !7\l  %1549 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 70),\l... align 8, !tbaa !7\l  %1550 = fsub contract float %1548, %1549\l  %1551 = tail call float @llvm.fabs.f32(float %1550)\l  %1552 = fadd contract float %1547, %1551\l  %1553 = load float, float addrspace(3)* %1070, align 4, !tbaa !7\l  %1554 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 71),\l... align 4, !tbaa !7\l  %1555 = fsub contract float %1553, %1554\l  %1556 = tail call float @llvm.fabs.f32(float %1555)\l  %1557 = fadd contract float %1552, %1556\l  %1558 = load float, float addrspace(3)* %1072, align 16, !tbaa !7\l  %1559 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 72),\l... align 16, !tbaa !7\l  %1560 = fsub contract float %1558, %1559\l  %1561 = tail call float @llvm.fabs.f32(float %1560)\l  %1562 = fadd contract float %1557, %1561\l  %1563 = load float, float addrspace(3)* %1074, align 4, !tbaa !7\l  %1564 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 73),\l... align 4, !tbaa !7\l  %1565 = fsub contract float %1563, %1564\l  %1566 = tail call float @llvm.fabs.f32(float %1565)\l  %1567 = fadd contract float %1562, %1566\l  %1568 = load float, float addrspace(3)* %1076, align 8, !tbaa !7\l  %1569 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 74),\l... align 8, !tbaa !7\l  %1570 = fsub contract float %1568, %1569\l  %1571 = tail call float @llvm.fabs.f32(float %1570)\l  %1572 = fadd contract float %1567, %1571\l  %1573 = load float, float addrspace(3)* %1078, align 4, !tbaa !7\l  %1574 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 75),\l... align 4, !tbaa !7\l  %1575 = fsub contract float %1573, %1574\l  %1576 = tail call float @llvm.fabs.f32(float %1575)\l  %1577 = fadd contract float %1572, %1576\l  %1578 = load float, float addrspace(3)* %1080, align 16, !tbaa !7\l  %1579 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 76),\l... align 16, !tbaa !7\l  %1580 = fsub contract float %1578, %1579\l  %1581 = tail call float @llvm.fabs.f32(float %1580)\l  %1582 = fadd contract float %1577, %1581\l  %1583 = load float, float addrspace(3)* %1082, align 4, !tbaa !7\l  %1584 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 77),\l... align 4, !tbaa !7\l  %1585 = fsub contract float %1583, %1584\l  %1586 = tail call float @llvm.fabs.f32(float %1585)\l  %1587 = fadd contract float %1582, %1586\l  %1588 = load float, float addrspace(3)* %1084, align 8, !tbaa !7\l  %1589 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 78),\l... align 8, !tbaa !7\l  %1590 = fsub contract float %1588, %1589\l  %1591 = tail call float @llvm.fabs.f32(float %1590)\l  %1592 = fadd contract float %1587, %1591\l  %1593 = load float, float addrspace(3)* %1086, align 4, !tbaa !7\l  %1594 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 79),\l... align 4, !tbaa !7\l  %1595 = fsub contract float %1593, %1594\l  %1596 = tail call float @llvm.fabs.f32(float %1595)\l  %1597 = fadd contract float %1592, %1596\l  %1598 = load float, float addrspace(3)* %1088, align 16, !tbaa !7\l  %1599 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 80),\l... align 16, !tbaa !7\l  %1600 = fsub contract float %1598, %1599\l  %1601 = tail call float @llvm.fabs.f32(float %1600)\l  %1602 = fadd contract float %1597, %1601\l  %1603 = load float, float addrspace(3)* %1090, align 4, !tbaa !7\l  %1604 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 81),\l... align 4, !tbaa !7\l  %1605 = fsub contract float %1603, %1604\l  %1606 = tail call float @llvm.fabs.f32(float %1605)\l  %1607 = fadd contract float %1602, %1606\l  %1608 = load float, float addrspace(3)* %1092, align 8, !tbaa !7\l  %1609 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 82),\l... align 8, !tbaa !7\l  %1610 = fsub contract float %1608, %1609\l  %1611 = tail call float @llvm.fabs.f32(float %1610)\l  %1612 = fadd contract float %1607, %1611\l  %1613 = load float, float addrspace(3)* %1094, align 4, !tbaa !7\l  %1614 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 83),\l... align 4, !tbaa !7\l  %1615 = fsub contract float %1613, %1614\l  %1616 = tail call float @llvm.fabs.f32(float %1615)\l  %1617 = fadd contract float %1612, %1616\l  %1618 = load float, float addrspace(3)* %1096, align 16, !tbaa !7\l  %1619 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 84),\l... align 16, !tbaa !7\l  %1620 = fsub contract float %1618, %1619\l  %1621 = tail call float @llvm.fabs.f32(float %1620)\l  %1622 = fadd contract float %1617, %1621\l  %1623 = load float, float addrspace(3)* %1098, align 4, !tbaa !7\l  %1624 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 85),\l... align 4, !tbaa !7\l  %1625 = fsub contract float %1623, %1624\l  %1626 = tail call float @llvm.fabs.f32(float %1625)\l  %1627 = fadd contract float %1622, %1626\l  %1628 = load float, float addrspace(3)* %1100, align 8, !tbaa !7\l  %1629 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 86),\l... align 8, !tbaa !7\l  %1630 = fsub contract float %1628, %1629\l  %1631 = tail call float @llvm.fabs.f32(float %1630)\l  %1632 = fadd contract float %1627, %1631\l  %1633 = load float, float addrspace(3)* %1102, align 4, !tbaa !7\l  %1634 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 87),\l... align 4, !tbaa !7\l  %1635 = fsub contract float %1633, %1634\l  %1636 = tail call float @llvm.fabs.f32(float %1635)\l  %1637 = fadd contract float %1632, %1636\l  %1638 = load float, float addrspace(3)* %1104, align 16, !tbaa !7\l  %1639 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 88),\l... align 16, !tbaa !7\l  %1640 = fsub contract float %1638, %1639\l  %1641 = tail call float @llvm.fabs.f32(float %1640)\l  %1642 = fadd contract float %1637, %1641\l  %1643 = load float, float addrspace(3)* %1106, align 4, !tbaa !7\l  %1644 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 89),\l... align 4, !tbaa !7\l  %1645 = fsub contract float %1643, %1644\l  %1646 = tail call float @llvm.fabs.f32(float %1645)\l  %1647 = fadd contract float %1642, %1646\l  %1648 = load float, float addrspace(3)* %1108, align 8, !tbaa !7\l  %1649 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 90),\l... align 8, !tbaa !7\l  %1650 = fsub contract float %1648, %1649\l  %1651 = tail call float @llvm.fabs.f32(float %1650)\l  %1652 = fadd contract float %1647, %1651\l  %1653 = load float, float addrspace(3)* %1110, align 4, !tbaa !7\l  %1654 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 91),\l... align 4, !tbaa !7\l  %1655 = fsub contract float %1653, %1654\l  %1656 = tail call float @llvm.fabs.f32(float %1655)\l  %1657 = fadd contract float %1652, %1656\l  %1658 = load float, float addrspace(3)* %1112, align 16, !tbaa !7\l  %1659 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 92),\l... align 16, !tbaa !7\l  %1660 = fsub contract float %1658, %1659\l  %1661 = tail call float @llvm.fabs.f32(float %1660)\l  %1662 = fadd contract float %1657, %1661\l  %1663 = load float, float addrspace(3)* %1114, align 4, !tbaa !7\l  %1664 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 93),\l... align 4, !tbaa !7\l  %1665 = fsub contract float %1663, %1664\l  %1666 = tail call float @llvm.fabs.f32(float %1665)\l  %1667 = fadd contract float %1662, %1666\l  %1668 = load float, float addrspace(3)* %1116, align 8, !tbaa !7\l  %1669 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 94),\l... align 8, !tbaa !7\l  %1670 = fsub contract float %1668, %1669\l  %1671 = tail call float @llvm.fabs.f32(float %1670)\l  %1672 = fadd contract float %1667, %1671\l  %1673 = load float, float addrspace(3)* %1118, align 4, !tbaa !7\l  %1674 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 95),\l... align 4, !tbaa !7\l  %1675 = fsub contract float %1673, %1674\l  %1676 = tail call float @llvm.fabs.f32(float %1675)\l  %1677 = fadd contract float %1672, %1676\l  %1678 = load float, float addrspace(3)* %1120, align 16, !tbaa !7\l  %1679 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 96),\l... align 16, !tbaa !7\l  %1680 = fsub contract float %1678, %1679\l  %1681 = tail call float @llvm.fabs.f32(float %1680)\l  %1682 = fadd contract float %1677, %1681\l  %1683 = load float, float addrspace(3)* %1122, align 4, !tbaa !7\l  %1684 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 97),\l... align 4, !tbaa !7\l  %1685 = fsub contract float %1683, %1684\l  %1686 = tail call float @llvm.fabs.f32(float %1685)\l  %1687 = fadd contract float %1682, %1686\l  %1688 = load float, float addrspace(3)* %1124, align 8, !tbaa !7\l  %1689 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 98),\l... align 8, !tbaa !7\l  %1690 = fsub contract float %1688, %1689\l  %1691 = tail call float @llvm.fabs.f32(float %1690)\l  %1692 = fadd contract float %1687, %1691\l  %1693 = load float, float addrspace(3)* %1126, align 4, !tbaa !7\l  %1694 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 99),\l... align 4, !tbaa !7\l  %1695 = fsub contract float %1693, %1694\l  %1696 = tail call float @llvm.fabs.f32(float %1695)\l  %1697 = fadd contract float %1692, %1696\l  %1698 = load float, float addrspace(3)* %1128, align 16, !tbaa !7\l  %1699 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 100),\l... align 16, !tbaa !7\l  %1700 = fsub contract float %1698, %1699\l  %1701 = tail call float @llvm.fabs.f32(float %1700)\l  %1702 = fadd contract float %1697, %1701\l  %1703 = load float, float addrspace(3)* %1130, align 4, !tbaa !7\l  %1704 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 101),\l... align 4, !tbaa !7\l  %1705 = fsub contract float %1703, %1704\l  %1706 = tail call float @llvm.fabs.f32(float %1705)\l  %1707 = fadd contract float %1702, %1706\l  %1708 = load float, float addrspace(3)* %1132, align 8, !tbaa !7\l  %1709 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 102),\l... align 8, !tbaa !7\l  %1710 = fsub contract float %1708, %1709\l  %1711 = tail call float @llvm.fabs.f32(float %1710)\l  %1712 = fadd contract float %1707, %1711\l  %1713 = load float, float addrspace(3)* %1134, align 4, !tbaa !7\l  %1714 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 103),\l... align 4, !tbaa !7\l  %1715 = fsub contract float %1713, %1714\l  %1716 = tail call float @llvm.fabs.f32(float %1715)\l  %1717 = fadd contract float %1712, %1716\l  %1718 = load float, float addrspace(3)* %1136, align 16, !tbaa !7\l  %1719 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 104),\l... align 16, !tbaa !7\l  %1720 = fsub contract float %1718, %1719\l  %1721 = tail call float @llvm.fabs.f32(float %1720)\l  %1722 = fadd contract float %1717, %1721\l  %1723 = load float, float addrspace(3)* %1138, align 4, !tbaa !7\l  %1724 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 105),\l... align 4, !tbaa !7\l  %1725 = fsub contract float %1723, %1724\l  %1726 = tail call float @llvm.fabs.f32(float %1725)\l  %1727 = fadd contract float %1722, %1726\l  %1728 = load float, float addrspace(3)* %1140, align 8, !tbaa !7\l  %1729 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 106),\l... align 8, !tbaa !7\l  %1730 = fsub contract float %1728, %1729\l  %1731 = tail call float @llvm.fabs.f32(float %1730)\l  %1732 = fadd contract float %1727, %1731\l  %1733 = load float, float addrspace(3)* %1142, align 4, !tbaa !7\l  %1734 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 107),\l... align 4, !tbaa !7\l  %1735 = fsub contract float %1733, %1734\l  %1736 = tail call float @llvm.fabs.f32(float %1735)\l  %1737 = fadd contract float %1732, %1736\l  %1738 = load float, float addrspace(3)* %1144, align 16, !tbaa !7\l  %1739 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 108),\l... align 16, !tbaa !7\l  %1740 = fsub contract float %1738, %1739\l  %1741 = tail call float @llvm.fabs.f32(float %1740)\l  %1742 = fadd contract float %1737, %1741\l  %1743 = load float, float addrspace(3)* %1146, align 4, !tbaa !7\l  %1744 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 109),\l... align 4, !tbaa !7\l  %1745 = fsub contract float %1743, %1744\l  %1746 = tail call float @llvm.fabs.f32(float %1745)\l  %1747 = fadd contract float %1742, %1746\l  %1748 = load float, float addrspace(3)* %1148, align 8, !tbaa !7\l  %1749 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 110),\l... align 8, !tbaa !7\l  %1750 = fsub contract float %1748, %1749\l  %1751 = tail call float @llvm.fabs.f32(float %1750)\l  %1752 = fadd contract float %1747, %1751\l  %1753 = load float, float addrspace(3)* %1150, align 4, !tbaa !7\l  %1754 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 111),\l... align 4, !tbaa !7\l  %1755 = fsub contract float %1753, %1754\l  %1756 = tail call float @llvm.fabs.f32(float %1755)\l  %1757 = fadd contract float %1752, %1756\l  %1758 = load float, float addrspace(3)* %1152, align 16, !tbaa !7\l  %1759 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 112),\l... align 16, !tbaa !7\l  %1760 = fsub contract float %1758, %1759\l  %1761 = tail call float @llvm.fabs.f32(float %1760)\l  %1762 = fadd contract float %1757, %1761\l  %1763 = load float, float addrspace(3)* %1154, align 4, !tbaa !7\l  %1764 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 113),\l... align 4, !tbaa !7\l  %1765 = fsub contract float %1763, %1764\l  %1766 = tail call float @llvm.fabs.f32(float %1765)\l  %1767 = fadd contract float %1762, %1766\l  %1768 = load float, float addrspace(3)* %1156, align 8, !tbaa !7\l  %1769 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 114),\l... align 8, !tbaa !7\l  %1770 = fsub contract float %1768, %1769\l  %1771 = tail call float @llvm.fabs.f32(float %1770)\l  %1772 = fadd contract float %1767, %1771\l  %1773 = load float, float addrspace(3)* %1158, align 4, !tbaa !7\l  %1774 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 115),\l... align 4, !tbaa !7\l  %1775 = fsub contract float %1773, %1774\l  %1776 = tail call float @llvm.fabs.f32(float %1775)\l  %1777 = fadd contract float %1772, %1776\l  %1778 = load float, float addrspace(3)* %1160, align 16, !tbaa !7\l  %1779 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 116),\l... align 16, !tbaa !7\l  %1780 = fsub contract float %1778, %1779\l  %1781 = tail call float @llvm.fabs.f32(float %1780)\l  %1782 = fadd contract float %1777, %1781\l  %1783 = load float, float addrspace(3)* %1162, align 4, !tbaa !7\l  %1784 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 117),\l... align 4, !tbaa !7\l  %1785 = fsub contract float %1783, %1784\l  %1786 = tail call float @llvm.fabs.f32(float %1785)\l  %1787 = fadd contract float %1782, %1786\l  %1788 = load float, float addrspace(3)* %1164, align 8, !tbaa !7\l  %1789 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 118),\l... align 8, !tbaa !7\l  %1790 = fsub contract float %1788, %1789\l  %1791 = tail call float @llvm.fabs.f32(float %1790)\l  %1792 = fadd contract float %1787, %1791\l  %1793 = load float, float addrspace(3)* %1166, align 4, !tbaa !7\l  %1794 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 119),\l... align 4, !tbaa !7\l  %1795 = fsub contract float %1793, %1794\l  %1796 = tail call float @llvm.fabs.f32(float %1795)\l  %1797 = fadd contract float %1792, %1796\l  %1798 = load float, float addrspace(3)* %1168, align 16, !tbaa !7\l  %1799 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 120),\l... align 16, !tbaa !7\l  %1800 = fsub contract float %1798, %1799\l  %1801 = tail call float @llvm.fabs.f32(float %1800)\l  %1802 = fadd contract float %1797, %1801\l  %1803 = load float, float addrspace(3)* %1170, align 4, !tbaa !7\l  %1804 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 121),\l... align 4, !tbaa !7\l  %1805 = fsub contract float %1803, %1804\l  %1806 = tail call float @llvm.fabs.f32(float %1805)\l  %1807 = fadd contract float %1802, %1806\l  %1808 = load float, float addrspace(3)* %1172, align 8, !tbaa !7\l  %1809 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 122),\l... align 8, !tbaa !7\l  %1810 = fsub contract float %1808, %1809\l  %1811 = tail call float @llvm.fabs.f32(float %1810)\l  %1812 = fadd contract float %1807, %1811\l  %1813 = load float, float addrspace(3)* %1174, align 4, !tbaa !7\l  %1814 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 123),\l... align 4, !tbaa !7\l  %1815 = fsub contract float %1813, %1814\l  %1816 = tail call float @llvm.fabs.f32(float %1815)\l  %1817 = fadd contract float %1812, %1816\l  %1818 = load float, float addrspace(3)* %1176, align 16, !tbaa !7\l  %1819 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 124),\l... align 16, !tbaa !7\l  %1820 = fsub contract float %1818, %1819\l  %1821 = tail call float @llvm.fabs.f32(float %1820)\l  %1822 = fadd contract float %1817, %1821\l  %1823 = load float, float addrspace(3)* %1178, align 4, !tbaa !7\l  %1824 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 125),\l... align 4, !tbaa !7\l  %1825 = fsub contract float %1823, %1824\l  %1826 = tail call float @llvm.fabs.f32(float %1825)\l  %1827 = fadd contract float %1822, %1826\l  %1828 = load float, float addrspace(3)* %1180, align 8, !tbaa !7\l  %1829 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 126),\l... align 8, !tbaa !7\l  %1830 = fsub contract float %1828, %1829\l  %1831 = tail call float @llvm.fabs.f32(float %1830)\l  %1832 = fadd contract float %1827, %1831\l  %1833 = load float, float addrspace(3)* %1182, align 4, !tbaa !7\l  %1834 = load float, float addrspace(3)* getelementptr inbounds ([128 x\l... float], [128 x float] addrspace(3)*\l... @_ZZ14histDupeKernelPKfS0_S0_S0_PiS1_S1_S1_PfS1_iiiE5other, i32 0, i32 127),\l... align 4, !tbaa !7\l  %1835 = fsub contract float %1833, %1834\l  %1836 = tail call float @llvm.fabs.f32(float %1835)\l  %1837 = fadd contract float %1832, %1836\l  %1838 = fmul contract float %1837, 1.250000e-01\l  %1839 = fsub contract float 1.000000e+00, %1838\l  %1840 = zext i32 %1184 to i64\l  %1841 = getelementptr inbounds i32, i32 addrspace(1)* %5, i64 %1840\l  %1842 = load i32, i32 addrspace(1)* %1841, align 4, !tbaa !11\l  %1843 = icmp eq i32 %1842, %27\l  br i1 %1843, label %1857, label %1844\l|{<s0>T|<s1>F}}"];
	Node0x4a76370:s0 -> Node0x4aa02b0;
	Node0x4a76370:s1 -> Node0x4aa0f60;
	Node0x4aa0f60 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#f7ac8e70",label="{%1844:\l1844:                                             \l  %1845 = getelementptr inbounds float, float addrspace(1)* %3, i64 %1840\l  %1846 = load float, float addrspace(1)* %1845, align 4, !tbaa !7\l  %1847 = tail call float @llvm.maxnum.f32(float %25, float %1846)\l  %1848 = fcmp contract ogt float %1839, %1847\l  br i1 %1848, label %1849, label %1857\l|{<s0>T|<s1>F}}"];
	Node0x4aa0f60:s0 -> Node0x4aa13e0;
	Node0x4aa0f60:s1 -> Node0x4aa02b0;
	Node0x4aa13e0 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#ecd3c570",label="{%1849:\l1849:                                             \l  %1850 = atomicrmw add i32 addrspace(1)* %9, i32 1 syncscope(\"agent-one-as\")\l... monotonic, align 4\l  %1851 = icmp slt i32 %1850, %12\l  br i1 %1851, label %1852, label %1857\l|{<s0>T|<s1>F}}"];
	Node0x4aa13e0:s0 -> Node0x4aa16a0;
	Node0x4aa13e0:s1 -> Node0x4aa02b0;
	Node0x4aa16a0 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#c7d7f070",label="{%1852:\l1852:                                             \l  %1853 = sext i32 %1850 to i64\l  %1854 = getelementptr inbounds float, float addrspace(1)* %8, i64 %1853\l  store float %1839, float addrspace(1)* %1854, align 4, !tbaa !7\l  %1855 = getelementptr inbounds i32, i32 addrspace(1)* %6, i64 %1853\l  store i32 %27, i32 addrspace(1)* %1855, align 4, !tbaa !11\l  %1856 = getelementptr inbounds i32, i32 addrspace(1)* %7, i64 %1853\l  store i32 %1842, i32 addrspace(1)* %1856, align 4, !tbaa !11\l  br label %1857\l}"];
	Node0x4aa16a0 -> Node0x4aa02b0;
	Node0x4aa02b0 [shape=record,color="#b70d28ff", style=filled, fillcolor="#bb1b2c70",label="{%1857:\l1857:                                             \l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %1858 = add nuw i32 %1184, 1\l  %1859 = icmp eq i32 %1858, %11\l  br i1 %1859, label %1187, label %1183, !llvm.loop !13\l|{<s0>T|<s1>F}}"];
	Node0x4aa02b0:s0 -> Node0x4a90680;
	Node0x4aa02b0:s1 -> Node0x4aa0180;
}
