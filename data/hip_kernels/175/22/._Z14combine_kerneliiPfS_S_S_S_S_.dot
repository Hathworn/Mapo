digraph "CFG for '_Z14combine_kerneliiPfS_S_S_S_S_' function" {
	label="CFG for '_Z14combine_kerneliiPfS_S_S_S_S_' function";

	Node0x451f340 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%8:\l  %9 = tail call align 4 dereferenceable(64) i8 addrspace(4)*\l... @llvm.amdgcn.dispatch.ptr()\l  %10 = getelementptr i8, i8 addrspace(4)* %9, i64 4\l  %11 = bitcast i8 addrspace(4)* %10 to i16 addrspace(4)*\l  %12 = load i16, i16 addrspace(4)* %11, align 4, !range !4, !invariant.load !5\l  %13 = zext i16 %12 to i32\l  %14 = tail call i32 @llvm.amdgcn.workgroup.id.x()\l  %15 = mul i32 %14, %13\l  %16 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6\l  %17 = add i32 %15, %16\l  %18 = icmp slt i32 %17, %0\l  br i1 %18, label %19, label %124\l|{<s0>T|<s1>F}}"];
	Node0x451f340:s0 -> Node0x4520c60;
	Node0x451f340:s1 -> Node0x4520cf0;
	Node0x4520c60 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#f59c7d70",label="{%19:\l19:                                               \l  %20 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6\l  %21 = mul nsw i32 %20, %1\l  %22 = add nsw i32 %17, %21\l  %23 = sext i32 %22 to i64\l  %24 = getelementptr inbounds float, float addrspace(1)* %2, i64 %23\l  %25 = load float, float addrspace(1)* %24, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %26 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 0), align 16, !tbaa !7\l  %27 = fmul contract float %25, %26\l  %28 = fadd contract float %27, 0.000000e+00\l  %29 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 0), align 16, !tbaa !7\l  %30 = fmul contract float %25, %29\l  %31 = fadd contract float %30, 0.000000e+00\l  %32 = shl nsw i32 %1, 3\l  %33 = sext i32 %32 to i64\l  %34 = getelementptr inbounds float, float addrspace(1)* %24, i64 %33\l  %35 = load float, float addrspace(1)* %34, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %36 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 1), align 4, !tbaa !7\l  %37 = fmul contract float %35, %36\l  %38 = fadd contract float %28, %37\l  %39 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 1), align 4, !tbaa !7\l  %40 = fmul contract float %35, %39\l  %41 = fadd contract float %31, %40\l  %42 = getelementptr inbounds float, float addrspace(1)* %34, i64 %33\l  %43 = load float, float addrspace(1)* %42, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %44 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 2), align 8, !tbaa !7\l  %45 = fmul contract float %43, %44\l  %46 = fadd contract float %38, %45\l  %47 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 2), align 8, !tbaa !7\l  %48 = fmul contract float %43, %47\l  %49 = fadd contract float %41, %48\l  %50 = getelementptr inbounds float, float addrspace(1)* %3, i64 %23\l  %51 = load float, float addrspace(1)* %50, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %52 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 3), align 4, !tbaa !7\l  %53 = fmul contract float %51, %52\l  %54 = fadd contract float %46, %53\l  %55 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 3), align 4, !tbaa !7\l  %56 = fmul contract float %51, %55\l  %57 = fadd contract float %49, %56\l  %58 = getelementptr inbounds float, float addrspace(1)* %50, i64 %33\l  %59 = load float, float addrspace(1)* %58, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %60 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 4), align 16, !tbaa !7\l  %61 = fmul contract float %59, %60\l  %62 = fadd contract float %54, %61\l  %63 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 4), align 16, !tbaa !7\l  %64 = fmul contract float %59, %63\l  %65 = fadd contract float %57, %64\l  %66 = getelementptr inbounds float, float addrspace(1)* %58, i64 %33\l  %67 = load float, float addrspace(1)* %66, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %68 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 5), align 4, !tbaa !7\l  %69 = fmul contract float %67, %68\l  %70 = fadd contract float %62, %69\l  %71 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 5), align 4, !tbaa !7\l  %72 = fmul contract float %67, %71\l  %73 = fadd contract float %65, %72\l  %74 = getelementptr inbounds float, float addrspace(1)* %4, i64 %23\l  %75 = load float, float addrspace(1)* %74, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %76 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 6), align 8, !tbaa !7\l  %77 = fmul contract float %75, %76\l  %78 = fadd contract float %70, %77\l  %79 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 6), align 8, !tbaa !7\l  %80 = fmul contract float %75, %79\l  %81 = fadd contract float %73, %80\l  %82 = getelementptr inbounds float, float addrspace(1)* %74, i64 %33\l  %83 = load float, float addrspace(1)* %82, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %84 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 7), align 4, !tbaa !7\l  %85 = fmul contract float %83, %84\l  %86 = fadd contract float %78, %85\l  %87 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 7), align 4, !tbaa !7\l  %88 = fmul contract float %83, %87\l  %89 = fadd contract float %81, %88\l  %90 = getelementptr inbounds float, float addrspace(1)* %82, i64 %33\l  %91 = load float, float addrspace(1)* %90, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %92 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 8), align 16, !tbaa !7\l  %93 = fmul contract float %91, %92\l  %94 = fadd contract float %86, %93\l  %95 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 8), align 16, !tbaa !7\l  %96 = fmul contract float %91, %95\l  %97 = fadd contract float %89, %96\l  %98 = getelementptr inbounds float, float addrspace(1)* %5, i64 %23\l  %99 = load float, float addrspace(1)* %98, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %100 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 9), align 4, !tbaa !7\l  %101 = fmul contract float %99, %100\l  %102 = fadd contract float %94, %101\l  %103 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 9), align 4, !tbaa !7\l  %104 = fmul contract float %99, %103\l  %105 = fadd contract float %97, %104\l  %106 = getelementptr inbounds float, float addrspace(1)* %98, i64 %33\l  %107 = load float, float addrspace(1)* %106, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %108 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 10), align 8, !tbaa !7\l  %109 = fmul contract float %107, %108\l  %110 = fadd contract float %102, %109\l  %111 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 10), align 8, !tbaa !7\l  %112 = fmul contract float %107, %111\l  %113 = fadd contract float %105, %112\l  %114 = getelementptr inbounds float, float addrspace(1)* %106, i64 %33\l  %115 = load float, float addrspace(1)* %114, align 4, !tbaa !7,\l... !amdgpu.noclobber !5\l  %116 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @coefficients, i64 0, i64 11), align 4, !tbaa !7\l  %117 = fmul contract float %115, %116\l  %118 = fadd contract float %110, %117\l  %119 = load float, float addrspace(4)* getelementptr inbounds ([12 x float],\l... [12 x float] addrspace(4)* @weights, i64 0, i64 11), align 4, !tbaa !7\l  %120 = fmul contract float %115, %119\l  %121 = fadd contract float %113, %120\l  %122 = getelementptr inbounds float, float addrspace(1)* %6, i64 %23\l  store float %118, float addrspace(1)* %122, align 4, !tbaa !7\l  %123 = getelementptr inbounds float, float addrspace(1)* %7, i64 %23\l  store float %121, float addrspace(1)* %123, align 4, !tbaa !7\l  br label %124\l}"];
	Node0x4520c60 -> Node0x4520cf0;
	Node0x4520cf0 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%124:\l124:                                              \l  ret void\l}"];
}
