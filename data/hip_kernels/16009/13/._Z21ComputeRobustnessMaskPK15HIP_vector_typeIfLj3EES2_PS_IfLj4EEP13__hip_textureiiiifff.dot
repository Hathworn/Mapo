digraph "CFG for '_Z21ComputeRobustnessMaskPK15HIP_vector_typeIfLj3EES2_PS_IfLj4EEP13__hip_textureiiiifff' function" {
	label="CFG for '_Z21ComputeRobustnessMaskPK15HIP_vector_typeIfLj3EES2_PS_IfLj4EEP13__hip_textureiiiifff' function";

	Node0x48b61b0 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%11:\l  %12 = tail call i32 @llvm.amdgcn.workgroup.id.x()\l  %13 = tail call align 4 dereferenceable(64) i8 addrspace(4)*\l... @llvm.amdgcn.dispatch.ptr()\l  %14 = getelementptr i8, i8 addrspace(4)* %13, i64 4\l  %15 = bitcast i8 addrspace(4)* %14 to i16 addrspace(4)*\l  %16 = load i16, i16 addrspace(4)* %15, align 4, !range !4, !invariant.load !5\l  %17 = zext i16 %16 to i32\l  %18 = mul i32 %12, %17\l  %19 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6\l  %20 = add i32 %18, %19\l  %21 = tail call i32 @llvm.amdgcn.workgroup.id.y()\l  %22 = getelementptr i8, i8 addrspace(4)* %13, i64 6\l  %23 = bitcast i8 addrspace(4)* %22 to i16 addrspace(4)*\l  %24 = load i16, i16 addrspace(4)* %23, align 2, !range !4, !invariant.load !5\l  %25 = zext i16 %24 to i32\l  %26 = mul i32 %21, %25\l  %27 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6\l  %28 = add i32 %26, %27\l  %29 = mul nuw nsw i32 %27, %17\l  %30 = add nuw nsw i32 %29, %19\l  %31 = mul nuw nsw i32 %30, 9\l  %32 = add nsw i32 %4, -1\l  %33 = icmp slt i32 %20, %32\l  br i1 %33, label %34, label %757\l|{<s0>T|<s1>F}}"];
	Node0x48b61b0:s0 -> Node0x48b8220;
	Node0x48b61b0:s1 -> Node0x48ba570;
	Node0x48b8220 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#ef886b70",label="{%34:\l34:                                               \l  %35 = add nsw i32 %5, -1\l  %36 = icmp sge i32 %28, %35\l  %37 = icmp slt i32 %20, 1\l  %38 = select i1 %36, i1 true, i1 %37\l  %39 = icmp slt i32 %28, 1\l  %40 = or i1 %39, %38\l  br i1 %40, label %757, label %41\l|{<s0>T|<s1>F}}"];
	Node0x48b8220:s0 -> Node0x48ba570;
	Node0x48b8220:s1 -> Node0x48baa60;
	Node0x48baa60 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#f1ccb870",label="{%41:\l41:                                               \l  %42 = sitofp i32 %20 to float\l  %43 = fadd contract float %42, 5.000000e-01\l  %44 = sitofp i32 %4 to float\l  %45 = fdiv contract float %43, %44\l  %46 = sitofp i32 %28 to float\l  %47 = fadd contract float %46, 5.000000e-01\l  %48 = sitofp i32 %5 to float\l  %49 = fdiv contract float %47, %48\l  %50 = bitcast %struct.__hip_texture addrspace(1)* %3 to i32 addrspace(1)*\l  %51 = addrspacecast i32 addrspace(1)* %50 to i32 addrspace(4)*\l  %52 = getelementptr inbounds i32, i32 addrspace(4)* %51, i64 12\l  %53 = getelementptr inbounds i32, i32 addrspace(4)* %51, i64 10\l  %54 = load i32, i32 addrspace(4)* %53, align 4, !tbaa !7, !amdgpu.noclobber\l... !5\l  %55 = uitofp i32 %54 to float\l  %56 = getelementptr inbounds i32, i32 addrspace(4)* %51, i64 2\l  %57 = load i32, i32 addrspace(4)* %56, align 4, !tbaa !7, !amdgpu.noclobber\l... !5\l  %58 = lshr i32 %57, 14\l  %59 = and i32 %58, 16383\l  %60 = add nuw nsw i32 %59, 1\l  %61 = uitofp i32 %60 to float\l  %62 = load i32, i32 addrspace(4)* %52, align 4, !tbaa !7, !amdgpu.noclobber\l... !5\l  %63 = and i32 %62, 32768\l  %64 = icmp eq i32 %63, 0\l  %65 = select i1 %64, float %55, float 1.000000e+00\l  %66 = select i1 %64, float %61, float 1.000000e+00\l  %67 = getelementptr inbounds i32, i32 addrspace(4)* %51, i64 14\l  %68 = load i32, i32 addrspace(4)* %67, align 4, !tbaa !7, !amdgpu.noclobber\l... !5\l  %69 = and i32 %68, 1048576\l  %70 = icmp eq i32 %69, 0\l  %71 = bitcast i32 addrspace(4)* %52 to \<4 x i32\> addrspace(4)*\l  %72 = load \<4 x i32\>, \<4 x i32\> addrspace(4)* %71, align 16, !tbaa !11,\l... !amdgpu.noclobber !5\l  %73 = bitcast %struct.__hip_texture addrspace(1)* %3 to \<8 x i32\>\l... addrspace(1)*\l  %74 = addrspacecast \<8 x i32\> addrspace(1)* %73 to \<8 x i32\> addrspace(4)*\l  %75 = load \<8 x i32\>, \<8 x i32\> addrspace(4)* %74, align 32, !tbaa !11,\l... !amdgpu.noclobber !5\l  %76 = tail call float @llvm.amdgcn.rcp.f32(float %66)\l  %77 = fmul float %49, %66\l  %78 = tail call float @llvm.floor.f32(float %77)\l  %79 = fmul float %76, %78\l  %80 = select i1 %70, float %79, float %49\l  %81 = tail call float @llvm.amdgcn.rcp.f32(float %65)\l  %82 = fmul float %45, %65\l  %83 = tail call float @llvm.floor.f32(float %82)\l  %84 = fmul float %81, %83\l  %85 = select i1 %70, float %84, float %45\l  %86 = tail call \<2 x float\> @llvm.amdgcn.image.sample.lz.2d.v2f32.f32(i32 3,\l... float %85, float %80, \<8 x i32\> %75, \<4 x i32\> %72, i1 false, i32 0, i32 0)\l  %87 = extractelement \<2 x float\> %86, i64 0\l  %88 = extractelement \<2 x float\> %86, i64 1\l  %89 = fadd contract float %46, 2.000000e+00\l  %90 = fadd contract float %89, 5.000000e-01\l  %91 = fdiv contract float %90, %48\l  %92 = fmul float %66, %91\l  %93 = tail call float @llvm.floor.f32(float %92)\l  %94 = fmul float %76, %93\l  %95 = select i1 %70, float %94, float %91\l  %96 = fadd contract float %42, 2.000000e+00\l  %97 = fadd contract float %96, 5.000000e-01\l  %98 = fdiv contract float %97, %44\l  %99 = fmul float %65, %98\l  %100 = tail call float @llvm.floor.f32(float %99)\l  %101 = fmul float %81, %100\l  %102 = select i1 %70, float %101, float %98\l  %103 = tail call \<2 x float\> @llvm.amdgcn.image.sample.lz.2d.v2f32.f32(i32\l... 3, float %102, float %95, \<8 x i32\> %75, \<4 x i32\> %72, i1 false, i32 0, i32\l... 0)\l  %104 = extractelement \<2 x float\> %103, i64 0\l  %105 = tail call float @llvm.maxnum.f32(float %104, float %87)\l  %106 = tail call float @llvm.minnum.f32(float %104, float %87)\l  %107 = fmul contract float %87, 5.000000e-01\l  %108 = tail call float @llvm.round.f32(float %107)\l  %109 = fptosi float %108 to i32\l  %110 = fmul contract float %88, 5.000000e-01\l  %111 = tail call float @llvm.round.f32(float %110)\l  %112 = fptosi float %111 to i32\l  %113 = bitcast %struct.HIP_vector_type addrspace(1)* %0 to i8 addrspace(1)*\l  %114 = zext i32 %20 to i64\l  %115 = add nuw nsw i32 %31, 3\l  %116 = add nsw i32 %20, %109\l  %117 = bitcast %struct.HIP_vector_type addrspace(1)* %1 to i8 addrspace(1)*\l  %118 = add nsw i32 %28, -1\l  %119 = mul nsw i32 %118, %6\l  %120 = sext i32 %119 to i64\l  %121 = getelementptr inbounds i8, i8 addrspace(1)* %113, i64 %120\l  %122 = bitcast i8 addrspace(1)* %121 to %struct.HIP_vector_type addrspace(1)*\l  %123 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %122, i64 %114\l  %124 = add i32 %118, %112\l  %125 = tail call i32 @llvm.smax.i32(i32 %124, i32 0)\l  %126 = tail call i32 @llvm.smin.i32(i32 %125, i32 %35)\l  %127 = mul nsw i32 %126, %6\l  %128 = sext i32 %127 to i64\l  %129 = getelementptr inbounds i8, i8 addrspace(1)* %117, i64 %128\l  %130 = bitcast i8 addrspace(1)* %129 to %struct.HIP_vector_type addrspace(1)*\l  %131 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %123, i64 -1\l  %132 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %131, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %133 = load float, float addrspace(1)* %132, align 4, !amdgpu.noclobber !5\l  %134 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %131, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 1\l  %135 = load float, float addrspace(1)* %134, align 4, !amdgpu.noclobber !5\l  %136 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %131, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 2\l  %137 = load float, float addrspace(1)* %136, align 4, !amdgpu.noclobber !5\l  %138 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %31, i32 0, i32\l... 0, i32 0, i32 0, i32 0\l  store float %133, float addrspace(3)* %138, align 4\l  %139 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %31, i32 0, i32\l... 0, i32 0, i32 0, i32 1\l  store float %135, float addrspace(3)* %139, align 4\l  %140 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %31, i32 0, i32\l... 0, i32 0, i32 0, i32 2\l  store float %137, float addrspace(3)* %140, align 4\l  %141 = fadd contract float %133, 0.000000e+00\l  %142 = fadd contract float %135, 0.000000e+00\l  %143 = fadd contract float %137, 0.000000e+00\l  %144 = tail call i32 @llvm.smax.i32(i32 %116, i32 1)\l  %145 = add nsw i32 %144, -1\l  %146 = tail call i32 @llvm.smin.i32(i32 %145, i32 %32)\l  %147 = sext i32 %146 to i64\l  %148 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %149 = load float, float addrspace(1)* %148, align 4, !amdgpu.noclobber !5\l  %150 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %151 = load float, float addrspace(1)* %150, align 4, !amdgpu.noclobber !5\l  %152 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %153 = load float, float addrspace(1)* %152, align 4, !amdgpu.noclobber !5\l  %154 = fadd contract float %149, 0.000000e+00\l  %155 = fadd contract float %151, 0.000000e+00\l  %156 = fadd contract float %153, 0.000000e+00\l  %157 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %123, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %158 = load float, float addrspace(1)* %157, align 4, !amdgpu.noclobber !5\l  %159 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %122, i64 %114, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %160 = load float, float addrspace(1)* %159, align 4, !amdgpu.noclobber !5\l  %161 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %122, i64 %114, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %162 = load float, float addrspace(1)* %161, align 4, !amdgpu.noclobber !5\l  %163 = add nuw nsw i32 %31, 1\l  %164 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %163, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %158, float addrspace(3)* %164, align 4\l  %165 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %163, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %160, float addrspace(3)* %165, align 4\l  %166 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %163, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %162, float addrspace(3)* %166, align 4\l  %167 = fadd contract float %141, %158\l  %168 = fadd contract float %142, %160\l  %169 = fadd contract float %143, %162\l  %170 = tail call i32 @llvm.smax.i32(i32 %116, i32 0)\l  %171 = tail call i32 @llvm.smin.i32(i32 %170, i32 %32)\l  %172 = sext i32 %171 to i64\l  %173 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %174 = load float, float addrspace(1)* %173, align 4, !amdgpu.noclobber !5\l  %175 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %176 = load float, float addrspace(1)* %175, align 4, !amdgpu.noclobber !5\l  %177 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %178 = load float, float addrspace(1)* %177, align 4, !amdgpu.noclobber !5\l  %179 = fadd contract float %154, %174\l  %180 = fadd contract float %155, %176\l  %181 = fadd contract float %156, %178\l  %182 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %123, i64 1\l  %183 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %182, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %184 = load float, float addrspace(1)* %183, align 4, !amdgpu.noclobber !5\l  %185 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %182, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 1\l  %186 = load float, float addrspace(1)* %185, align 4, !amdgpu.noclobber !5\l  %187 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %182, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 2\l  %188 = load float, float addrspace(1)* %187, align 4, !amdgpu.noclobber !5\l  %189 = add nuw nsw i32 %31, 2\l  %190 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %189, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %184, float addrspace(3)* %190, align 4\l  %191 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %189, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %186, float addrspace(3)* %191, align 4\l  %192 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %189, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %188, float addrspace(3)* %192, align 4\l  %193 = fadd contract float %167, %184\l  %194 = fadd contract float %168, %186\l  %195 = fadd contract float %169, %188\l  %196 = tail call i32 @llvm.smax.i32(i32 %116, i32 -1)\l  %197 = add nsw i32 %196, 1\l  %198 = tail call i32 @llvm.smin.i32(i32 %197, i32 %32)\l  %199 = sext i32 %198 to i64\l  %200 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %201 = load float, float addrspace(1)* %200, align 4, !amdgpu.noclobber !5\l  %202 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %203 = load float, float addrspace(1)* %202, align 4, !amdgpu.noclobber !5\l  %204 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %130, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %205 = load float, float addrspace(1)* %204, align 4, !amdgpu.noclobber !5\l  %206 = fadd contract float %179, %201\l  %207 = fadd contract float %180, %203\l  %208 = fadd contract float %181, %205\l  %209 = mul nsw i32 %28, %6\l  %210 = sext i32 %209 to i64\l  %211 = getelementptr inbounds i8, i8 addrspace(1)* %113, i64 %210\l  %212 = bitcast i8 addrspace(1)* %211 to %struct.HIP_vector_type addrspace(1)*\l  %213 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %212, i64 %114\l  %214 = add i32 %28, %112\l  %215 = tail call i32 @llvm.smax.i32(i32 %214, i32 0)\l  %216 = tail call i32 @llvm.smin.i32(i32 %215, i32 %35)\l  %217 = mul nsw i32 %216, %6\l  %218 = sext i32 %217 to i64\l  %219 = getelementptr inbounds i8, i8 addrspace(1)* %117, i64 %218\l  %220 = bitcast i8 addrspace(1)* %219 to %struct.HIP_vector_type addrspace(1)*\l  %221 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %213, i64 -1\l  %222 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %221, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %223 = load float, float addrspace(1)* %222, align 4, !amdgpu.noclobber !5\l  %224 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %221, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 1\l  %225 = load float, float addrspace(1)* %224, align 4, !amdgpu.noclobber !5\l  %226 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %221, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 2\l  %227 = load float, float addrspace(1)* %226, align 4, !amdgpu.noclobber !5\l  %228 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %115, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %223, float addrspace(3)* %228, align 4\l  %229 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %115, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %225, float addrspace(3)* %229, align 4\l  %230 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %115, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %227, float addrspace(3)* %230, align 4\l  %231 = fadd contract float %193, %223\l  %232 = fadd contract float %194, %225\l  %233 = fadd contract float %195, %227\l  %234 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %235 = load float, float addrspace(1)* %234, align 4, !amdgpu.noclobber !5\l  %236 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %237 = load float, float addrspace(1)* %236, align 4, !amdgpu.noclobber !5\l  %238 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %239 = load float, float addrspace(1)* %238, align 4, !amdgpu.noclobber !5\l  %240 = fadd contract float %206, %235\l  %241 = fadd contract float %207, %237\l  %242 = fadd contract float %208, %239\l  %243 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %213, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %244 = load float, float addrspace(1)* %243, align 4, !amdgpu.noclobber !5\l  %245 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %212, i64 %114, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %246 = load float, float addrspace(1)* %245, align 4, !amdgpu.noclobber !5\l  %247 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %212, i64 %114, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %248 = load float, float addrspace(1)* %247, align 4, !amdgpu.noclobber !5\l  %249 = add nuw nsw i32 %31, 4\l  %250 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %249, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %244, float addrspace(3)* %250, align 4\l  %251 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %249, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %246, float addrspace(3)* %251, align 4\l  %252 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %249, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %248, float addrspace(3)* %252, align 4\l  %253 = fadd contract float %231, %244\l  %254 = fadd contract float %232, %246\l  %255 = fadd contract float %233, %248\l  %256 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %257 = load float, float addrspace(1)* %256, align 4, !amdgpu.noclobber !5\l  %258 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %259 = load float, float addrspace(1)* %258, align 4, !amdgpu.noclobber !5\l  %260 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %261 = load float, float addrspace(1)* %260, align 4, !amdgpu.noclobber !5\l  %262 = fadd contract float %240, %257\l  %263 = fadd contract float %241, %259\l  %264 = fadd contract float %242, %261\l  %265 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %213, i64 1\l  %266 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %265, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %267 = load float, float addrspace(1)* %266, align 4, !amdgpu.noclobber !5\l  %268 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %265, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 1\l  %269 = load float, float addrspace(1)* %268, align 4, !amdgpu.noclobber !5\l  %270 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %265, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 2\l  %271 = load float, float addrspace(1)* %270, align 4, !amdgpu.noclobber !5\l  %272 = add nuw nsw i32 %31, 5\l  %273 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %272, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %267, float addrspace(3)* %273, align 4\l  %274 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %272, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %269, float addrspace(3)* %274, align 4\l  %275 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %272, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %271, float addrspace(3)* %275, align 4\l  %276 = fadd contract float %253, %267\l  %277 = fadd contract float %254, %269\l  %278 = fadd contract float %255, %271\l  %279 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %280 = load float, float addrspace(1)* %279, align 4, !amdgpu.noclobber !5\l  %281 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %282 = load float, float addrspace(1)* %281, align 4, !amdgpu.noclobber !5\l  %283 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %220, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %284 = load float, float addrspace(1)* %283, align 4, !amdgpu.noclobber !5\l  %285 = fadd contract float %262, %280\l  %286 = fadd contract float %263, %282\l  %287 = fadd contract float %264, %284\l  %288 = add nuw nsw i32 %28, 1\l  %289 = mul nsw i32 %288, %6\l  %290 = sext i32 %289 to i64\l  %291 = getelementptr inbounds i8, i8 addrspace(1)* %113, i64 %290\l  %292 = bitcast i8 addrspace(1)* %291 to %struct.HIP_vector_type addrspace(1)*\l  %293 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %292, i64 %114\l  %294 = add nuw nsw i32 %31, 6\l  %295 = add i32 %288, %112\l  %296 = tail call i32 @llvm.smax.i32(i32 %295, i32 0)\l  %297 = tail call i32 @llvm.smin.i32(i32 %296, i32 %35)\l  %298 = mul nsw i32 %297, %6\l  %299 = sext i32 %298 to i64\l  %300 = getelementptr inbounds i8, i8 addrspace(1)* %117, i64 %299\l  %301 = bitcast i8 addrspace(1)* %300 to %struct.HIP_vector_type addrspace(1)*\l  %302 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %293, i64 -1\l  %303 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %302, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %304 = load float, float addrspace(1)* %303, align 4, !amdgpu.noclobber !5\l  %305 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %302, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 1\l  %306 = load float, float addrspace(1)* %305, align 4, !amdgpu.noclobber !5\l  %307 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %302, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 2\l  %308 = load float, float addrspace(1)* %307, align 4, !amdgpu.noclobber !5\l  %309 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %294, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %304, float addrspace(3)* %309, align 4\l  %310 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %294, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %306, float addrspace(3)* %310, align 4\l  %311 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %294, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %308, float addrspace(3)* %311, align 4\l  %312 = fadd contract float %276, %304\l  %313 = fadd contract float %277, %306\l  %314 = fadd contract float %278, %308\l  %315 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %316 = load float, float addrspace(1)* %315, align 4, !amdgpu.noclobber !5\l  %317 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %318 = load float, float addrspace(1)* %317, align 4, !amdgpu.noclobber !5\l  %319 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %147, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %320 = load float, float addrspace(1)* %319, align 4, !amdgpu.noclobber !5\l  %321 = fadd contract float %285, %316\l  %322 = fadd contract float %286, %318\l  %323 = fadd contract float %287, %320\l  %324 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %293, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %325 = load float, float addrspace(1)* %324, align 4, !amdgpu.noclobber !5\l  %326 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %292, i64 %114, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %327 = load float, float addrspace(1)* %326, align 4, !amdgpu.noclobber !5\l  %328 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %292, i64 %114, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %329 = load float, float addrspace(1)* %328, align 4, !amdgpu.noclobber !5\l  %330 = add nuw nsw i32 %31, 7\l  %331 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %330, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %325, float addrspace(3)* %331, align 4\l  %332 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %330, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %327, float addrspace(3)* %332, align 4\l  %333 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %330, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %329, float addrspace(3)* %333, align 4\l  %334 = fadd contract float %312, %325\l  %335 = fadd contract float %313, %327\l  %336 = fadd contract float %314, %329\l  %337 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %338 = load float, float addrspace(1)* %337, align 4, !amdgpu.noclobber !5\l  %339 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %340 = load float, float addrspace(1)* %339, align 4, !amdgpu.noclobber !5\l  %341 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %172, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %342 = load float, float addrspace(1)* %341, align 4, !amdgpu.noclobber !5\l  %343 = fadd contract float %321, %338\l  %344 = fadd contract float %322, %340\l  %345 = fadd contract float %323, %342\l  %346 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %293, i64 1\l  %347 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %346, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 0\l  %348 = load float, float addrspace(1)* %347, align 4, !amdgpu.noclobber !5\l  %349 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %346, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 1\l  %350 = load float, float addrspace(1)* %349, align 4, !amdgpu.noclobber !5\l  %351 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %346, i64 0, i32 0, i32 0, i32 0, i32\l... 0, i64 2\l  %352 = load float, float addrspace(1)* %351, align 4, !amdgpu.noclobber !5\l  %353 = add nuw nsw i32 %31, 8\l  %354 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %353, i32 0,\l... i32 0, i32 0, i32 0, i32 0\l  store float %348, float addrspace(3)* %354, align 4\l  %355 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %353, i32 0,\l... i32 0, i32 0, i32 0, i32 1\l  store float %350, float addrspace(3)* %355, align 4\l  %356 = getelementptr inbounds [0 x %struct.HIP_vector_type], [0 x\l... %struct.HIP_vector_type] addrspace(3)* @pixelsRef, i32 0, i32 %353, i32 0,\l... i32 0, i32 0, i32 0, i32 2\l  store float %352, float addrspace(3)* %356, align 4\l  %357 = fadd contract float %334, %348\l  %358 = fadd contract float %335, %350\l  %359 = fadd contract float %336, %352\l  %360 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 0\l  %361 = load float, float addrspace(1)* %360, align 4, !amdgpu.noclobber !5\l  %362 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 1\l  %363 = load float, float addrspace(1)* %362, align 4, !amdgpu.noclobber !5\l  %364 = getelementptr inbounds %struct.HIP_vector_type,\l... %struct.HIP_vector_type addrspace(1)* %301, i64 %199, i32 0, i32 0, i32 0,\l... i32 0, i64 2\l  %365 = load float, float addrspace(1)* %364, align 4, !amdgpu.noclobber !5\l  %366 = fadd contract float %343, %361\l  %367 = fadd contract float %344, %363\l  %368 = fadd contract float %345, %365\l  %369 = extractelement \<2 x float\> %103, i64 1\l  %370 = tail call float @llvm.maxnum.f32(float %369, float %88)\l  %371 = tail call float @llvm.minnum.f32(float %369, float %88)\l  %372 = fdiv contract float %357, 9.000000e+00\l  %373 = fdiv contract float %358, 9.000000e+00\l  %374 = fdiv contract float %359, 9.000000e+00\l  %375 = fdiv contract float %366, 9.000000e+00\l  %376 = fdiv contract float %367, 9.000000e+00\l  %377 = fdiv contract float %368, 9.000000e+00\l  %378 = fsub contract float %372, %375\l  %379 = tail call float @llvm.fabs.f32(float %378)\l  %380 = fsub contract float %373, %376\l  %381 = tail call float @llvm.fabs.f32(float %380)\l  %382 = fadd contract float %379, %381\l  %383 = fsub contract float %374, %377\l  %384 = tail call float @llvm.fabs.f32(float %383)\l  %385 = fadd contract float %382, %384\l  %386 = fdiv contract float %385, 3.000000e+00\l  %387 = fmul contract float %386, 5.000000e-01\l  %388 = fmul contract float %105, %387\l  %389 = fmul contract float %370, %387\l  %390 = fmul contract float %106, %387\l  %391 = fmul contract float %371, %387\l  %392 = fsub contract float %388, %390\l  %393 = fmul contract float %392, %392\l  %394 = fsub contract float %389, %391\l  %395 = fmul contract float %394, %394\l  %396 = fadd contract float %393, %395\l  %397 = fcmp olt float %396, 0x39F0000000000000\l  %398 = select i1 %397, float 0x41F0000000000000, float 1.000000e+00\l  %399 = fmul float %396, %398\l  %400 = tail call float @llvm.sqrt.f32(float %399)\l  %401 = bitcast float %400 to i32\l  %402 = add nsw i32 %401, -1\l  %403 = bitcast i32 %402 to float\l  %404 = add nsw i32 %401, 1\l  %405 = bitcast i32 %404 to float\l  %406 = select i1 %397, float 0x3EF0000000000000, float 1.000000e+00\l  %407 = fneg float %405\l  %408 = tail call float @llvm.fma.f32(float %407, float %400, float %399)\l  %409 = fcmp ogt float %408, 0.000000e+00\l  %410 = fneg float %403\l  %411 = tail call float @llvm.fma.f32(float %410, float %400, float %399)\l  %412 = fcmp ole float %411, 0.000000e+00\l  %413 = select i1 %412, float %403, float %400\l  %414 = select i1 %409, float %405, float %413\l  %415 = fmul float %406, %414\l  %416 = load float, float addrspace(3)* %138, align 4, !tbaa !12\l  %417 = fsub contract float %416, %372\l  %418 = fmul contract float %417, %417\l  %419 = fadd contract float %418, 0.000000e+00\l  %420 = load float, float addrspace(3)* %139, align 4, !tbaa !12\l  %421 = fsub contract float %420, %373\l  %422 = fmul contract float %421, %421\l  %423 = fadd contract float %422, 0.000000e+00\l  %424 = load float, float addrspace(3)* %140, align 4, !tbaa !12\l  %425 = fsub contract float %424, %374\l  %426 = fmul contract float %425, %425\l  %427 = fadd contract float %426, 0.000000e+00\l  %428 = load float, float addrspace(3)* %164, align 4, !tbaa !12\l  %429 = fsub contract float %428, %372\l  %430 = fmul contract float %429, %429\l  %431 = fadd contract float %419, %430\l  %432 = load float, float addrspace(3)* %165, align 4, !tbaa !12\l  %433 = fsub contract float %432, %373\l  %434 = fmul contract float %433, %433\l  %435 = fadd contract float %423, %434\l  %436 = load float, float addrspace(3)* %166, align 4, !tbaa !12\l  %437 = fsub contract float %436, %374\l  %438 = fmul contract float %437, %437\l  %439 = fadd contract float %427, %438\l  %440 = load float, float addrspace(3)* %190, align 4, !tbaa !12\l  %441 = fsub contract float %440, %372\l  %442 = fmul contract float %441, %441\l  %443 = fadd contract float %431, %442\l  %444 = load float, float addrspace(3)* %191, align 4, !tbaa !12\l  %445 = fsub contract float %444, %373\l  %446 = fmul contract float %445, %445\l  %447 = fadd contract float %435, %446\l  %448 = load float, float addrspace(3)* %192, align 4, !tbaa !12\l  %449 = fsub contract float %448, %374\l  %450 = fmul contract float %449, %449\l  %451 = fadd contract float %439, %450\l  %452 = load float, float addrspace(3)* %228, align 4, !tbaa !12\l  %453 = fsub contract float %452, %372\l  %454 = fmul contract float %453, %453\l  %455 = fadd contract float %443, %454\l  %456 = load float, float addrspace(3)* %229, align 4, !tbaa !12\l  %457 = fsub contract float %456, %373\l  %458 = fmul contract float %457, %457\l  %459 = fadd contract float %447, %458\l  %460 = load float, float addrspace(3)* %230, align 4, !tbaa !12\l  %461 = fsub contract float %460, %374\l  %462 = fmul contract float %461, %461\l  %463 = fadd contract float %451, %462\l  %464 = load float, float addrspace(3)* %250, align 4, !tbaa !12\l  %465 = fsub contract float %464, %372\l  %466 = fmul contract float %465, %465\l  %467 = fadd contract float %455, %466\l  %468 = load float, float addrspace(3)* %251, align 4, !tbaa !12\l  %469 = fsub contract float %468, %373\l  %470 = fmul contract float %469, %469\l  %471 = fadd contract float %459, %470\l  %472 = load float, float addrspace(3)* %252, align 4, !tbaa !12\l  %473 = fsub contract float %472, %374\l  %474 = fmul contract float %473, %473\l  %475 = fadd contract float %463, %474\l  %476 = load float, float addrspace(3)* %273, align 4, !tbaa !12\l  %477 = fsub contract float %476, %372\l  %478 = fmul contract float %477, %477\l  %479 = fadd contract float %467, %478\l  %480 = load float, float addrspace(3)* %274, align 4, !tbaa !12\l  %481 = fsub contract float %480, %373\l  %482 = fmul contract float %481, %481\l  %483 = fadd contract float %471, %482\l  %484 = load float, float addrspace(3)* %275, align 4, !tbaa !12\l  %485 = fsub contract float %484, %374\l  %486 = fmul contract float %485, %485\l  %487 = fadd contract float %475, %486\l  %488 = load float, float addrspace(3)* %309, align 4, !tbaa !12\l  %489 = fsub contract float %488, %372\l  %490 = fmul contract float %489, %489\l  %491 = fadd contract float %479, %490\l  %492 = load float, float addrspace(3)* %310, align 4, !tbaa !12\l  %493 = fsub contract float %492, %373\l  %494 = fmul contract float %493, %493\l  %495 = fadd contract float %483, %494\l  %496 = load float, float addrspace(3)* %311, align 4, !tbaa !12\l  %497 = fsub contract float %496, %374\l  %498 = fmul contract float %497, %497\l  %499 = fadd contract float %487, %498\l  %500 = load float, float addrspace(3)* %331, align 4, !tbaa !12\l  %501 = fsub contract float %500, %372\l  %502 = fmul contract float %501, %501\l  %503 = fadd contract float %491, %502\l  %504 = load float, float addrspace(3)* %332, align 4, !tbaa !12\l  %505 = fsub contract float %504, %373\l  %506 = fmul contract float %505, %505\l  %507 = fadd contract float %495, %506\l  %508 = load float, float addrspace(3)* %333, align 4, !tbaa !12\l  %509 = fsub contract float %508, %374\l  %510 = fmul contract float %509, %509\l  %511 = fadd contract float %499, %510\l  %512 = load float, float addrspace(3)* %354, align 4, !tbaa !12\l  %513 = fsub contract float %512, %372\l  %514 = fmul contract float %513, %513\l  %515 = fadd contract float %503, %514\l  %516 = load float, float addrspace(3)* %355, align 4, !tbaa !12\l  %517 = fsub contract float %516, %373\l  %518 = fmul contract float %517, %517\l  %519 = fadd contract float %507, %518\l  %520 = load float, float addrspace(3)* %356, align 4, !tbaa !12\l  %521 = fsub contract float %520, %374\l  %522 = fmul contract float %521, %521\l  %523 = fadd contract float %511, %522\l  %524 = tail call i1 @llvm.amdgcn.class.f32(float %399, i32 608)\l  %525 = select i1 %524, float %399, float %415\l  %526 = fdiv contract float %515, 9.000000e+00\l  %527 = fcmp olt float %526, 0x39F0000000000000\l  %528 = select i1 %527, float 0x41F0000000000000, float 1.000000e+00\l  %529 = fmul float %526, %528\l  %530 = tail call float @llvm.sqrt.f32(float %529)\l  %531 = bitcast float %530 to i32\l  %532 = add nsw i32 %531, -1\l  %533 = bitcast i32 %532 to float\l  %534 = add nsw i32 %531, 1\l  %535 = bitcast i32 %534 to float\l  %536 = tail call i1 @llvm.amdgcn.class.f32(float %529, i32 608)\l  %537 = select i1 %527, float 0x3EF0000000000000, float 1.000000e+00\l  %538 = fneg float %535\l  %539 = tail call float @llvm.fma.f32(float %538, float %530, float %529)\l  %540 = fcmp ogt float %539, 0.000000e+00\l  %541 = fneg float %533\l  %542 = tail call float @llvm.fma.f32(float %541, float %530, float %529)\l  %543 = fcmp ole float %542, 0.000000e+00\l  %544 = select i1 %543, float %533, float %530\l  %545 = select i1 %540, float %535, float %544\l  %546 = fmul float %537, %545\l  %547 = select i1 %536, float %529, float %546\l  %548 = fdiv contract float %519, 9.000000e+00\l  %549 = fcmp olt float %548, 0x39F0000000000000\l  %550 = select i1 %549, float 0x41F0000000000000, float 1.000000e+00\l  %551 = fmul float %548, %550\l  %552 = tail call float @llvm.sqrt.f32(float %551)\l  %553 = bitcast float %552 to i32\l  %554 = add nsw i32 %553, -1\l  %555 = bitcast i32 %554 to float\l  %556 = add nsw i32 %553, 1\l  %557 = bitcast i32 %556 to float\l  %558 = tail call i1 @llvm.amdgcn.class.f32(float %551, i32 608)\l  %559 = select i1 %549, float 0x3EF0000000000000, float 1.000000e+00\l  %560 = fneg float %557\l  %561 = tail call float @llvm.fma.f32(float %560, float %552, float %551)\l  %562 = fcmp ogt float %561, 0.000000e+00\l  %563 = fneg float %555\l  %564 = tail call float @llvm.fma.f32(float %563, float %552, float %551)\l  %565 = fcmp ole float %564, 0.000000e+00\l  %566 = select i1 %565, float %555, float %552\l  %567 = select i1 %562, float %557, float %566\l  %568 = fmul float %559, %567\l  %569 = select i1 %558, float %551, float %568\l  %570 = fdiv contract float %523, 9.000000e+00\l  %571 = fcmp olt float %570, 0x39F0000000000000\l  %572 = select i1 %571, float 0x41F0000000000000, float 1.000000e+00\l  %573 = fmul float %570, %572\l  %574 = tail call float @llvm.sqrt.f32(float %573)\l  %575 = bitcast float %574 to i32\l  %576 = add nsw i32 %575, -1\l  %577 = bitcast i32 %576 to float\l  %578 = add nsw i32 %575, 1\l  %579 = bitcast i32 %578 to float\l  %580 = tail call i1 @llvm.amdgcn.class.f32(float %573, i32 608)\l  %581 = select i1 %571, float 0x3EF0000000000000, float 1.000000e+00\l  %582 = fneg float %579\l  %583 = tail call float @llvm.fma.f32(float %582, float %574, float %573)\l  %584 = fcmp ogt float %583, 0.000000e+00\l  %585 = fneg float %577\l  %586 = tail call float @llvm.fma.f32(float %585, float %574, float %573)\l  %587 = fcmp ole float %586, 0.000000e+00\l  %588 = select i1 %587, float %577, float %574\l  %589 = select i1 %584, float %579, float %588\l  %590 = fmul float %581, %589\l  %591 = select i1 %580, float %573, float %590\l  %592 = fmul contract float %372, %8\l  %593 = fadd contract float %592, %9\l  %594 = fcmp olt float %593, 0x39F0000000000000\l  %595 = select i1 %594, float 0x41F0000000000000, float 1.000000e+00\l  %596 = fmul float %593, %595\l  %597 = tail call float @llvm.sqrt.f32(float %596)\l  %598 = bitcast float %597 to i32\l  %599 = add nsw i32 %598, -1\l  %600 = bitcast i32 %599 to float\l  %601 = add nsw i32 %598, 1\l  %602 = bitcast i32 %601 to float\l  %603 = tail call i1 @llvm.amdgcn.class.f32(float %596, i32 608)\l  %604 = select i1 %594, float 0x3EF0000000000000, float 1.000000e+00\l  %605 = fneg float %602\l  %606 = tail call float @llvm.fma.f32(float %605, float %597, float %596)\l  %607 = fcmp ogt float %606, 0.000000e+00\l  %608 = fneg float %600\l  %609 = tail call float @llvm.fma.f32(float %608, float %597, float %596)\l  %610 = fcmp ole float %609, 0.000000e+00\l  %611 = select i1 %610, float %600, float %597\l  %612 = select i1 %607, float %602, float %611\l  %613 = fmul float %604, %612\l  %614 = select i1 %603, float %596, float %613\l  %615 = fmul contract float %373, %8\l  %616 = fadd contract float %615, %9\l  %617 = fcmp olt float %616, 0x39F0000000000000\l  %618 = select i1 %617, float 0x41F0000000000000, float 1.000000e+00\l  %619 = fmul float %616, %618\l  %620 = tail call float @llvm.sqrt.f32(float %619)\l  %621 = bitcast float %620 to i32\l  %622 = add nsw i32 %621, -1\l  %623 = bitcast i32 %622 to float\l  %624 = add nsw i32 %621, 1\l  %625 = bitcast i32 %624 to float\l  %626 = tail call i1 @llvm.amdgcn.class.f32(float %619, i32 608)\l  %627 = select i1 %617, float 0x3EF0000000000000, float 1.000000e+00\l  %628 = fneg float %625\l  %629 = tail call float @llvm.fma.f32(float %628, float %620, float %619)\l  %630 = fcmp ogt float %629, 0.000000e+00\l  %631 = fneg float %623\l  %632 = tail call float @llvm.fma.f32(float %631, float %620, float %619)\l  %633 = fcmp ole float %632, 0.000000e+00\l  %634 = select i1 %633, float %623, float %620\l  %635 = select i1 %630, float %625, float %634\l  %636 = fmul float %627, %635\l  %637 = select i1 %626, float %619, float %636\l  %638 = fdiv contract float %637, 0x3FF6A09E60000000\l  %639 = fmul contract float %374, %8\l  %640 = fadd contract float %639, %9\l  %641 = fcmp olt float %640, 0x39F0000000000000\l  %642 = select i1 %641, float 0x41F0000000000000, float 1.000000e+00\l  %643 = fmul float %640, %642\l  %644 = tail call float @llvm.sqrt.f32(float %643)\l  %645 = bitcast float %644 to i32\l  %646 = add nsw i32 %645, -1\l  %647 = bitcast i32 %646 to float\l  %648 = add nsw i32 %645, 1\l  %649 = bitcast i32 %648 to float\l  %650 = tail call i1 @llvm.amdgcn.class.f32(float %643, i32 608)\l  %651 = select i1 %641, float 0x3EF0000000000000, float 1.000000e+00\l  %652 = fneg float %649\l  %653 = tail call float @llvm.fma.f32(float %652, float %644, float %643)\l  %654 = fcmp ogt float %653, 0.000000e+00\l  %655 = fneg float %647\l  %656 = tail call float @llvm.fma.f32(float %655, float %644, float %643)\l  %657 = fcmp ole float %656, 0.000000e+00\l  %658 = select i1 %657, float %647, float %644\l  %659 = select i1 %654, float %649, float %658\l  %660 = fmul float %651, %659\l  %661 = select i1 %650, float %643, float %660\l  %662 = tail call float @llvm.maxnum.f32(float %614, float %547)\l  %663 = tail call float @llvm.maxnum.f32(float %638, float %569)\l  %664 = tail call float @llvm.maxnum.f32(float %661, float %591)\l  %665 = fmul contract float %547, %547\l  %666 = fmul contract float %614, %614\l  %667 = fadd contract float %666, %665\l  %668 = fdiv contract float %665, %667\l  %669 = fmul contract float %379, %668\l  %670 = fmul contract float %569, %569\l  %671 = fmul contract float %638, %638\l  %672 = fadd contract float %671, %670\l  %673 = fdiv contract float %670, %672\l  %674 = fmul contract float %381, %673\l  %675 = fmul contract float %591, %591\l  %676 = fmul contract float %661, %661\l  %677 = fadd contract float %676, %675\l  %678 = fdiv contract float %675, %677\l  %679 = fmul contract float %384, %678\l  %680 = fcmp contract ogt float %525, %10\l  %681 = select i1 %680, float 0.000000e+00, float 1.500000e+00\l  %682 = fneg contract float %669\l  %683 = fmul contract float %669, %682\l  %684 = fmul contract float %662, %662\l  %685 = fdiv contract float %683, %684\l  %686 = fmul float %685, 0x3FF7154760000000\l  %687 = tail call float @llvm.rint.f32(float %686)\l  %688 = fcmp ogt float %685, 0x40562E4300000000\l  %689 = fcmp olt float %685, 0xC059D1DA00000000\l  %690 = fneg float %686\l  %691 = tail call float @llvm.fma.f32(float %685, float 0x3FF7154760000000,\l... float %690)\l  %692 = tail call float @llvm.fma.f32(float %685, float 0x3E54AE0BE0000000,\l... float %691)\l  %693 = fsub float %686, %687\l  %694 = fadd float %692, %693\l  %695 = tail call float @llvm.exp2.f32(float %694)\l  %696 = fptosi float %687 to i32\l  %697 = tail call float @llvm.amdgcn.ldexp.f32(float %695, i32 %696)\l  %698 = select i1 %689, float 0.000000e+00, float %697\l  %699 = select i1 %688, float 0x7FF0000000000000, float %698\l  %700 = fmul contract float %681, %699\l  %701 = fadd contract float %700, 0xBFBEB851E0000000\l  %702 = tail call float @llvm.minnum.f32(float %701, float 1.000000e+00)\l  %703 = tail call float @llvm.maxnum.f32(float %702, float 0.000000e+00)\l  %704 = fneg contract float %674\l  %705 = fmul contract float %674, %704\l  %706 = fmul contract float %663, %663\l  %707 = fdiv contract float %705, %706\l  %708 = fmul float %707, 0x3FF7154760000000\l  %709 = tail call float @llvm.rint.f32(float %708)\l  %710 = fcmp ogt float %707, 0x40562E4300000000\l  %711 = fcmp olt float %707, 0xC059D1DA00000000\l  %712 = fneg float %708\l  %713 = tail call float @llvm.fma.f32(float %707, float 0x3FF7154760000000,\l... float %712)\l  %714 = tail call float @llvm.fma.f32(float %707, float 0x3E54AE0BE0000000,\l... float %713)\l  %715 = fsub float %708, %709\l  %716 = fadd float %714, %715\l  %717 = tail call float @llvm.exp2.f32(float %716)\l  %718 = fptosi float %709 to i32\l  %719 = tail call float @llvm.amdgcn.ldexp.f32(float %717, i32 %718)\l  %720 = select i1 %711, float 0.000000e+00, float %719\l  %721 = select i1 %710, float 0x7FF0000000000000, float %720\l  %722 = fmul contract float %681, %721\l  %723 = fadd contract float %722, 0xBFBEB851E0000000\l  %724 = tail call float @llvm.minnum.f32(float %723, float 1.000000e+00)\l  %725 = tail call float @llvm.maxnum.f32(float %724, float 0.000000e+00)\l  %726 = fneg contract float %679\l  %727 = fmul contract float %679, %726\l  %728 = fmul contract float %664, %664\l  %729 = fdiv contract float %727, %728\l  %730 = fmul float %729, 0x3FF7154760000000\l  %731 = tail call float @llvm.rint.f32(float %730)\l  %732 = fcmp ogt float %729, 0x40562E4300000000\l  %733 = fcmp olt float %729, 0xC059D1DA00000000\l  %734 = fneg float %730\l  %735 = tail call float @llvm.fma.f32(float %729, float 0x3FF7154760000000,\l... float %734)\l  %736 = tail call float @llvm.fma.f32(float %729, float 0x3E54AE0BE0000000,\l... float %735)\l  %737 = fsub float %730, %731\l  %738 = fadd float %736, %737\l  %739 = tail call float @llvm.exp2.f32(float %738)\l  %740 = fptosi float %731 to i32\l  %741 = tail call float @llvm.amdgcn.ldexp.f32(float %739, i32 %740)\l  %742 = select i1 %733, float 0.000000e+00, float %741\l  %743 = select i1 %732, float 0x7FF0000000000000, float %742\l  %744 = fmul contract float %681, %743\l  %745 = fadd contract float %744, 0xBFBEB851E0000000\l  %746 = tail call float @llvm.minnum.f32(float %745, float 1.000000e+00)\l  %747 = tail call float @llvm.maxnum.f32(float %746, float 0.000000e+00)\l  %748 = bitcast %struct.HIP_vector_type.0 addrspace(1)* %2 to i8 addrspace(1)*\l  %749 = mul nsw i32 %28, %7\l  %750 = sext i32 %749 to i64\l  %751 = getelementptr inbounds i8, i8 addrspace(1)* %748, i64 %750\l  %752 = bitcast i8 addrspace(1)* %751 to %struct.HIP_vector_type.0\l... addrspace(1)*\l  %753 = getelementptr inbounds %struct.HIP_vector_type.0,\l... %struct.HIP_vector_type.0 addrspace(1)* %752, i64 %114, i32 0, i32 0, i32 0,\l... i64 0\l  store float %703, float addrspace(1)* %753, align 16\l  %754 = getelementptr inbounds %struct.HIP_vector_type.0,\l... %struct.HIP_vector_type.0 addrspace(1)* %752, i64 %114, i32 0, i32 0, i32 0,\l... i64 1\l  store float %725, float addrspace(1)* %754, align 4\l  %755 = getelementptr inbounds %struct.HIP_vector_type.0,\l... %struct.HIP_vector_type.0 addrspace(1)* %752, i64 %114, i32 0, i32 0, i32 0,\l... i64 2\l  store float %747, float addrspace(1)* %755, align 8\l  %756 = getelementptr inbounds %struct.HIP_vector_type.0,\l... %struct.HIP_vector_type.0 addrspace(1)* %752, i64 %114, i32 0, i32 0, i32 0,\l... i64 3\l  store float %525, float addrspace(1)* %756, align 4\l  br label %757\l}"];
	Node0x48baa60 -> Node0x48ba570;
	Node0x48ba570 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%757:\l757:                                              \l  ret void\l}"];
}
