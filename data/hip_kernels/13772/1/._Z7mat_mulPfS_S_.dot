digraph "CFG for '_Z7mat_mulPfS_S_' function" {
	label="CFG for '_Z7mat_mulPfS_S_' function";

	Node0x5794f00 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%3:\l  %4 = tail call i32 @llvm.amdgcn.workgroup.id.x()\l  %5 = tail call i32 @llvm.amdgcn.workgroup.id.y()\l  %6 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !4\l  %7 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !4\l  %8 = shl i32 %4, 11\l  %9 = shl nuw nsw i32 %6, 7\l  %10 = add nuw nsw i32 %9, %7\l  %11 = add i32 %10, %8\l  %12 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 %7\l  %13 = shl nsw i32 %5, 4\l  %14 = add nsw i32 %13, %7\l  %15 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 %6, i32 %7\l  %16 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 0\l  %17 = sext i32 %11 to i64\l  %18 = getelementptr inbounds float, float addrspace(1)* %0, i64 %17\l  %19 = load float, float addrspace(1)* %18, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %19, float addrspace(3)* %12, align 4, !tbaa !5\l  %20 = shl nuw nsw i32 %6, 6\l  %21 = add nsw i32 %14, %20\l  %22 = sext i32 %21 to i64\l  %23 = getelementptr inbounds float, float addrspace(1)* %1, i64 %22\l  %24 = load float, float addrspace(1)* %23, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %24, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %25 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %26 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 0, i32 %7\l  %27 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %28 = fmul contract float %25, %27\l  %29 = fadd contract float %28, 0.000000e+00\l  %30 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 1\l  %31 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %32 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 1, i32 %7\l  %33 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %34 = fmul contract float %31, %33\l  %35 = fadd contract float %29, %34\l  %36 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 2\l  %37 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %38 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 2, i32 %7\l  %39 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %40 = fmul contract float %37, %39\l  %41 = fadd contract float %35, %40\l  %42 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 3\l  %43 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %44 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 3, i32 %7\l  %45 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %46 = fmul contract float %43, %45\l  %47 = fadd contract float %41, %46\l  %48 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 4\l  %49 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %50 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 4, i32 %7\l  %51 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %52 = fmul contract float %49, %51\l  %53 = fadd contract float %47, %52\l  %54 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 5\l  %55 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %56 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 5, i32 %7\l  %57 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %58 = fmul contract float %55, %57\l  %59 = fadd contract float %53, %58\l  %60 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 6\l  %61 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %62 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 6, i32 %7\l  %63 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %64 = fmul contract float %61, %63\l  %65 = fadd contract float %59, %64\l  %66 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 7\l  %67 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %68 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 7, i32 %7\l  %69 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %70 = fmul contract float %67, %69\l  %71 = fadd contract float %65, %70\l  %72 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 8\l  %73 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %74 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 8, i32 %7\l  %75 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %76 = fmul contract float %73, %75\l  %77 = fadd contract float %71, %76\l  %78 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 9\l  %79 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %80 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 9, i32 %7\l  %81 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %82 = fmul contract float %79, %81\l  %83 = fadd contract float %77, %82\l  %84 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 10\l  %85 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %86 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 10, i32 %7\l  %87 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %88 = fmul contract float %85, %87\l  %89 = fadd contract float %83, %88\l  %90 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 11\l  %91 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %92 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 11, i32 %7\l  %93 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %94 = fmul contract float %91, %93\l  %95 = fadd contract float %89, %94\l  %96 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 12\l  %97 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %98 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 12, i32 %7\l  %99 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %100 = fmul contract float %97, %99\l  %101 = fadd contract float %95, %100\l  %102 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 13\l  %103 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %104 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 13, i32 %7\l  %105 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %106 = fmul contract float %103, %105\l  %107 = fadd contract float %101, %106\l  %108 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 14\l  %109 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %110 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 14, i32 %7\l  %111 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %112 = fmul contract float %109, %111\l  %113 = fadd contract float %107, %112\l  %114 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2As, i32 0, i32 %6, i32 15\l  %115 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %116 = getelementptr inbounds [16 x [16 x float]], [16 x [16 x float]]\l... addrspace(3)* @_ZZ7mat_mulPfS_S_E2Bs, i32 0, i32 15, i32 %7\l  %117 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %118 = fmul contract float %115, %117\l  %119 = fadd contract float %113, %118\l  %120 = add i32 %11, 16\l  %121 = sext i32 %120 to i64\l  %122 = getelementptr inbounds float, float addrspace(1)* %0, i64 %121\l  %123 = load float, float addrspace(1)* %122, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %123, float addrspace(3)* %12, align 4, !tbaa !5\l  %124 = shl nuw nsw i32 %6, 6\l  %125 = add nuw nsw i32 %124, 1024\l  %126 = add nsw i32 %14, %125\l  %127 = sext i32 %126 to i64\l  %128 = getelementptr inbounds float, float addrspace(1)* %1, i64 %127\l  %129 = load float, float addrspace(1)* %128, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %129, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %130 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %131 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %132 = fmul contract float %130, %131\l  %133 = fadd contract float %119, %132\l  %134 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %135 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %136 = fmul contract float %134, %135\l  %137 = fadd contract float %133, %136\l  %138 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %139 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %140 = fmul contract float %138, %139\l  %141 = fadd contract float %137, %140\l  %142 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %143 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %144 = fmul contract float %142, %143\l  %145 = fadd contract float %141, %144\l  %146 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %147 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %148 = fmul contract float %146, %147\l  %149 = fadd contract float %145, %148\l  %150 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %151 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %152 = fmul contract float %150, %151\l  %153 = fadd contract float %149, %152\l  %154 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %155 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %156 = fmul contract float %154, %155\l  %157 = fadd contract float %153, %156\l  %158 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %159 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %160 = fmul contract float %158, %159\l  %161 = fadd contract float %157, %160\l  %162 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %163 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %164 = fmul contract float %162, %163\l  %165 = fadd contract float %161, %164\l  %166 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %167 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %168 = fmul contract float %166, %167\l  %169 = fadd contract float %165, %168\l  %170 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %171 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %172 = fmul contract float %170, %171\l  %173 = fadd contract float %169, %172\l  %174 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %175 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %176 = fmul contract float %174, %175\l  %177 = fadd contract float %173, %176\l  %178 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %179 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %180 = fmul contract float %178, %179\l  %181 = fadd contract float %177, %180\l  %182 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %183 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %184 = fmul contract float %182, %183\l  %185 = fadd contract float %181, %184\l  %186 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %187 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %188 = fmul contract float %186, %187\l  %189 = fadd contract float %185, %188\l  %190 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %191 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %192 = fmul contract float %190, %191\l  %193 = fadd contract float %189, %192\l  %194 = add i32 %11, 32\l  %195 = sext i32 %194 to i64\l  %196 = getelementptr inbounds float, float addrspace(1)* %0, i64 %195\l  %197 = load float, float addrspace(1)* %196, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %197, float addrspace(3)* %12, align 4, !tbaa !5\l  %198 = shl nuw nsw i32 %6, 6\l  %199 = add nuw nsw i32 %198, 2048\l  %200 = add nsw i32 %14, %199\l  %201 = sext i32 %200 to i64\l  %202 = getelementptr inbounds float, float addrspace(1)* %1, i64 %201\l  %203 = load float, float addrspace(1)* %202, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %203, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %204 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %205 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %206 = fmul contract float %204, %205\l  %207 = fadd contract float %193, %206\l  %208 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %209 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %210 = fmul contract float %208, %209\l  %211 = fadd contract float %207, %210\l  %212 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %213 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %214 = fmul contract float %212, %213\l  %215 = fadd contract float %211, %214\l  %216 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %217 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %218 = fmul contract float %216, %217\l  %219 = fadd contract float %215, %218\l  %220 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %221 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %222 = fmul contract float %220, %221\l  %223 = fadd contract float %219, %222\l  %224 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %225 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %226 = fmul contract float %224, %225\l  %227 = fadd contract float %223, %226\l  %228 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %229 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %230 = fmul contract float %228, %229\l  %231 = fadd contract float %227, %230\l  %232 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %233 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %234 = fmul contract float %232, %233\l  %235 = fadd contract float %231, %234\l  %236 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %237 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %238 = fmul contract float %236, %237\l  %239 = fadd contract float %235, %238\l  %240 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %241 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %242 = fmul contract float %240, %241\l  %243 = fadd contract float %239, %242\l  %244 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %245 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %246 = fmul contract float %244, %245\l  %247 = fadd contract float %243, %246\l  %248 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %249 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %250 = fmul contract float %248, %249\l  %251 = fadd contract float %247, %250\l  %252 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %253 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %254 = fmul contract float %252, %253\l  %255 = fadd contract float %251, %254\l  %256 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %257 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %258 = fmul contract float %256, %257\l  %259 = fadd contract float %255, %258\l  %260 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %261 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %262 = fmul contract float %260, %261\l  %263 = fadd contract float %259, %262\l  %264 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %265 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %266 = fmul contract float %264, %265\l  %267 = fadd contract float %263, %266\l  %268 = add i32 %11, 48\l  %269 = sext i32 %268 to i64\l  %270 = getelementptr inbounds float, float addrspace(1)* %0, i64 %269\l  %271 = load float, float addrspace(1)* %270, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %271, float addrspace(3)* %12, align 4, !tbaa !5\l  %272 = shl nuw nsw i32 %6, 6\l  %273 = add nuw nsw i32 %272, 3072\l  %274 = add nsw i32 %14, %273\l  %275 = sext i32 %274 to i64\l  %276 = getelementptr inbounds float, float addrspace(1)* %1, i64 %275\l  %277 = load float, float addrspace(1)* %276, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %277, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %278 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %279 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %280 = fmul contract float %278, %279\l  %281 = fadd contract float %267, %280\l  %282 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %283 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %284 = fmul contract float %282, %283\l  %285 = fadd contract float %281, %284\l  %286 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %287 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %288 = fmul contract float %286, %287\l  %289 = fadd contract float %285, %288\l  %290 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %291 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %292 = fmul contract float %290, %291\l  %293 = fadd contract float %289, %292\l  %294 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %295 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %296 = fmul contract float %294, %295\l  %297 = fadd contract float %293, %296\l  %298 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %299 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %300 = fmul contract float %298, %299\l  %301 = fadd contract float %297, %300\l  %302 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %303 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %304 = fmul contract float %302, %303\l  %305 = fadd contract float %301, %304\l  %306 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %307 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %308 = fmul contract float %306, %307\l  %309 = fadd contract float %305, %308\l  %310 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %311 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %312 = fmul contract float %310, %311\l  %313 = fadd contract float %309, %312\l  %314 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %315 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %316 = fmul contract float %314, %315\l  %317 = fadd contract float %313, %316\l  %318 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %319 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %320 = fmul contract float %318, %319\l  %321 = fadd contract float %317, %320\l  %322 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %323 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %324 = fmul contract float %322, %323\l  %325 = fadd contract float %321, %324\l  %326 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %327 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %328 = fmul contract float %326, %327\l  %329 = fadd contract float %325, %328\l  %330 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %331 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %332 = fmul contract float %330, %331\l  %333 = fadd contract float %329, %332\l  %334 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %335 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %336 = fmul contract float %334, %335\l  %337 = fadd contract float %333, %336\l  %338 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %339 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %340 = fmul contract float %338, %339\l  %341 = fadd contract float %337, %340\l  %342 = add i32 %11, 64\l  %343 = sext i32 %342 to i64\l  %344 = getelementptr inbounds float, float addrspace(1)* %0, i64 %343\l  %345 = load float, float addrspace(1)* %344, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %345, float addrspace(3)* %12, align 4, !tbaa !5\l  %346 = shl nuw nsw i32 %6, 6\l  %347 = add nuw nsw i32 %346, 4096\l  %348 = add nsw i32 %14, %347\l  %349 = sext i32 %348 to i64\l  %350 = getelementptr inbounds float, float addrspace(1)* %1, i64 %349\l  %351 = load float, float addrspace(1)* %350, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %351, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %352 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %353 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %354 = fmul contract float %352, %353\l  %355 = fadd contract float %341, %354\l  %356 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %357 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %358 = fmul contract float %356, %357\l  %359 = fadd contract float %355, %358\l  %360 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %361 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %362 = fmul contract float %360, %361\l  %363 = fadd contract float %359, %362\l  %364 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %365 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %366 = fmul contract float %364, %365\l  %367 = fadd contract float %363, %366\l  %368 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %369 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %370 = fmul contract float %368, %369\l  %371 = fadd contract float %367, %370\l  %372 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %373 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %374 = fmul contract float %372, %373\l  %375 = fadd contract float %371, %374\l  %376 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %377 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %378 = fmul contract float %376, %377\l  %379 = fadd contract float %375, %378\l  %380 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %381 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %382 = fmul contract float %380, %381\l  %383 = fadd contract float %379, %382\l  %384 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %385 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %386 = fmul contract float %384, %385\l  %387 = fadd contract float %383, %386\l  %388 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %389 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %390 = fmul contract float %388, %389\l  %391 = fadd contract float %387, %390\l  %392 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %393 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %394 = fmul contract float %392, %393\l  %395 = fadd contract float %391, %394\l  %396 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %397 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %398 = fmul contract float %396, %397\l  %399 = fadd contract float %395, %398\l  %400 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %401 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %402 = fmul contract float %400, %401\l  %403 = fadd contract float %399, %402\l  %404 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %405 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %406 = fmul contract float %404, %405\l  %407 = fadd contract float %403, %406\l  %408 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %409 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %410 = fmul contract float %408, %409\l  %411 = fadd contract float %407, %410\l  %412 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %413 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %414 = fmul contract float %412, %413\l  %415 = fadd contract float %411, %414\l  %416 = add i32 %11, 80\l  %417 = sext i32 %416 to i64\l  %418 = getelementptr inbounds float, float addrspace(1)* %0, i64 %417\l  %419 = load float, float addrspace(1)* %418, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %419, float addrspace(3)* %12, align 4, !tbaa !5\l  %420 = shl nuw nsw i32 %6, 6\l  %421 = add nuw nsw i32 %420, 5120\l  %422 = add nsw i32 %14, %421\l  %423 = sext i32 %422 to i64\l  %424 = getelementptr inbounds float, float addrspace(1)* %1, i64 %423\l  %425 = load float, float addrspace(1)* %424, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %425, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %426 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %427 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %428 = fmul contract float %426, %427\l  %429 = fadd contract float %415, %428\l  %430 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %431 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %432 = fmul contract float %430, %431\l  %433 = fadd contract float %429, %432\l  %434 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %435 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %436 = fmul contract float %434, %435\l  %437 = fadd contract float %433, %436\l  %438 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %439 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %440 = fmul contract float %438, %439\l  %441 = fadd contract float %437, %440\l  %442 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %443 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %444 = fmul contract float %442, %443\l  %445 = fadd contract float %441, %444\l  %446 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %447 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %448 = fmul contract float %446, %447\l  %449 = fadd contract float %445, %448\l  %450 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %451 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %452 = fmul contract float %450, %451\l  %453 = fadd contract float %449, %452\l  %454 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %455 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %456 = fmul contract float %454, %455\l  %457 = fadd contract float %453, %456\l  %458 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %459 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %460 = fmul contract float %458, %459\l  %461 = fadd contract float %457, %460\l  %462 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %463 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %464 = fmul contract float %462, %463\l  %465 = fadd contract float %461, %464\l  %466 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %467 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %468 = fmul contract float %466, %467\l  %469 = fadd contract float %465, %468\l  %470 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %471 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %472 = fmul contract float %470, %471\l  %473 = fadd contract float %469, %472\l  %474 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %475 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %476 = fmul contract float %474, %475\l  %477 = fadd contract float %473, %476\l  %478 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %479 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %480 = fmul contract float %478, %479\l  %481 = fadd contract float %477, %480\l  %482 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %483 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %484 = fmul contract float %482, %483\l  %485 = fadd contract float %481, %484\l  %486 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %487 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %488 = fmul contract float %486, %487\l  %489 = fadd contract float %485, %488\l  %490 = add i32 %11, 96\l  %491 = sext i32 %490 to i64\l  %492 = getelementptr inbounds float, float addrspace(1)* %0, i64 %491\l  %493 = load float, float addrspace(1)* %492, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %493, float addrspace(3)* %12, align 4, !tbaa !5\l  %494 = shl nuw nsw i32 %6, 6\l  %495 = add nuw nsw i32 %494, 6144\l  %496 = add nsw i32 %14, %495\l  %497 = sext i32 %496 to i64\l  %498 = getelementptr inbounds float, float addrspace(1)* %1, i64 %497\l  %499 = load float, float addrspace(1)* %498, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %499, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %500 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %501 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %502 = fmul contract float %500, %501\l  %503 = fadd contract float %489, %502\l  %504 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %505 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %506 = fmul contract float %504, %505\l  %507 = fadd contract float %503, %506\l  %508 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %509 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %510 = fmul contract float %508, %509\l  %511 = fadd contract float %507, %510\l  %512 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %513 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %514 = fmul contract float %512, %513\l  %515 = fadd contract float %511, %514\l  %516 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %517 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %518 = fmul contract float %516, %517\l  %519 = fadd contract float %515, %518\l  %520 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %521 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %522 = fmul contract float %520, %521\l  %523 = fadd contract float %519, %522\l  %524 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %525 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %526 = fmul contract float %524, %525\l  %527 = fadd contract float %523, %526\l  %528 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %529 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %530 = fmul contract float %528, %529\l  %531 = fadd contract float %527, %530\l  %532 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %533 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %534 = fmul contract float %532, %533\l  %535 = fadd contract float %531, %534\l  %536 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %537 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %538 = fmul contract float %536, %537\l  %539 = fadd contract float %535, %538\l  %540 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %541 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %542 = fmul contract float %540, %541\l  %543 = fadd contract float %539, %542\l  %544 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %545 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %546 = fmul contract float %544, %545\l  %547 = fadd contract float %543, %546\l  %548 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %549 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %550 = fmul contract float %548, %549\l  %551 = fadd contract float %547, %550\l  %552 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %553 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %554 = fmul contract float %552, %553\l  %555 = fadd contract float %551, %554\l  %556 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %557 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %558 = fmul contract float %556, %557\l  %559 = fadd contract float %555, %558\l  %560 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %561 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %562 = fmul contract float %560, %561\l  %563 = fadd contract float %559, %562\l  %564 = add i32 %11, 112\l  %565 = sext i32 %564 to i64\l  %566 = getelementptr inbounds float, float addrspace(1)* %0, i64 %565\l  %567 = load float, float addrspace(1)* %566, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %567, float addrspace(3)* %12, align 4, !tbaa !5\l  %568 = shl nuw nsw i32 %6, 6\l  %569 = add nuw nsw i32 %568, 7168\l  %570 = add nsw i32 %14, %569\l  %571 = sext i32 %570 to i64\l  %572 = getelementptr inbounds float, float addrspace(1)* %1, i64 %571\l  %573 = load float, float addrspace(1)* %572, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  store float %573, float addrspace(3)* %15, align 4, !tbaa !5\l  fence syncscope(\"workgroup\") release\l  tail call void @llvm.amdgcn.s.barrier()\l  fence syncscope(\"workgroup\") acquire\l  %574 = load float, float addrspace(3)* %16, align 16, !tbaa !5\l  %575 = load float, float addrspace(3)* %26, align 4, !tbaa !5\l  %576 = fmul contract float %574, %575\l  %577 = fadd contract float %563, %576\l  %578 = load float, float addrspace(3)* %30, align 4, !tbaa !5\l  %579 = load float, float addrspace(3)* %32, align 4, !tbaa !5\l  %580 = fmul contract float %578, %579\l  %581 = fadd contract float %577, %580\l  %582 = load float, float addrspace(3)* %36, align 8, !tbaa !5\l  %583 = load float, float addrspace(3)* %38, align 4, !tbaa !5\l  %584 = fmul contract float %582, %583\l  %585 = fadd contract float %581, %584\l  %586 = load float, float addrspace(3)* %42, align 4, !tbaa !5\l  %587 = load float, float addrspace(3)* %44, align 4, !tbaa !5\l  %588 = fmul contract float %586, %587\l  %589 = fadd contract float %585, %588\l  %590 = load float, float addrspace(3)* %48, align 16, !tbaa !5\l  %591 = load float, float addrspace(3)* %50, align 4, !tbaa !5\l  %592 = fmul contract float %590, %591\l  %593 = fadd contract float %589, %592\l  %594 = load float, float addrspace(3)* %54, align 4, !tbaa !5\l  %595 = load float, float addrspace(3)* %56, align 4, !tbaa !5\l  %596 = fmul contract float %594, %595\l  %597 = fadd contract float %593, %596\l  %598 = load float, float addrspace(3)* %60, align 8, !tbaa !5\l  %599 = load float, float addrspace(3)* %62, align 4, !tbaa !5\l  %600 = fmul contract float %598, %599\l  %601 = fadd contract float %597, %600\l  %602 = load float, float addrspace(3)* %66, align 4, !tbaa !5\l  %603 = load float, float addrspace(3)* %68, align 4, !tbaa !5\l  %604 = fmul contract float %602, %603\l  %605 = fadd contract float %601, %604\l  %606 = load float, float addrspace(3)* %72, align 16, !tbaa !5\l  %607 = load float, float addrspace(3)* %74, align 4, !tbaa !5\l  %608 = fmul contract float %606, %607\l  %609 = fadd contract float %605, %608\l  %610 = load float, float addrspace(3)* %78, align 4, !tbaa !5\l  %611 = load float, float addrspace(3)* %80, align 4, !tbaa !5\l  %612 = fmul contract float %610, %611\l  %613 = fadd contract float %609, %612\l  %614 = load float, float addrspace(3)* %84, align 8, !tbaa !5\l  %615 = load float, float addrspace(3)* %86, align 4, !tbaa !5\l  %616 = fmul contract float %614, %615\l  %617 = fadd contract float %613, %616\l  %618 = load float, float addrspace(3)* %90, align 4, !tbaa !5\l  %619 = load float, float addrspace(3)* %92, align 4, !tbaa !5\l  %620 = fmul contract float %618, %619\l  %621 = fadd contract float %617, %620\l  %622 = load float, float addrspace(3)* %96, align 16, !tbaa !5\l  %623 = load float, float addrspace(3)* %98, align 4, !tbaa !5\l  %624 = fmul contract float %622, %623\l  %625 = fadd contract float %621, %624\l  %626 = load float, float addrspace(3)* %102, align 4, !tbaa !5\l  %627 = load float, float addrspace(3)* %104, align 4, !tbaa !5\l  %628 = fmul contract float %626, %627\l  %629 = fadd contract float %625, %628\l  %630 = load float, float addrspace(3)* %108, align 8, !tbaa !5\l  %631 = load float, float addrspace(3)* %110, align 4, !tbaa !5\l  %632 = fmul contract float %630, %631\l  %633 = fadd contract float %629, %632\l  %634 = load float, float addrspace(3)* %114, align 4, !tbaa !5\l  %635 = load float, float addrspace(3)* %116, align 4, !tbaa !5\l  %636 = fmul contract float %634, %635\l  %637 = fadd contract float %633, %636\l  %638 = shl i32 %4, 10\l  %639 = add nuw nsw i32 %20, %7\l  %640 = add i32 %639, %638\l  %641 = add i32 %640, %13\l  %642 = sext i32 %641 to i64\l  %643 = getelementptr inbounds float, float addrspace(1)* %2, i64 %642\l  store float %637, float addrspace(1)* %643, align 4, !tbaa !5\l  ret void\l}"];
}
