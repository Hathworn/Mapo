; ModuleID = '../data/hip_kernels/2884/16/main.cu'
source_filename = "../data/hip_kernels/2884/16/main.cu"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@_ZZ6Match2PfS_S_PiE7buffer1 = internal unnamed_addr addrspace(3) global [2048 x float] undef, align 16
@_ZZ6Match2PfS_S_PiE7buffer2 = internal unnamed_addr addrspace(3) global [2048 x float] undef, align 16
@_ZZ6Match2PfS_S_PiE6scores = internal unnamed_addr addrspace(3) global [256 x float] undef, align 16

; Function Attrs: convergent mustprogress norecurse nounwind
define protected amdgpu_kernel void @_Z6Match2PfS_S_Pi(float addrspace(1)* nocapture readonly %0, float addrspace(1)* nocapture readonly %1, float addrspace(1)* nocapture writeonly %2, i32 addrspace(1)* nocapture writeonly %3) local_unnamed_addr #0 {
  %5 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !4
  %6 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !4
  %7 = shl nuw nsw i32 %6, 4
  %8 = add nuw nsw i32 %7, %5
  %9 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %10 = shl i32 %9, 4
  %11 = icmp ult i32 %6, 16
  %12 = icmp ult i32 %5, 128
  %13 = select i1 %11, i1 %12, i1 false
  br i1 %13, label %14, label %87

14:                                               ; preds = %4
  %15 = add nsw i32 %6, %10
  %16 = shl nsw i32 %15, 7
  %17 = shl nuw nsw i32 %6, 7
  %18 = add nuw nsw i32 %16, %5
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds float, float addrspace(1)* %0, i64 %19
  %21 = load float, float addrspace(1)* %20, align 4, !tbaa !5, !amdgpu.noclobber !9
  %22 = add nuw nsw i32 %17, %5
  %23 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %22
  store float %21, float addrspace(3)* %23, align 4, !tbaa !5
  %24 = add nuw nsw i32 %5, 16
  %25 = icmp ult i32 %5, 112
  br i1 %25, label %26, label %87, !llvm.loop !10

26:                                               ; preds = %14
  %27 = add nuw nsw i32 %16, %24
  %28 = sext i32 %27 to i64
  %29 = getelementptr inbounds float, float addrspace(1)* %0, i64 %28
  %30 = load float, float addrspace(1)* %29, align 4, !tbaa !5, !amdgpu.noclobber !9
  %31 = add nuw nsw i32 %17, %24
  %32 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %31
  store float %30, float addrspace(3)* %32, align 4, !tbaa !5
  %33 = add nuw nsw i32 %5, 32
  %34 = icmp ult i32 %5, 96
  br i1 %34, label %35, label %87, !llvm.loop !10

35:                                               ; preds = %26
  %36 = add nuw nsw i32 %16, %33
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds float, float addrspace(1)* %0, i64 %37
  %39 = load float, float addrspace(1)* %38, align 4, !tbaa !5, !amdgpu.noclobber !9
  %40 = add nuw nsw i32 %17, %33
  %41 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %40
  store float %39, float addrspace(3)* %41, align 4, !tbaa !5
  %42 = add nuw nsw i32 %5, 48
  %43 = icmp ult i32 %5, 80
  br i1 %43, label %44, label %87, !llvm.loop !10

44:                                               ; preds = %35
  %45 = add nuw nsw i32 %16, %42
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds float, float addrspace(1)* %0, i64 %46
  %48 = load float, float addrspace(1)* %47, align 4, !tbaa !5, !amdgpu.noclobber !9
  %49 = add nuw nsw i32 %17, %42
  %50 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %49
  store float %48, float addrspace(3)* %50, align 4, !tbaa !5
  %51 = add nuw nsw i32 %5, 64
  %52 = icmp ult i32 %5, 64
  br i1 %52, label %53, label %87, !llvm.loop !10

53:                                               ; preds = %44
  %54 = add nuw nsw i32 %16, %51
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds float, float addrspace(1)* %0, i64 %55
  %57 = load float, float addrspace(1)* %56, align 4, !tbaa !5, !amdgpu.noclobber !9
  %58 = add nuw nsw i32 %17, %51
  %59 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %58
  store float %57, float addrspace(3)* %59, align 4, !tbaa !5
  %60 = add nuw nsw i32 %5, 80
  %61 = icmp ult i32 %5, 48
  br i1 %61, label %62, label %87, !llvm.loop !10

62:                                               ; preds = %53
  %63 = add nuw nsw i32 %16, %60
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float addrspace(1)* %0, i64 %64
  %66 = load float, float addrspace(1)* %65, align 4, !tbaa !5, !amdgpu.noclobber !9
  %67 = add nuw nsw i32 %17, %60
  %68 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %67
  store float %66, float addrspace(3)* %68, align 4, !tbaa !5
  %69 = add nuw nsw i32 %5, 96
  %70 = icmp ult i32 %5, 32
  br i1 %70, label %71, label %87, !llvm.loop !10

71:                                               ; preds = %62
  %72 = add nuw nsw i32 %16, %69
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float addrspace(1)* %0, i64 %73
  %75 = load float, float addrspace(1)* %74, align 4, !tbaa !5, !amdgpu.noclobber !9
  %76 = add nuw nsw i32 %17, %69
  %77 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %76
  store float %75, float addrspace(3)* %77, align 4, !tbaa !5
  %78 = add nuw nsw i32 %5, 112
  %79 = icmp ult i32 %5, 16
  br i1 %79, label %80, label %87, !llvm.loop !10

80:                                               ; preds = %71
  %81 = add nuw nsw i32 %16, %78
  %82 = sext i32 %81 to i64
  %83 = getelementptr inbounds float, float addrspace(1)* %0, i64 %82
  %84 = load float, float addrspace(1)* %83, align 4, !tbaa !5, !amdgpu.noclobber !9
  %85 = add nuw nsw i32 %17, %78
  %86 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %85
  store float %84, float addrspace(3)* %86, align 4, !tbaa !5
  br label %87

87:                                               ; preds = %14, %26, %35, %44, %53, %62, %71, %80, %4
  fence syncscope("workgroup") release
  tail call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  %88 = shl nuw nsw i32 %5, 7
  %89 = shl nuw nsw i32 %6, 7
  %90 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %8
  %91 = icmp eq i32 %6, 0
  %92 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %88
  %93 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %89
  %94 = add nuw nsw i32 %88, 1
  %95 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %94
  %96 = add nuw nsw i32 %89, 1
  %97 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %96
  %98 = add nuw nsw i32 %88, 2
  %99 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %98
  %100 = add nuw nsw i32 %89, 2
  %101 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %100
  %102 = add nuw nsw i32 %88, 3
  %103 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %102
  %104 = add nuw nsw i32 %89, 3
  %105 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %104
  %106 = add nuw nsw i32 %88, 4
  %107 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %106
  %108 = add nuw nsw i32 %89, 4
  %109 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %108
  %110 = add nuw nsw i32 %88, 5
  %111 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %110
  %112 = add nuw nsw i32 %89, 5
  %113 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %112
  %114 = add nuw nsw i32 %88, 6
  %115 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %114
  %116 = add nuw nsw i32 %89, 6
  %117 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %116
  %118 = add nuw nsw i32 %88, 7
  %119 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %118
  %120 = add nuw nsw i32 %89, 7
  %121 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %120
  %122 = add nuw nsw i32 %88, 8
  %123 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %122
  %124 = add nuw nsw i32 %89, 8
  %125 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %124
  %126 = add nuw nsw i32 %88, 9
  %127 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %126
  %128 = add nuw nsw i32 %89, 9
  %129 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %128
  %130 = add nuw nsw i32 %88, 10
  %131 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %130
  %132 = add nuw nsw i32 %89, 10
  %133 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %132
  %134 = add nuw nsw i32 %88, 11
  %135 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %134
  %136 = add nuw nsw i32 %89, 11
  %137 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %136
  %138 = add nuw nsw i32 %88, 12
  %139 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %138
  %140 = add nuw nsw i32 %89, 12
  %141 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %140
  %142 = add nuw nsw i32 %88, 13
  %143 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %142
  %144 = add nuw nsw i32 %89, 13
  %145 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %144
  %146 = add nuw nsw i32 %88, 14
  %147 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %146
  %148 = add nuw nsw i32 %89, 14
  %149 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %148
  %150 = add nuw nsw i32 %88, 15
  %151 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %150
  %152 = add nuw nsw i32 %89, 15
  %153 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %152
  %154 = add nuw nsw i32 %88, 16
  %155 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %154
  %156 = add nuw nsw i32 %89, 16
  %157 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %156
  %158 = add nuw nsw i32 %88, 17
  %159 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %158
  %160 = add nuw nsw i32 %89, 17
  %161 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %160
  %162 = add nuw nsw i32 %88, 18
  %163 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %162
  %164 = add nuw nsw i32 %89, 18
  %165 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %164
  %166 = add nuw nsw i32 %88, 19
  %167 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %166
  %168 = add nuw nsw i32 %89, 19
  %169 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %168
  %170 = add nuw nsw i32 %88, 20
  %171 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %170
  %172 = add nuw nsw i32 %89, 20
  %173 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %172
  %174 = add nuw nsw i32 %88, 21
  %175 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %174
  %176 = add nuw nsw i32 %89, 21
  %177 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %176
  %178 = add nuw nsw i32 %88, 22
  %179 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %178
  %180 = add nuw nsw i32 %89, 22
  %181 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %180
  %182 = add nuw nsw i32 %88, 23
  %183 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %182
  %184 = add nuw nsw i32 %89, 23
  %185 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %184
  %186 = add nuw nsw i32 %88, 24
  %187 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %186
  %188 = add nuw nsw i32 %89, 24
  %189 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %188
  %190 = add nuw nsw i32 %88, 25
  %191 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %190
  %192 = add nuw nsw i32 %89, 25
  %193 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %192
  %194 = add nuw nsw i32 %88, 26
  %195 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %194
  %196 = add nuw nsw i32 %89, 26
  %197 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %196
  %198 = add nuw nsw i32 %88, 27
  %199 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %198
  %200 = add nuw nsw i32 %89, 27
  %201 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %200
  %202 = add nuw nsw i32 %88, 28
  %203 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %202
  %204 = add nuw nsw i32 %89, 28
  %205 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %204
  %206 = add nuw nsw i32 %88, 29
  %207 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %206
  %208 = add nuw nsw i32 %89, 29
  %209 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %208
  %210 = add nuw nsw i32 %88, 30
  %211 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %210
  %212 = add nuw nsw i32 %89, 30
  %213 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %212
  %214 = add nuw nsw i32 %88, 31
  %215 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %214
  %216 = add nuw nsw i32 %89, 31
  %217 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %216
  %218 = add nuw nsw i32 %88, 32
  %219 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %218
  %220 = add nuw nsw i32 %89, 32
  %221 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %220
  %222 = add nuw nsw i32 %88, 33
  %223 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %222
  %224 = add nuw nsw i32 %89, 33
  %225 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %224
  %226 = add nuw nsw i32 %88, 34
  %227 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %226
  %228 = add nuw nsw i32 %89, 34
  %229 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %228
  %230 = add nuw nsw i32 %88, 35
  %231 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %230
  %232 = add nuw nsw i32 %89, 35
  %233 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %232
  %234 = add nuw nsw i32 %88, 36
  %235 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %234
  %236 = add nuw nsw i32 %89, 36
  %237 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %236
  %238 = add nuw nsw i32 %88, 37
  %239 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %238
  %240 = add nuw nsw i32 %89, 37
  %241 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %240
  %242 = add nuw nsw i32 %88, 38
  %243 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %242
  %244 = add nuw nsw i32 %89, 38
  %245 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %244
  %246 = add nuw nsw i32 %88, 39
  %247 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %246
  %248 = add nuw nsw i32 %89, 39
  %249 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %248
  %250 = add nuw nsw i32 %88, 40
  %251 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %250
  %252 = add nuw nsw i32 %89, 40
  %253 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %252
  %254 = add nuw nsw i32 %88, 41
  %255 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %254
  %256 = add nuw nsw i32 %89, 41
  %257 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %256
  %258 = add nuw nsw i32 %88, 42
  %259 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %258
  %260 = add nuw nsw i32 %89, 42
  %261 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %260
  %262 = add nuw nsw i32 %88, 43
  %263 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %262
  %264 = add nuw nsw i32 %89, 43
  %265 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %264
  %266 = add nuw nsw i32 %88, 44
  %267 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %266
  %268 = add nuw nsw i32 %89, 44
  %269 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %268
  %270 = add nuw nsw i32 %88, 45
  %271 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %270
  %272 = add nuw nsw i32 %89, 45
  %273 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %272
  %274 = add nuw nsw i32 %88, 46
  %275 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %274
  %276 = add nuw nsw i32 %89, 46
  %277 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %276
  %278 = add nuw nsw i32 %88, 47
  %279 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %278
  %280 = add nuw nsw i32 %89, 47
  %281 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %280
  %282 = add nuw nsw i32 %88, 48
  %283 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %282
  %284 = add nuw nsw i32 %89, 48
  %285 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %284
  %286 = add nuw nsw i32 %88, 49
  %287 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %286
  %288 = add nuw nsw i32 %89, 49
  %289 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %288
  %290 = add nuw nsw i32 %88, 50
  %291 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %290
  %292 = add nuw nsw i32 %89, 50
  %293 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %292
  %294 = add nuw nsw i32 %88, 51
  %295 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %294
  %296 = add nuw nsw i32 %89, 51
  %297 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %296
  %298 = add nuw nsw i32 %88, 52
  %299 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %298
  %300 = add nuw nsw i32 %89, 52
  %301 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %300
  %302 = add nuw nsw i32 %88, 53
  %303 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %302
  %304 = add nuw nsw i32 %89, 53
  %305 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %304
  %306 = add nuw nsw i32 %88, 54
  %307 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %306
  %308 = add nuw nsw i32 %89, 54
  %309 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %308
  %310 = add nuw nsw i32 %88, 55
  %311 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %310
  %312 = add nuw nsw i32 %89, 55
  %313 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %312
  %314 = add nuw nsw i32 %88, 56
  %315 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %314
  %316 = add nuw nsw i32 %89, 56
  %317 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %316
  %318 = add nuw nsw i32 %88, 57
  %319 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %318
  %320 = add nuw nsw i32 %89, 57
  %321 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %320
  %322 = add nuw nsw i32 %88, 58
  %323 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %322
  %324 = add nuw nsw i32 %89, 58
  %325 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %324
  %326 = add nuw nsw i32 %88, 59
  %327 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %326
  %328 = add nuw nsw i32 %89, 59
  %329 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %328
  %330 = add nuw nsw i32 %88, 60
  %331 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %330
  %332 = add nuw nsw i32 %89, 60
  %333 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %332
  %334 = add nuw nsw i32 %88, 61
  %335 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %334
  %336 = add nuw nsw i32 %89, 61
  %337 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %336
  %338 = add nuw nsw i32 %88, 62
  %339 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %338
  %340 = add nuw nsw i32 %89, 62
  %341 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %340
  %342 = add nuw nsw i32 %88, 63
  %343 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %342
  %344 = add nuw nsw i32 %89, 63
  %345 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %344
  %346 = add nuw nsw i32 %88, 64
  %347 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %346
  %348 = add nuw nsw i32 %89, 64
  %349 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %348
  %350 = add nuw nsw i32 %88, 65
  %351 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %350
  %352 = add nuw nsw i32 %89, 65
  %353 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %352
  %354 = add nuw nsw i32 %88, 66
  %355 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %354
  %356 = add nuw nsw i32 %89, 66
  %357 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %356
  %358 = add nuw nsw i32 %88, 67
  %359 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %358
  %360 = add nuw nsw i32 %89, 67
  %361 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %360
  %362 = add nuw nsw i32 %88, 68
  %363 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %362
  %364 = add nuw nsw i32 %89, 68
  %365 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %364
  %366 = add nuw nsw i32 %88, 69
  %367 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %366
  %368 = add nuw nsw i32 %89, 69
  %369 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %368
  %370 = add nuw nsw i32 %88, 70
  %371 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %370
  %372 = add nuw nsw i32 %89, 70
  %373 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %372
  %374 = add nuw nsw i32 %88, 71
  %375 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %374
  %376 = add nuw nsw i32 %89, 71
  %377 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %376
  %378 = add nuw nsw i32 %88, 72
  %379 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %378
  %380 = add nuw nsw i32 %89, 72
  %381 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %380
  %382 = add nuw nsw i32 %88, 73
  %383 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %382
  %384 = add nuw nsw i32 %89, 73
  %385 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %384
  %386 = add nuw nsw i32 %88, 74
  %387 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %386
  %388 = add nuw nsw i32 %89, 74
  %389 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %388
  %390 = add nuw nsw i32 %88, 75
  %391 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %390
  %392 = add nuw nsw i32 %89, 75
  %393 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %392
  %394 = add nuw nsw i32 %88, 76
  %395 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %394
  %396 = add nuw nsw i32 %89, 76
  %397 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %396
  %398 = add nuw nsw i32 %88, 77
  %399 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %398
  %400 = add nuw nsw i32 %89, 77
  %401 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %400
  %402 = add nuw nsw i32 %88, 78
  %403 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %402
  %404 = add nuw nsw i32 %89, 78
  %405 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %404
  %406 = add nuw nsw i32 %88, 79
  %407 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %406
  %408 = add nuw nsw i32 %89, 79
  %409 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %408
  %410 = add nuw nsw i32 %88, 80
  %411 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %410
  %412 = add nuw nsw i32 %89, 80
  %413 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %412
  %414 = add nuw nsw i32 %88, 81
  %415 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %414
  %416 = add nuw nsw i32 %89, 81
  %417 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %416
  %418 = add nuw nsw i32 %88, 82
  %419 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %418
  %420 = add nuw nsw i32 %89, 82
  %421 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %420
  %422 = add nuw nsw i32 %88, 83
  %423 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %422
  %424 = add nuw nsw i32 %89, 83
  %425 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %424
  %426 = add nuw nsw i32 %88, 84
  %427 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %426
  %428 = add nuw nsw i32 %89, 84
  %429 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %428
  %430 = add nuw nsw i32 %88, 85
  %431 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %430
  %432 = add nuw nsw i32 %89, 85
  %433 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %432
  %434 = add nuw nsw i32 %88, 86
  %435 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %434
  %436 = add nuw nsw i32 %89, 86
  %437 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %436
  %438 = add nuw nsw i32 %88, 87
  %439 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %438
  %440 = add nuw nsw i32 %89, 87
  %441 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %440
  %442 = add nuw nsw i32 %88, 88
  %443 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %442
  %444 = add nuw nsw i32 %89, 88
  %445 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %444
  %446 = add nuw nsw i32 %88, 89
  %447 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %446
  %448 = add nuw nsw i32 %89, 89
  %449 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %448
  %450 = add nuw nsw i32 %88, 90
  %451 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %450
  %452 = add nuw nsw i32 %89, 90
  %453 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %452
  %454 = add nuw nsw i32 %88, 91
  %455 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %454
  %456 = add nuw nsw i32 %89, 91
  %457 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %456
  %458 = add nuw nsw i32 %88, 92
  %459 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %458
  %460 = add nuw nsw i32 %89, 92
  %461 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %460
  %462 = add nuw nsw i32 %88, 93
  %463 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %462
  %464 = add nuw nsw i32 %89, 93
  %465 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %464
  %466 = add nuw nsw i32 %88, 94
  %467 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %466
  %468 = add nuw nsw i32 %89, 94
  %469 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %468
  %470 = add nuw nsw i32 %88, 95
  %471 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %470
  %472 = add nuw nsw i32 %89, 95
  %473 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %472
  %474 = add nuw nsw i32 %88, 96
  %475 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %474
  %476 = add nuw nsw i32 %89, 96
  %477 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %476
  %478 = add nuw nsw i32 %88, 97
  %479 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %478
  %480 = add nuw nsw i32 %89, 97
  %481 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %480
  %482 = add nuw nsw i32 %88, 98
  %483 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %482
  %484 = add nuw nsw i32 %89, 98
  %485 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %484
  %486 = add nuw nsw i32 %88, 99
  %487 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %486
  %488 = add nuw nsw i32 %89, 99
  %489 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %488
  %490 = add nuw nsw i32 %88, 100
  %491 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %490
  %492 = add nuw nsw i32 %89, 100
  %493 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %492
  %494 = add nuw nsw i32 %88, 101
  %495 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %494
  %496 = add nuw nsw i32 %89, 101
  %497 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %496
  %498 = add nuw nsw i32 %88, 102
  %499 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %498
  %500 = add nuw nsw i32 %89, 102
  %501 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %500
  %502 = add nuw nsw i32 %88, 103
  %503 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %502
  %504 = add nuw nsw i32 %89, 103
  %505 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %504
  %506 = add nuw nsw i32 %88, 104
  %507 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %506
  %508 = add nuw nsw i32 %89, 104
  %509 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %508
  %510 = add nuw nsw i32 %88, 105
  %511 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %510
  %512 = add nuw nsw i32 %89, 105
  %513 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %512
  %514 = add nuw nsw i32 %88, 106
  %515 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %514
  %516 = add nuw nsw i32 %89, 106
  %517 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %516
  %518 = add nuw nsw i32 %88, 107
  %519 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %518
  %520 = add nuw nsw i32 %89, 107
  %521 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %520
  %522 = add nuw nsw i32 %88, 108
  %523 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %522
  %524 = add nuw nsw i32 %89, 108
  %525 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %524
  %526 = add nuw nsw i32 %88, 109
  %527 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %526
  %528 = add nuw nsw i32 %89, 109
  %529 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %528
  %530 = add nuw nsw i32 %88, 110
  %531 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %530
  %532 = add nuw nsw i32 %89, 110
  %533 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %532
  %534 = add nuw nsw i32 %88, 111
  %535 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %534
  %536 = add nuw nsw i32 %89, 111
  %537 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %536
  %538 = add nuw nsw i32 %88, 112
  %539 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %538
  %540 = add nuw nsw i32 %89, 112
  %541 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %540
  %542 = add nuw nsw i32 %88, 113
  %543 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %542
  %544 = add nuw nsw i32 %89, 113
  %545 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %544
  %546 = add nuw nsw i32 %88, 114
  %547 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %546
  %548 = add nuw nsw i32 %89, 114
  %549 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %548
  %550 = add nuw nsw i32 %88, 115
  %551 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %550
  %552 = add nuw nsw i32 %89, 115
  %553 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %552
  %554 = add nuw nsw i32 %88, 116
  %555 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %554
  %556 = add nuw nsw i32 %89, 116
  %557 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %556
  %558 = add nuw nsw i32 %88, 117
  %559 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %558
  %560 = add nuw nsw i32 %89, 117
  %561 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %560
  %562 = add nuw nsw i32 %88, 118
  %563 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %562
  %564 = add nuw nsw i32 %89, 118
  %565 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %564
  %566 = add nuw nsw i32 %88, 119
  %567 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %566
  %568 = add nuw nsw i32 %89, 119
  %569 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %568
  %570 = add nuw nsw i32 %88, 120
  %571 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %570
  %572 = add nuw nsw i32 %89, 120
  %573 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %572
  %574 = add nuw nsw i32 %88, 121
  %575 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %574
  %576 = add nuw nsw i32 %89, 121
  %577 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %576
  %578 = add nuw nsw i32 %88, 122
  %579 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %578
  %580 = add nuw nsw i32 %89, 122
  %581 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %580
  %582 = add nuw nsw i32 %88, 123
  %583 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %582
  %584 = add nuw nsw i32 %89, 123
  %585 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %584
  %586 = add nuw nsw i32 %88, 124
  %587 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %586
  %588 = add nuw nsw i32 %89, 124
  %589 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %588
  %590 = add nuw nsw i32 %88, 125
  %591 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %590
  %592 = add nuw nsw i32 %89, 125
  %593 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %592
  %594 = add nuw nsw i32 %88, 126
  %595 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %594
  %596 = add nuw nsw i32 %89, 126
  %597 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %596
  %598 = add nuw nsw i32 %88, 127
  %599 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer1, i32 0, i32 %598
  %600 = add nuw nsw i32 %89, 127
  %601 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %600
  %602 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %5
  %603 = add nuw nsw i32 %5, 16
  %604 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %603
  %605 = add nuw nsw i32 %5, 32
  %606 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %605
  %607 = add nuw nsw i32 %5, 48
  %608 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %607
  %609 = add nuw nsw i32 %5, 64
  %610 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %609
  %611 = add nuw nsw i32 %5, 80
  %612 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %611
  %613 = add nuw nsw i32 %5, 96
  %614 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %613
  %615 = add nuw nsw i32 %5, 112
  %616 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %615
  %617 = add nuw nsw i32 %5, 128
  %618 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %617
  %619 = add nuw nsw i32 %5, 144
  %620 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %619
  %621 = add nuw nsw i32 %5, 160
  %622 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %621
  %623 = add nuw nsw i32 %5, 176
  %624 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %623
  %625 = add nuw nsw i32 %5, 192
  %626 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %625
  %627 = add nuw nsw i32 %5, 208
  %628 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %627
  %629 = add nuw nsw i32 %5, 224
  %630 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %629
  %631 = add nuw nsw i32 %5, 240
  %632 = getelementptr inbounds [256 x float], [256 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE6scores, i32 0, i32 %631
  %633 = add nuw nsw i32 %5, %89
  %634 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %633
  %635 = add nuw nsw i32 %5, 16
  %636 = icmp ult i32 %5, 112
  %637 = add nuw nsw i32 %635, %89
  %638 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %637
  %639 = add nuw nsw i32 %5, 32
  %640 = icmp ult i32 %5, 96
  %641 = add nuw nsw i32 %639, %89
  %642 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %641
  %643 = add nuw nsw i32 %5, 48
  %644 = icmp ult i32 %5, 80
  %645 = add nuw nsw i32 %643, %89
  %646 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %645
  %647 = add nuw nsw i32 %5, 64
  %648 = icmp ult i32 %5, 64
  %649 = add nuw nsw i32 %647, %89
  %650 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %649
  %651 = add nuw nsw i32 %5, 80
  %652 = icmp ult i32 %5, 48
  %653 = add nuw nsw i32 %651, %89
  %654 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %653
  %655 = add nuw nsw i32 %5, 96
  %656 = icmp ult i32 %5, 32
  %657 = add nuw nsw i32 %655, %89
  %658 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %657
  %659 = add nuw nsw i32 %5, 112
  %660 = icmp ult i32 %5, 16
  %661 = add nuw nsw i32 %659, %89
  %662 = getelementptr inbounds [2048 x float], [2048 x float] addrspace(3)* @_ZZ6Match2PfS_S_PiE7buffer2, i32 0, i32 %661
  br label %663

663:                                              ; preds = %87, %1303
  %664 = phi i32 [ 0, %87 ], [ %1306, %1303 ]
  %665 = phi i32 [ -1, %87 ], [ %1305, %1303 ]
  %666 = phi float [ 0.000000e+00, %87 ], [ %1304, %1303 ]
  br i1 %12, label %667, label %675

667:                                              ; preds = %663
  %668 = add nuw nsw i32 %664, %6
  %669 = shl nsw i32 %668, 7
  %670 = add nuw nsw i32 %5, %669
  %671 = zext i32 %670 to i64
  %672 = getelementptr inbounds float, float addrspace(1)* %1, i64 %671
  %673 = load float, float addrspace(1)* %672, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %673, float addrspace(3)* %634, align 4, !tbaa !5
  br i1 %636, label %1188, label %675, !llvm.loop !12

674:                                              ; preds = %1303
  br i1 %91, label %1308, label %1313

675:                                              ; preds = %667, %1188, %1193, %1198, %1203, %1208, %1213, %1218, %663
  fence syncscope("workgroup") release
  tail call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  %676 = load float, float addrspace(3)* %92, align 16, !tbaa !5
  %677 = load float, float addrspace(3)* %93, align 16, !tbaa !5
  %678 = fmul contract float %676, %677
  %679 = fadd contract float %678, 0.000000e+00
  %680 = load float, float addrspace(3)* %95, align 4, !tbaa !5
  %681 = load float, float addrspace(3)* %97, align 4, !tbaa !5
  %682 = fmul contract float %680, %681
  %683 = fadd contract float %679, %682
  %684 = load float, float addrspace(3)* %99, align 8, !tbaa !5
  %685 = load float, float addrspace(3)* %101, align 8, !tbaa !5
  %686 = fmul contract float %684, %685
  %687 = fadd contract float %683, %686
  %688 = load float, float addrspace(3)* %103, align 4, !tbaa !5
  %689 = load float, float addrspace(3)* %105, align 4, !tbaa !5
  %690 = fmul contract float %688, %689
  %691 = fadd contract float %687, %690
  %692 = load float, float addrspace(3)* %107, align 16, !tbaa !5
  %693 = load float, float addrspace(3)* %109, align 16, !tbaa !5
  %694 = fmul contract float %692, %693
  %695 = fadd contract float %691, %694
  %696 = load float, float addrspace(3)* %111, align 4, !tbaa !5
  %697 = load float, float addrspace(3)* %113, align 4, !tbaa !5
  %698 = fmul contract float %696, %697
  %699 = fadd contract float %695, %698
  %700 = load float, float addrspace(3)* %115, align 8, !tbaa !5
  %701 = load float, float addrspace(3)* %117, align 8, !tbaa !5
  %702 = fmul contract float %700, %701
  %703 = fadd contract float %699, %702
  %704 = load float, float addrspace(3)* %119, align 4, !tbaa !5
  %705 = load float, float addrspace(3)* %121, align 4, !tbaa !5
  %706 = fmul contract float %704, %705
  %707 = fadd contract float %703, %706
  %708 = load float, float addrspace(3)* %123, align 16, !tbaa !5
  %709 = load float, float addrspace(3)* %125, align 16, !tbaa !5
  %710 = fmul contract float %708, %709
  %711 = fadd contract float %707, %710
  %712 = load float, float addrspace(3)* %127, align 4, !tbaa !5
  %713 = load float, float addrspace(3)* %129, align 4, !tbaa !5
  %714 = fmul contract float %712, %713
  %715 = fadd contract float %711, %714
  %716 = load float, float addrspace(3)* %131, align 8, !tbaa !5
  %717 = load float, float addrspace(3)* %133, align 8, !tbaa !5
  %718 = fmul contract float %716, %717
  %719 = fadd contract float %715, %718
  %720 = load float, float addrspace(3)* %135, align 4, !tbaa !5
  %721 = load float, float addrspace(3)* %137, align 4, !tbaa !5
  %722 = fmul contract float %720, %721
  %723 = fadd contract float %719, %722
  %724 = load float, float addrspace(3)* %139, align 16, !tbaa !5
  %725 = load float, float addrspace(3)* %141, align 16, !tbaa !5
  %726 = fmul contract float %724, %725
  %727 = fadd contract float %723, %726
  %728 = load float, float addrspace(3)* %143, align 4, !tbaa !5
  %729 = load float, float addrspace(3)* %145, align 4, !tbaa !5
  %730 = fmul contract float %728, %729
  %731 = fadd contract float %727, %730
  %732 = load float, float addrspace(3)* %147, align 8, !tbaa !5
  %733 = load float, float addrspace(3)* %149, align 8, !tbaa !5
  %734 = fmul contract float %732, %733
  %735 = fadd contract float %731, %734
  %736 = load float, float addrspace(3)* %151, align 4, !tbaa !5
  %737 = load float, float addrspace(3)* %153, align 4, !tbaa !5
  %738 = fmul contract float %736, %737
  %739 = fadd contract float %735, %738
  %740 = load float, float addrspace(3)* %155, align 16, !tbaa !5
  %741 = load float, float addrspace(3)* %157, align 16, !tbaa !5
  %742 = fmul contract float %740, %741
  %743 = fadd contract float %739, %742
  %744 = load float, float addrspace(3)* %159, align 4, !tbaa !5
  %745 = load float, float addrspace(3)* %161, align 4, !tbaa !5
  %746 = fmul contract float %744, %745
  %747 = fadd contract float %743, %746
  %748 = load float, float addrspace(3)* %163, align 8, !tbaa !5
  %749 = load float, float addrspace(3)* %165, align 8, !tbaa !5
  %750 = fmul contract float %748, %749
  %751 = fadd contract float %747, %750
  %752 = load float, float addrspace(3)* %167, align 4, !tbaa !5
  %753 = load float, float addrspace(3)* %169, align 4, !tbaa !5
  %754 = fmul contract float %752, %753
  %755 = fadd contract float %751, %754
  %756 = load float, float addrspace(3)* %171, align 16, !tbaa !5
  %757 = load float, float addrspace(3)* %173, align 16, !tbaa !5
  %758 = fmul contract float %756, %757
  %759 = fadd contract float %755, %758
  %760 = load float, float addrspace(3)* %175, align 4, !tbaa !5
  %761 = load float, float addrspace(3)* %177, align 4, !tbaa !5
  %762 = fmul contract float %760, %761
  %763 = fadd contract float %759, %762
  %764 = load float, float addrspace(3)* %179, align 8, !tbaa !5
  %765 = load float, float addrspace(3)* %181, align 8, !tbaa !5
  %766 = fmul contract float %764, %765
  %767 = fadd contract float %763, %766
  %768 = load float, float addrspace(3)* %183, align 4, !tbaa !5
  %769 = load float, float addrspace(3)* %185, align 4, !tbaa !5
  %770 = fmul contract float %768, %769
  %771 = fadd contract float %767, %770
  %772 = load float, float addrspace(3)* %187, align 16, !tbaa !5
  %773 = load float, float addrspace(3)* %189, align 16, !tbaa !5
  %774 = fmul contract float %772, %773
  %775 = fadd contract float %771, %774
  %776 = load float, float addrspace(3)* %191, align 4, !tbaa !5
  %777 = load float, float addrspace(3)* %193, align 4, !tbaa !5
  %778 = fmul contract float %776, %777
  %779 = fadd contract float %775, %778
  %780 = load float, float addrspace(3)* %195, align 8, !tbaa !5
  %781 = load float, float addrspace(3)* %197, align 8, !tbaa !5
  %782 = fmul contract float %780, %781
  %783 = fadd contract float %779, %782
  %784 = load float, float addrspace(3)* %199, align 4, !tbaa !5
  %785 = load float, float addrspace(3)* %201, align 4, !tbaa !5
  %786 = fmul contract float %784, %785
  %787 = fadd contract float %783, %786
  %788 = load float, float addrspace(3)* %203, align 16, !tbaa !5
  %789 = load float, float addrspace(3)* %205, align 16, !tbaa !5
  %790 = fmul contract float %788, %789
  %791 = fadd contract float %787, %790
  %792 = load float, float addrspace(3)* %207, align 4, !tbaa !5
  %793 = load float, float addrspace(3)* %209, align 4, !tbaa !5
  %794 = fmul contract float %792, %793
  %795 = fadd contract float %791, %794
  %796 = load float, float addrspace(3)* %211, align 8, !tbaa !5
  %797 = load float, float addrspace(3)* %213, align 8, !tbaa !5
  %798 = fmul contract float %796, %797
  %799 = fadd contract float %795, %798
  %800 = load float, float addrspace(3)* %215, align 4, !tbaa !5
  %801 = load float, float addrspace(3)* %217, align 4, !tbaa !5
  %802 = fmul contract float %800, %801
  %803 = fadd contract float %799, %802
  %804 = load float, float addrspace(3)* %219, align 16, !tbaa !5
  %805 = load float, float addrspace(3)* %221, align 16, !tbaa !5
  %806 = fmul contract float %804, %805
  %807 = fadd contract float %803, %806
  %808 = load float, float addrspace(3)* %223, align 4, !tbaa !5
  %809 = load float, float addrspace(3)* %225, align 4, !tbaa !5
  %810 = fmul contract float %808, %809
  %811 = fadd contract float %807, %810
  %812 = load float, float addrspace(3)* %227, align 8, !tbaa !5
  %813 = load float, float addrspace(3)* %229, align 8, !tbaa !5
  %814 = fmul contract float %812, %813
  %815 = fadd contract float %811, %814
  %816 = load float, float addrspace(3)* %231, align 4, !tbaa !5
  %817 = load float, float addrspace(3)* %233, align 4, !tbaa !5
  %818 = fmul contract float %816, %817
  %819 = fadd contract float %815, %818
  %820 = load float, float addrspace(3)* %235, align 16, !tbaa !5
  %821 = load float, float addrspace(3)* %237, align 16, !tbaa !5
  %822 = fmul contract float %820, %821
  %823 = fadd contract float %819, %822
  %824 = load float, float addrspace(3)* %239, align 4, !tbaa !5
  %825 = load float, float addrspace(3)* %241, align 4, !tbaa !5
  %826 = fmul contract float %824, %825
  %827 = fadd contract float %823, %826
  %828 = load float, float addrspace(3)* %243, align 8, !tbaa !5
  %829 = load float, float addrspace(3)* %245, align 8, !tbaa !5
  %830 = fmul contract float %828, %829
  %831 = fadd contract float %827, %830
  %832 = load float, float addrspace(3)* %247, align 4, !tbaa !5
  %833 = load float, float addrspace(3)* %249, align 4, !tbaa !5
  %834 = fmul contract float %832, %833
  %835 = fadd contract float %831, %834
  %836 = load float, float addrspace(3)* %251, align 16, !tbaa !5
  %837 = load float, float addrspace(3)* %253, align 16, !tbaa !5
  %838 = fmul contract float %836, %837
  %839 = fadd contract float %835, %838
  %840 = load float, float addrspace(3)* %255, align 4, !tbaa !5
  %841 = load float, float addrspace(3)* %257, align 4, !tbaa !5
  %842 = fmul contract float %840, %841
  %843 = fadd contract float %839, %842
  %844 = load float, float addrspace(3)* %259, align 8, !tbaa !5
  %845 = load float, float addrspace(3)* %261, align 8, !tbaa !5
  %846 = fmul contract float %844, %845
  %847 = fadd contract float %843, %846
  %848 = load float, float addrspace(3)* %263, align 4, !tbaa !5
  %849 = load float, float addrspace(3)* %265, align 4, !tbaa !5
  %850 = fmul contract float %848, %849
  %851 = fadd contract float %847, %850
  %852 = load float, float addrspace(3)* %267, align 16, !tbaa !5
  %853 = load float, float addrspace(3)* %269, align 16, !tbaa !5
  %854 = fmul contract float %852, %853
  %855 = fadd contract float %851, %854
  %856 = load float, float addrspace(3)* %271, align 4, !tbaa !5
  %857 = load float, float addrspace(3)* %273, align 4, !tbaa !5
  %858 = fmul contract float %856, %857
  %859 = fadd contract float %855, %858
  %860 = load float, float addrspace(3)* %275, align 8, !tbaa !5
  %861 = load float, float addrspace(3)* %277, align 8, !tbaa !5
  %862 = fmul contract float %860, %861
  %863 = fadd contract float %859, %862
  %864 = load float, float addrspace(3)* %279, align 4, !tbaa !5
  %865 = load float, float addrspace(3)* %281, align 4, !tbaa !5
  %866 = fmul contract float %864, %865
  %867 = fadd contract float %863, %866
  %868 = load float, float addrspace(3)* %283, align 16, !tbaa !5
  %869 = load float, float addrspace(3)* %285, align 16, !tbaa !5
  %870 = fmul contract float %868, %869
  %871 = fadd contract float %867, %870
  %872 = load float, float addrspace(3)* %287, align 4, !tbaa !5
  %873 = load float, float addrspace(3)* %289, align 4, !tbaa !5
  %874 = fmul contract float %872, %873
  %875 = fadd contract float %871, %874
  %876 = load float, float addrspace(3)* %291, align 8, !tbaa !5
  %877 = load float, float addrspace(3)* %293, align 8, !tbaa !5
  %878 = fmul contract float %876, %877
  %879 = fadd contract float %875, %878
  %880 = load float, float addrspace(3)* %295, align 4, !tbaa !5
  %881 = load float, float addrspace(3)* %297, align 4, !tbaa !5
  %882 = fmul contract float %880, %881
  %883 = fadd contract float %879, %882
  %884 = load float, float addrspace(3)* %299, align 16, !tbaa !5
  %885 = load float, float addrspace(3)* %301, align 16, !tbaa !5
  %886 = fmul contract float %884, %885
  %887 = fadd contract float %883, %886
  %888 = load float, float addrspace(3)* %303, align 4, !tbaa !5
  %889 = load float, float addrspace(3)* %305, align 4, !tbaa !5
  %890 = fmul contract float %888, %889
  %891 = fadd contract float %887, %890
  %892 = load float, float addrspace(3)* %307, align 8, !tbaa !5
  %893 = load float, float addrspace(3)* %309, align 8, !tbaa !5
  %894 = fmul contract float %892, %893
  %895 = fadd contract float %891, %894
  %896 = load float, float addrspace(3)* %311, align 4, !tbaa !5
  %897 = load float, float addrspace(3)* %313, align 4, !tbaa !5
  %898 = fmul contract float %896, %897
  %899 = fadd contract float %895, %898
  %900 = load float, float addrspace(3)* %315, align 16, !tbaa !5
  %901 = load float, float addrspace(3)* %317, align 16, !tbaa !5
  %902 = fmul contract float %900, %901
  %903 = fadd contract float %899, %902
  %904 = load float, float addrspace(3)* %319, align 4, !tbaa !5
  %905 = load float, float addrspace(3)* %321, align 4, !tbaa !5
  %906 = fmul contract float %904, %905
  %907 = fadd contract float %903, %906
  %908 = load float, float addrspace(3)* %323, align 8, !tbaa !5
  %909 = load float, float addrspace(3)* %325, align 8, !tbaa !5
  %910 = fmul contract float %908, %909
  %911 = fadd contract float %907, %910
  %912 = load float, float addrspace(3)* %327, align 4, !tbaa !5
  %913 = load float, float addrspace(3)* %329, align 4, !tbaa !5
  %914 = fmul contract float %912, %913
  %915 = fadd contract float %911, %914
  %916 = load float, float addrspace(3)* %331, align 16, !tbaa !5
  %917 = load float, float addrspace(3)* %333, align 16, !tbaa !5
  %918 = fmul contract float %916, %917
  %919 = fadd contract float %915, %918
  %920 = load float, float addrspace(3)* %335, align 4, !tbaa !5
  %921 = load float, float addrspace(3)* %337, align 4, !tbaa !5
  %922 = fmul contract float %920, %921
  %923 = fadd contract float %919, %922
  %924 = load float, float addrspace(3)* %339, align 8, !tbaa !5
  %925 = load float, float addrspace(3)* %341, align 8, !tbaa !5
  %926 = fmul contract float %924, %925
  %927 = fadd contract float %923, %926
  %928 = load float, float addrspace(3)* %343, align 4, !tbaa !5
  %929 = load float, float addrspace(3)* %345, align 4, !tbaa !5
  %930 = fmul contract float %928, %929
  %931 = fadd contract float %927, %930
  %932 = load float, float addrspace(3)* %347, align 16, !tbaa !5
  %933 = load float, float addrspace(3)* %349, align 16, !tbaa !5
  %934 = fmul contract float %932, %933
  %935 = fadd contract float %931, %934
  %936 = load float, float addrspace(3)* %351, align 4, !tbaa !5
  %937 = load float, float addrspace(3)* %353, align 4, !tbaa !5
  %938 = fmul contract float %936, %937
  %939 = fadd contract float %935, %938
  %940 = load float, float addrspace(3)* %355, align 8, !tbaa !5
  %941 = load float, float addrspace(3)* %357, align 8, !tbaa !5
  %942 = fmul contract float %940, %941
  %943 = fadd contract float %939, %942
  %944 = load float, float addrspace(3)* %359, align 4, !tbaa !5
  %945 = load float, float addrspace(3)* %361, align 4, !tbaa !5
  %946 = fmul contract float %944, %945
  %947 = fadd contract float %943, %946
  %948 = load float, float addrspace(3)* %363, align 16, !tbaa !5
  %949 = load float, float addrspace(3)* %365, align 16, !tbaa !5
  %950 = fmul contract float %948, %949
  %951 = fadd contract float %947, %950
  %952 = load float, float addrspace(3)* %367, align 4, !tbaa !5
  %953 = load float, float addrspace(3)* %369, align 4, !tbaa !5
  %954 = fmul contract float %952, %953
  %955 = fadd contract float %951, %954
  %956 = load float, float addrspace(3)* %371, align 8, !tbaa !5
  %957 = load float, float addrspace(3)* %373, align 8, !tbaa !5
  %958 = fmul contract float %956, %957
  %959 = fadd contract float %955, %958
  %960 = load float, float addrspace(3)* %375, align 4, !tbaa !5
  %961 = load float, float addrspace(3)* %377, align 4, !tbaa !5
  %962 = fmul contract float %960, %961
  %963 = fadd contract float %959, %962
  %964 = load float, float addrspace(3)* %379, align 16, !tbaa !5
  %965 = load float, float addrspace(3)* %381, align 16, !tbaa !5
  %966 = fmul contract float %964, %965
  %967 = fadd contract float %963, %966
  %968 = load float, float addrspace(3)* %383, align 4, !tbaa !5
  %969 = load float, float addrspace(3)* %385, align 4, !tbaa !5
  %970 = fmul contract float %968, %969
  %971 = fadd contract float %967, %970
  %972 = load float, float addrspace(3)* %387, align 8, !tbaa !5
  %973 = load float, float addrspace(3)* %389, align 8, !tbaa !5
  %974 = fmul contract float %972, %973
  %975 = fadd contract float %971, %974
  %976 = load float, float addrspace(3)* %391, align 4, !tbaa !5
  %977 = load float, float addrspace(3)* %393, align 4, !tbaa !5
  %978 = fmul contract float %976, %977
  %979 = fadd contract float %975, %978
  %980 = load float, float addrspace(3)* %395, align 16, !tbaa !5
  %981 = load float, float addrspace(3)* %397, align 16, !tbaa !5
  %982 = fmul contract float %980, %981
  %983 = fadd contract float %979, %982
  %984 = load float, float addrspace(3)* %399, align 4, !tbaa !5
  %985 = load float, float addrspace(3)* %401, align 4, !tbaa !5
  %986 = fmul contract float %984, %985
  %987 = fadd contract float %983, %986
  %988 = load float, float addrspace(3)* %403, align 8, !tbaa !5
  %989 = load float, float addrspace(3)* %405, align 8, !tbaa !5
  %990 = fmul contract float %988, %989
  %991 = fadd contract float %987, %990
  %992 = load float, float addrspace(3)* %407, align 4, !tbaa !5
  %993 = load float, float addrspace(3)* %409, align 4, !tbaa !5
  %994 = fmul contract float %992, %993
  %995 = fadd contract float %991, %994
  %996 = load float, float addrspace(3)* %411, align 16, !tbaa !5
  %997 = load float, float addrspace(3)* %413, align 16, !tbaa !5
  %998 = fmul contract float %996, %997
  %999 = fadd contract float %995, %998
  %1000 = load float, float addrspace(3)* %415, align 4, !tbaa !5
  %1001 = load float, float addrspace(3)* %417, align 4, !tbaa !5
  %1002 = fmul contract float %1000, %1001
  %1003 = fadd contract float %999, %1002
  %1004 = load float, float addrspace(3)* %419, align 8, !tbaa !5
  %1005 = load float, float addrspace(3)* %421, align 8, !tbaa !5
  %1006 = fmul contract float %1004, %1005
  %1007 = fadd contract float %1003, %1006
  %1008 = load float, float addrspace(3)* %423, align 4, !tbaa !5
  %1009 = load float, float addrspace(3)* %425, align 4, !tbaa !5
  %1010 = fmul contract float %1008, %1009
  %1011 = fadd contract float %1007, %1010
  %1012 = load float, float addrspace(3)* %427, align 16, !tbaa !5
  %1013 = load float, float addrspace(3)* %429, align 16, !tbaa !5
  %1014 = fmul contract float %1012, %1013
  %1015 = fadd contract float %1011, %1014
  %1016 = load float, float addrspace(3)* %431, align 4, !tbaa !5
  %1017 = load float, float addrspace(3)* %433, align 4, !tbaa !5
  %1018 = fmul contract float %1016, %1017
  %1019 = fadd contract float %1015, %1018
  %1020 = load float, float addrspace(3)* %435, align 8, !tbaa !5
  %1021 = load float, float addrspace(3)* %437, align 8, !tbaa !5
  %1022 = fmul contract float %1020, %1021
  %1023 = fadd contract float %1019, %1022
  %1024 = load float, float addrspace(3)* %439, align 4, !tbaa !5
  %1025 = load float, float addrspace(3)* %441, align 4, !tbaa !5
  %1026 = fmul contract float %1024, %1025
  %1027 = fadd contract float %1023, %1026
  %1028 = load float, float addrspace(3)* %443, align 16, !tbaa !5
  %1029 = load float, float addrspace(3)* %445, align 16, !tbaa !5
  %1030 = fmul contract float %1028, %1029
  %1031 = fadd contract float %1027, %1030
  %1032 = load float, float addrspace(3)* %447, align 4, !tbaa !5
  %1033 = load float, float addrspace(3)* %449, align 4, !tbaa !5
  %1034 = fmul contract float %1032, %1033
  %1035 = fadd contract float %1031, %1034
  %1036 = load float, float addrspace(3)* %451, align 8, !tbaa !5
  %1037 = load float, float addrspace(3)* %453, align 8, !tbaa !5
  %1038 = fmul contract float %1036, %1037
  %1039 = fadd contract float %1035, %1038
  %1040 = load float, float addrspace(3)* %455, align 4, !tbaa !5
  %1041 = load float, float addrspace(3)* %457, align 4, !tbaa !5
  %1042 = fmul contract float %1040, %1041
  %1043 = fadd contract float %1039, %1042
  %1044 = load float, float addrspace(3)* %459, align 16, !tbaa !5
  %1045 = load float, float addrspace(3)* %461, align 16, !tbaa !5
  %1046 = fmul contract float %1044, %1045
  %1047 = fadd contract float %1043, %1046
  %1048 = load float, float addrspace(3)* %463, align 4, !tbaa !5
  %1049 = load float, float addrspace(3)* %465, align 4, !tbaa !5
  %1050 = fmul contract float %1048, %1049
  %1051 = fadd contract float %1047, %1050
  %1052 = load float, float addrspace(3)* %467, align 8, !tbaa !5
  %1053 = load float, float addrspace(3)* %469, align 8, !tbaa !5
  %1054 = fmul contract float %1052, %1053
  %1055 = fadd contract float %1051, %1054
  %1056 = load float, float addrspace(3)* %471, align 4, !tbaa !5
  %1057 = load float, float addrspace(3)* %473, align 4, !tbaa !5
  %1058 = fmul contract float %1056, %1057
  %1059 = fadd contract float %1055, %1058
  %1060 = load float, float addrspace(3)* %475, align 16, !tbaa !5
  %1061 = load float, float addrspace(3)* %477, align 16, !tbaa !5
  %1062 = fmul contract float %1060, %1061
  %1063 = fadd contract float %1059, %1062
  %1064 = load float, float addrspace(3)* %479, align 4, !tbaa !5
  %1065 = load float, float addrspace(3)* %481, align 4, !tbaa !5
  %1066 = fmul contract float %1064, %1065
  %1067 = fadd contract float %1063, %1066
  %1068 = load float, float addrspace(3)* %483, align 8, !tbaa !5
  %1069 = load float, float addrspace(3)* %485, align 8, !tbaa !5
  %1070 = fmul contract float %1068, %1069
  %1071 = fadd contract float %1067, %1070
  %1072 = load float, float addrspace(3)* %487, align 4, !tbaa !5
  %1073 = load float, float addrspace(3)* %489, align 4, !tbaa !5
  %1074 = fmul contract float %1072, %1073
  %1075 = fadd contract float %1071, %1074
  %1076 = load float, float addrspace(3)* %491, align 16, !tbaa !5
  %1077 = load float, float addrspace(3)* %493, align 16, !tbaa !5
  %1078 = fmul contract float %1076, %1077
  %1079 = fadd contract float %1075, %1078
  %1080 = load float, float addrspace(3)* %495, align 4, !tbaa !5
  %1081 = load float, float addrspace(3)* %497, align 4, !tbaa !5
  %1082 = fmul contract float %1080, %1081
  %1083 = fadd contract float %1079, %1082
  %1084 = load float, float addrspace(3)* %499, align 8, !tbaa !5
  %1085 = load float, float addrspace(3)* %501, align 8, !tbaa !5
  %1086 = fmul contract float %1084, %1085
  %1087 = fadd contract float %1083, %1086
  %1088 = load float, float addrspace(3)* %503, align 4, !tbaa !5
  %1089 = load float, float addrspace(3)* %505, align 4, !tbaa !5
  %1090 = fmul contract float %1088, %1089
  %1091 = fadd contract float %1087, %1090
  %1092 = load float, float addrspace(3)* %507, align 16, !tbaa !5
  %1093 = load float, float addrspace(3)* %509, align 16, !tbaa !5
  %1094 = fmul contract float %1092, %1093
  %1095 = fadd contract float %1091, %1094
  %1096 = load float, float addrspace(3)* %511, align 4, !tbaa !5
  %1097 = load float, float addrspace(3)* %513, align 4, !tbaa !5
  %1098 = fmul contract float %1096, %1097
  %1099 = fadd contract float %1095, %1098
  %1100 = load float, float addrspace(3)* %515, align 8, !tbaa !5
  %1101 = load float, float addrspace(3)* %517, align 8, !tbaa !5
  %1102 = fmul contract float %1100, %1101
  %1103 = fadd contract float %1099, %1102
  %1104 = load float, float addrspace(3)* %519, align 4, !tbaa !5
  %1105 = load float, float addrspace(3)* %521, align 4, !tbaa !5
  %1106 = fmul contract float %1104, %1105
  %1107 = fadd contract float %1103, %1106
  %1108 = load float, float addrspace(3)* %523, align 16, !tbaa !5
  %1109 = load float, float addrspace(3)* %525, align 16, !tbaa !5
  %1110 = fmul contract float %1108, %1109
  %1111 = fadd contract float %1107, %1110
  %1112 = load float, float addrspace(3)* %527, align 4, !tbaa !5
  %1113 = load float, float addrspace(3)* %529, align 4, !tbaa !5
  %1114 = fmul contract float %1112, %1113
  %1115 = fadd contract float %1111, %1114
  %1116 = load float, float addrspace(3)* %531, align 8, !tbaa !5
  %1117 = load float, float addrspace(3)* %533, align 8, !tbaa !5
  %1118 = fmul contract float %1116, %1117
  %1119 = fadd contract float %1115, %1118
  %1120 = load float, float addrspace(3)* %535, align 4, !tbaa !5
  %1121 = load float, float addrspace(3)* %537, align 4, !tbaa !5
  %1122 = fmul contract float %1120, %1121
  %1123 = fadd contract float %1119, %1122
  %1124 = load float, float addrspace(3)* %539, align 16, !tbaa !5
  %1125 = load float, float addrspace(3)* %541, align 16, !tbaa !5
  %1126 = fmul contract float %1124, %1125
  %1127 = fadd contract float %1123, %1126
  %1128 = load float, float addrspace(3)* %543, align 4, !tbaa !5
  %1129 = load float, float addrspace(3)* %545, align 4, !tbaa !5
  %1130 = fmul contract float %1128, %1129
  %1131 = fadd contract float %1127, %1130
  %1132 = load float, float addrspace(3)* %547, align 8, !tbaa !5
  %1133 = load float, float addrspace(3)* %549, align 8, !tbaa !5
  %1134 = fmul contract float %1132, %1133
  %1135 = fadd contract float %1131, %1134
  %1136 = load float, float addrspace(3)* %551, align 4, !tbaa !5
  %1137 = load float, float addrspace(3)* %553, align 4, !tbaa !5
  %1138 = fmul contract float %1136, %1137
  %1139 = fadd contract float %1135, %1138
  %1140 = load float, float addrspace(3)* %555, align 16, !tbaa !5
  %1141 = load float, float addrspace(3)* %557, align 16, !tbaa !5
  %1142 = fmul contract float %1140, %1141
  %1143 = fadd contract float %1139, %1142
  %1144 = load float, float addrspace(3)* %559, align 4, !tbaa !5
  %1145 = load float, float addrspace(3)* %561, align 4, !tbaa !5
  %1146 = fmul contract float %1144, %1145
  %1147 = fadd contract float %1143, %1146
  %1148 = load float, float addrspace(3)* %563, align 8, !tbaa !5
  %1149 = load float, float addrspace(3)* %565, align 8, !tbaa !5
  %1150 = fmul contract float %1148, %1149
  %1151 = fadd contract float %1147, %1150
  %1152 = load float, float addrspace(3)* %567, align 4, !tbaa !5
  %1153 = load float, float addrspace(3)* %569, align 4, !tbaa !5
  %1154 = fmul contract float %1152, %1153
  %1155 = fadd contract float %1151, %1154
  %1156 = load float, float addrspace(3)* %571, align 16, !tbaa !5
  %1157 = load float, float addrspace(3)* %573, align 16, !tbaa !5
  %1158 = fmul contract float %1156, %1157
  %1159 = fadd contract float %1155, %1158
  %1160 = load float, float addrspace(3)* %575, align 4, !tbaa !5
  %1161 = load float, float addrspace(3)* %577, align 4, !tbaa !5
  %1162 = fmul contract float %1160, %1161
  %1163 = fadd contract float %1159, %1162
  %1164 = load float, float addrspace(3)* %579, align 8, !tbaa !5
  %1165 = load float, float addrspace(3)* %581, align 8, !tbaa !5
  %1166 = fmul contract float %1164, %1165
  %1167 = fadd contract float %1163, %1166
  %1168 = load float, float addrspace(3)* %583, align 4, !tbaa !5
  %1169 = load float, float addrspace(3)* %585, align 4, !tbaa !5
  %1170 = fmul contract float %1168, %1169
  %1171 = fadd contract float %1167, %1170
  %1172 = load float, float addrspace(3)* %587, align 16, !tbaa !5
  %1173 = load float, float addrspace(3)* %589, align 16, !tbaa !5
  %1174 = fmul contract float %1172, %1173
  %1175 = fadd contract float %1171, %1174
  %1176 = load float, float addrspace(3)* %591, align 4, !tbaa !5
  %1177 = load float, float addrspace(3)* %593, align 4, !tbaa !5
  %1178 = fmul contract float %1176, %1177
  %1179 = fadd contract float %1175, %1178
  %1180 = load float, float addrspace(3)* %595, align 8, !tbaa !5
  %1181 = load float, float addrspace(3)* %597, align 8, !tbaa !5
  %1182 = fmul contract float %1180, %1181
  %1183 = fadd contract float %1179, %1182
  %1184 = load float, float addrspace(3)* %599, align 4, !tbaa !5
  %1185 = load float, float addrspace(3)* %601, align 4, !tbaa !5
  %1186 = fmul contract float %1184, %1185
  %1187 = fadd contract float %1183, %1186
  store float %1187, float addrspace(3)* %90, align 4, !tbaa !5
  fence syncscope("workgroup") release
  tail call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  br i1 %91, label %1223, label %1303

1188:                                             ; preds = %667
  %1189 = add nuw nsw i32 %635, %669
  %1190 = zext i32 %1189 to i64
  %1191 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1190
  %1192 = load float, float addrspace(1)* %1191, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1192, float addrspace(3)* %638, align 4, !tbaa !5
  br i1 %640, label %1193, label %675, !llvm.loop !12

1193:                                             ; preds = %1188
  %1194 = add nuw nsw i32 %639, %669
  %1195 = zext i32 %1194 to i64
  %1196 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1195
  %1197 = load float, float addrspace(1)* %1196, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1197, float addrspace(3)* %642, align 4, !tbaa !5
  br i1 %644, label %1198, label %675, !llvm.loop !12

1198:                                             ; preds = %1193
  %1199 = add nuw nsw i32 %643, %669
  %1200 = zext i32 %1199 to i64
  %1201 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1200
  %1202 = load float, float addrspace(1)* %1201, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1202, float addrspace(3)* %646, align 4, !tbaa !5
  br i1 %648, label %1203, label %675, !llvm.loop !12

1203:                                             ; preds = %1198
  %1204 = add nuw nsw i32 %647, %669
  %1205 = zext i32 %1204 to i64
  %1206 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1205
  %1207 = load float, float addrspace(1)* %1206, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1207, float addrspace(3)* %650, align 4, !tbaa !5
  br i1 %652, label %1208, label %675, !llvm.loop !12

1208:                                             ; preds = %1203
  %1209 = add nuw nsw i32 %651, %669
  %1210 = zext i32 %1209 to i64
  %1211 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1210
  %1212 = load float, float addrspace(1)* %1211, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1212, float addrspace(3)* %654, align 4, !tbaa !5
  br i1 %656, label %1213, label %675, !llvm.loop !12

1213:                                             ; preds = %1208
  %1214 = add nuw nsw i32 %655, %669
  %1215 = zext i32 %1214 to i64
  %1216 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1215
  %1217 = load float, float addrspace(1)* %1216, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1217, float addrspace(3)* %658, align 4, !tbaa !5
  br i1 %660, label %1218, label %675, !llvm.loop !12

1218:                                             ; preds = %1213
  %1219 = add nuw nsw i32 %659, %669
  %1220 = zext i32 %1219 to i64
  %1221 = getelementptr inbounds float, float addrspace(1)* %1, i64 %1220
  %1222 = load float, float addrspace(1)* %1221, align 4, !tbaa !5, !amdgpu.noclobber !9
  store float %1222, float addrspace(3)* %662, align 4, !tbaa !5
  br label %675

1223:                                             ; preds = %675
  %1224 = load float, float addrspace(3)* %602, align 4, !tbaa !5
  %1225 = fcmp contract ogt float %1224, %666
  %1226 = select i1 %1225, float %1224, float %666
  %1227 = select i1 %1225, i32 %664, i32 %665
  %1228 = load float, float addrspace(3)* %604, align 4, !tbaa !5
  %1229 = fcmp contract ogt float %1228, %1226
  %1230 = or i32 %664, 1
  %1231 = select i1 %1229, float %1228, float %1226
  %1232 = select i1 %1229, i32 %1230, i32 %1227
  %1233 = load float, float addrspace(3)* %606, align 4, !tbaa !5
  %1234 = fcmp contract ogt float %1233, %1231
  %1235 = or i32 %664, 2
  %1236 = select i1 %1234, float %1233, float %1231
  %1237 = select i1 %1234, i32 %1235, i32 %1232
  %1238 = load float, float addrspace(3)* %608, align 4, !tbaa !5
  %1239 = fcmp contract ogt float %1238, %1236
  %1240 = or i32 %664, 3
  %1241 = select i1 %1239, float %1238, float %1236
  %1242 = select i1 %1239, i32 %1240, i32 %1237
  %1243 = load float, float addrspace(3)* %610, align 4, !tbaa !5
  %1244 = fcmp contract ogt float %1243, %1241
  %1245 = or i32 %664, 4
  %1246 = select i1 %1244, float %1243, float %1241
  %1247 = select i1 %1244, i32 %1245, i32 %1242
  %1248 = load float, float addrspace(3)* %612, align 4, !tbaa !5
  %1249 = fcmp contract ogt float %1248, %1246
  %1250 = or i32 %664, 5
  %1251 = select i1 %1249, float %1248, float %1246
  %1252 = select i1 %1249, i32 %1250, i32 %1247
  %1253 = load float, float addrspace(3)* %614, align 4, !tbaa !5
  %1254 = fcmp contract ogt float %1253, %1251
  %1255 = or i32 %664, 6
  %1256 = select i1 %1254, float %1253, float %1251
  %1257 = select i1 %1254, i32 %1255, i32 %1252
  %1258 = load float, float addrspace(3)* %616, align 4, !tbaa !5
  %1259 = fcmp contract ogt float %1258, %1256
  %1260 = or i32 %664, 7
  %1261 = select i1 %1259, float %1258, float %1256
  %1262 = select i1 %1259, i32 %1260, i32 %1257
  %1263 = load float, float addrspace(3)* %618, align 4, !tbaa !5
  %1264 = fcmp contract ogt float %1263, %1261
  %1265 = or i32 %664, 8
  %1266 = select i1 %1264, float %1263, float %1261
  %1267 = select i1 %1264, i32 %1265, i32 %1262
  %1268 = load float, float addrspace(3)* %620, align 4, !tbaa !5
  %1269 = fcmp contract ogt float %1268, %1266
  %1270 = or i32 %664, 9
  %1271 = select i1 %1269, float %1268, float %1266
  %1272 = select i1 %1269, i32 %1270, i32 %1267
  %1273 = load float, float addrspace(3)* %622, align 4, !tbaa !5
  %1274 = fcmp contract ogt float %1273, %1271
  %1275 = or i32 %664, 10
  %1276 = select i1 %1274, float %1273, float %1271
  %1277 = select i1 %1274, i32 %1275, i32 %1272
  %1278 = load float, float addrspace(3)* %624, align 4, !tbaa !5
  %1279 = fcmp contract ogt float %1278, %1276
  %1280 = or i32 %664, 11
  %1281 = select i1 %1279, float %1278, float %1276
  %1282 = select i1 %1279, i32 %1280, i32 %1277
  %1283 = load float, float addrspace(3)* %626, align 4, !tbaa !5
  %1284 = fcmp contract ogt float %1283, %1281
  %1285 = or i32 %664, 12
  %1286 = select i1 %1284, float %1283, float %1281
  %1287 = select i1 %1284, i32 %1285, i32 %1282
  %1288 = load float, float addrspace(3)* %628, align 4, !tbaa !5
  %1289 = fcmp contract ogt float %1288, %1286
  %1290 = or i32 %664, 13
  %1291 = select i1 %1289, float %1288, float %1286
  %1292 = select i1 %1289, i32 %1290, i32 %1287
  %1293 = load float, float addrspace(3)* %630, align 4, !tbaa !5
  %1294 = fcmp contract ogt float %1293, %1291
  %1295 = or i32 %664, 14
  %1296 = select i1 %1294, float %1293, float %1291
  %1297 = select i1 %1294, i32 %1295, i32 %1292
  %1298 = load float, float addrspace(3)* %632, align 4, !tbaa !5
  %1299 = fcmp contract ogt float %1298, %1296
  %1300 = or i32 %664, 15
  %1301 = select i1 %1299, float %1298, float %1296
  %1302 = select i1 %1299, i32 %1300, i32 %1297
  br label %1303

1303:                                             ; preds = %1223, %675
  %1304 = phi float [ %666, %675 ], [ %1301, %1223 ]
  %1305 = phi i32 [ %665, %675 ], [ %1302, %1223 ]
  fence syncscope("workgroup") release
  tail call void @llvm.amdgcn.s.barrier()
  fence syncscope("workgroup") acquire
  %1306 = add nuw nsw i32 %664, 16
  %1307 = icmp ult i32 %664, 16368
  br i1 %1307, label %663, label %674, !llvm.loop !13

1308:                                             ; preds = %674
  %1309 = add nsw i32 %10, %5
  %1310 = sext i32 %1309 to i64
  %1311 = getelementptr inbounds float, float addrspace(1)* %2, i64 %1310
  store float %1304, float addrspace(1)* %1311, align 4, !tbaa !5
  %1312 = getelementptr inbounds i32, i32 addrspace(1)* %3, i64 %1310
  store i32 %1305, i32 addrspace(1)* %1312, align 4, !tbaa !14
  br label %1313

1313:                                             ; preds = %1308, %674
  ret void
}

; Function Attrs: convergent mustprogress nounwind willreturn
declare void @llvm.amdgcn.s.barrier() #1

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workitem.id.x() #2

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workitem.id.y() #2

; Function Attrs: mustprogress nofree nosync nounwind readnone speculatable willreturn
declare i32 @llvm.amdgcn.workgroup.id.x() #2

attributes #0 = { convergent mustprogress norecurse nounwind "amdgpu-flat-work-group-size"="1,256" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx906" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+s-memrealtime,+s-memtime-inst,+sramecc" "uniform-work-group-size"="true" }
attributes #1 = { convergent mustprogress nounwind willreturn }
attributes #2 = { mustprogress nofree nosync nounwind readnone speculatable willreturn }

!llvm.module.flags = !{!0, !1}
!opencl.ocl.version = !{!2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 1}
!2 = !{i32 2, i32 0}
!3 = !{!"clang version 15.0.0 (http://10.15.3.7/dcutoolkit/driverruntime/llvm-project.git 340750feeda88c9c2ce8ad481b11d9aa7f033d39)"}
!4 = !{i32 0, i32 1024}
!5 = !{!6, !6, i64 0}
!6 = !{!"float", !7, i64 0}
!7 = !{!"omnipotent char", !8, i64 0}
!8 = !{!"Simple C++ TBAA"}
!9 = !{}
!10 = distinct !{!10, !11}
!11 = !{!"llvm.loop.mustprogress"}
!12 = distinct !{!12, !11}
!13 = distinct !{!13, !11}
!14 = !{!15, !15, i64 0}
!15 = !{!"int", !7, i64 0}
