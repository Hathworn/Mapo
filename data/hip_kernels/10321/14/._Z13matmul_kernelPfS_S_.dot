digraph "CFG for '_Z13matmul_kernelPfS_S_' function" {
	label="CFG for '_Z13matmul_kernelPfS_S_' function";

	Node0x4fa0190 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#b9d0f970",label="{%3:\l  %4 = tail call i32 @llvm.amdgcn.workgroup.id.x()\l  %5 = shl i32 %4, 5\l  %6 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !4\l  %7 = add i32 %5, %6\l  %8 = tail call i32 @llvm.amdgcn.workgroup.id.y()\l  %9 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !4\l  %10 = shl i32 %8, 16\l  %11 = shl nuw nsw i32 %9, 12\l  %12 = add i32 %10, %11\l  br label %17\l}"];
	Node0x4fa0190 -> Node0x4fa2500;
	Node0x4fa2600 [shape=record,color="#3d50c3ff", style=filled, fillcolor="#b9d0f970",label="{%13:\l13:                                               \l  %14 = add nsw i32 %12, %7\l  %15 = sext i32 %14 to i64\l  %16 = getelementptr inbounds float, float addrspace(1)* %0, i64 %15\l  store float %114, float addrspace(1)* %16, align 4, !tbaa !5\l  ret void\l}"];
	Node0x4fa2500 [shape=record,color="#b70d28ff", style=filled, fillcolor="#b70d2870",label="{%17:\l17:                                               \l  %18 = phi i32 [ 0, %3 ], [ %115, %17 ]\l  %19 = phi float [ 0.000000e+00, %3 ], [ %114, %17 ]\l  %20 = add nuw nsw i32 %18, %12\l  %21 = sext i32 %20 to i64\l  %22 = getelementptr inbounds float, float addrspace(1)* %1, i64 %21\l  %23 = load float, float addrspace(1)* %22, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %24 = shl nuw nsw i32 %18, 12\l  %25 = add nsw i32 %24, %7\l  %26 = sext i32 %25 to i64\l  %27 = getelementptr inbounds float, float addrspace(1)* %2, i64 %26\l  %28 = load float, float addrspace(1)* %27, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %29 = fmul contract float %23, %28\l  %30 = fadd contract float %19, %29\l  %31 = or i32 %18, 1\l  %32 = add nuw nsw i32 %31, %12\l  %33 = sext i32 %32 to i64\l  %34 = getelementptr inbounds float, float addrspace(1)* %1, i64 %33\l  %35 = load float, float addrspace(1)* %34, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %36 = shl nuw nsw i32 %31, 12\l  %37 = add nsw i32 %36, %7\l  %38 = sext i32 %37 to i64\l  %39 = getelementptr inbounds float, float addrspace(1)* %2, i64 %38\l  %40 = load float, float addrspace(1)* %39, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %41 = fmul contract float %35, %40\l  %42 = fadd contract float %30, %41\l  %43 = or i32 %18, 2\l  %44 = add nuw nsw i32 %43, %12\l  %45 = sext i32 %44 to i64\l  %46 = getelementptr inbounds float, float addrspace(1)* %1, i64 %45\l  %47 = load float, float addrspace(1)* %46, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %48 = shl nuw nsw i32 %43, 12\l  %49 = add nsw i32 %48, %7\l  %50 = sext i32 %49 to i64\l  %51 = getelementptr inbounds float, float addrspace(1)* %2, i64 %50\l  %52 = load float, float addrspace(1)* %51, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %53 = fmul contract float %47, %52\l  %54 = fadd contract float %42, %53\l  %55 = or i32 %18, 3\l  %56 = add nuw nsw i32 %55, %12\l  %57 = sext i32 %56 to i64\l  %58 = getelementptr inbounds float, float addrspace(1)* %1, i64 %57\l  %59 = load float, float addrspace(1)* %58, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %60 = shl nuw nsw i32 %55, 12\l  %61 = add nsw i32 %60, %7\l  %62 = sext i32 %61 to i64\l  %63 = getelementptr inbounds float, float addrspace(1)* %2, i64 %62\l  %64 = load float, float addrspace(1)* %63, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %65 = fmul contract float %59, %64\l  %66 = fadd contract float %54, %65\l  %67 = or i32 %18, 4\l  %68 = add nuw nsw i32 %67, %12\l  %69 = sext i32 %68 to i64\l  %70 = getelementptr inbounds float, float addrspace(1)* %1, i64 %69\l  %71 = load float, float addrspace(1)* %70, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %72 = shl nuw nsw i32 %67, 12\l  %73 = add nsw i32 %72, %7\l  %74 = sext i32 %73 to i64\l  %75 = getelementptr inbounds float, float addrspace(1)* %2, i64 %74\l  %76 = load float, float addrspace(1)* %75, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %77 = fmul contract float %71, %76\l  %78 = fadd contract float %66, %77\l  %79 = or i32 %18, 5\l  %80 = add nuw nsw i32 %79, %12\l  %81 = sext i32 %80 to i64\l  %82 = getelementptr inbounds float, float addrspace(1)* %1, i64 %81\l  %83 = load float, float addrspace(1)* %82, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %84 = shl nuw nsw i32 %79, 12\l  %85 = add nsw i32 %84, %7\l  %86 = sext i32 %85 to i64\l  %87 = getelementptr inbounds float, float addrspace(1)* %2, i64 %86\l  %88 = load float, float addrspace(1)* %87, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %89 = fmul contract float %83, %88\l  %90 = fadd contract float %78, %89\l  %91 = or i32 %18, 6\l  %92 = add nuw nsw i32 %91, %12\l  %93 = sext i32 %92 to i64\l  %94 = getelementptr inbounds float, float addrspace(1)* %1, i64 %93\l  %95 = load float, float addrspace(1)* %94, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %96 = shl nuw nsw i32 %91, 12\l  %97 = add nsw i32 %96, %7\l  %98 = sext i32 %97 to i64\l  %99 = getelementptr inbounds float, float addrspace(1)* %2, i64 %98\l  %100 = load float, float addrspace(1)* %99, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %101 = fmul contract float %95, %100\l  %102 = fadd contract float %90, %101\l  %103 = or i32 %18, 7\l  %104 = add nuw nsw i32 %103, %12\l  %105 = sext i32 %104 to i64\l  %106 = getelementptr inbounds float, float addrspace(1)* %1, i64 %105\l  %107 = load float, float addrspace(1)* %106, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %108 = shl nuw nsw i32 %103, 12\l  %109 = add nsw i32 %108, %7\l  %110 = sext i32 %109 to i64\l  %111 = getelementptr inbounds float, float addrspace(1)* %2, i64 %110\l  %112 = load float, float addrspace(1)* %111, align 4, !tbaa !5,\l... !amdgpu.noclobber !9\l  %113 = fmul contract float %107, %112\l  %114 = fadd contract float %102, %113\l  %115 = add nuw nsw i32 %18, 8\l  %116 = icmp eq i32 %115, 4096\l  br i1 %116, label %13, label %17, !llvm.loop !10\l|{<s0>T|<s1>F}}"];
	Node0x4fa2500:s0 -> Node0x4fa2600;
	Node0x4fa2500:s1 -> Node0x4fa2500;
}
